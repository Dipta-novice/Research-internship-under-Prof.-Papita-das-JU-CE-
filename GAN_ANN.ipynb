{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN ANN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vWjMqz4BsWWe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "epwbAS0P1SYs",
        "outputId": "71678be9-c40c-4af1-db6f-a28aba86f48a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ed9d55df-84ab-4107-87bc-a5d50f9c3d8a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ed9d55df-84ab-4107-87bc-a5d50f9c3d8a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Book2n.xlsx to Book2n.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_excel('Book2n.xlsx')"
      ],
      "metadata": {
        "id": "yzRCUJ4J1s7L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lCDmn8paM4Po",
        "outputId": "2cc163d0-57b3-4280-821b-667c3ddf10eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-feb9d553-2b12-487e-a87d-b99c7625dc31\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conc (ppm)</th>\n",
              "      <th>ad dose(g/L)</th>\n",
              "      <th>ph value</th>\n",
              "      <th>Temperature(⁰C)</th>\n",
              "      <th>time</th>\n",
              "      <th>absorbance</th>\n",
              "      <th>conc</th>\n",
              "      <th>real conc</th>\n",
              "      <th>removal</th>\n",
              "      <th>%removal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6</td>\n",
              "      <td>30</td>\n",
              "      <td>15</td>\n",
              "      <td>0.0229</td>\n",
              "      <td>0.789655</td>\n",
              "      <td>0.789655</td>\n",
              "      <td>29.210345</td>\n",
              "      <td>97.270448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>0.0153</td>\n",
              "      <td>0.527586</td>\n",
              "      <td>0.527586</td>\n",
              "      <td>29.472414</td>\n",
              "      <td>98.143138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6</td>\n",
              "      <td>30</td>\n",
              "      <td>45</td>\n",
              "      <td>0.0152</td>\n",
              "      <td>0.524138</td>\n",
              "      <td>0.524138</td>\n",
              "      <td>29.475862</td>\n",
              "      <td>98.154621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6</td>\n",
              "      <td>30</td>\n",
              "      <td>60</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.482759</td>\n",
              "      <td>0.482759</td>\n",
              "      <td>29.517241</td>\n",
              "      <td>98.292414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6</td>\n",
              "      <td>30</td>\n",
              "      <td>120</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.379310</td>\n",
              "      <td>0.379310</td>\n",
              "      <td>29.620690</td>\n",
              "      <td>98.636897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6</td>\n",
              "      <td>40</td>\n",
              "      <td>15</td>\n",
              "      <td>0.1484</td>\n",
              "      <td>5.117241</td>\n",
              "      <td>5.117241</td>\n",
              "      <td>24.882759</td>\n",
              "      <td>82.859586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6</td>\n",
              "      <td>40</td>\n",
              "      <td>30</td>\n",
              "      <td>0.1252</td>\n",
              "      <td>4.317241</td>\n",
              "      <td>4.317241</td>\n",
              "      <td>25.682759</td>\n",
              "      <td>85.523586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6</td>\n",
              "      <td>40</td>\n",
              "      <td>45</td>\n",
              "      <td>0.0791</td>\n",
              "      <td>2.727586</td>\n",
              "      <td>2.727586</td>\n",
              "      <td>27.272414</td>\n",
              "      <td>90.817138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6</td>\n",
              "      <td>40</td>\n",
              "      <td>60</td>\n",
              "      <td>0.0563</td>\n",
              "      <td>1.941379</td>\n",
              "      <td>1.941379</td>\n",
              "      <td>28.058621</td>\n",
              "      <td>93.435207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6</td>\n",
              "      <td>40</td>\n",
              "      <td>120</td>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>29.310345</td>\n",
              "      <td>97.603448</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-feb9d553-2b12-487e-a87d-b99c7625dc31')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-feb9d553-2b12-487e-a87d-b99c7625dc31 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-feb9d553-2b12-487e-a87d-b99c7625dc31');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    conc (ppm)  ad dose(g/L)  ph value  Temperature(⁰C)  time  absorbance  \\\n",
              "0           10           1.0         6               30    15      0.0229   \n",
              "1           10           1.0         6               30    30      0.0153   \n",
              "2           10           1.0         6               30    45      0.0152   \n",
              "3           10           1.0         6               30    60      0.0140   \n",
              "4           10           1.0         6               30   120      0.0110   \n",
              "..         ...           ...       ...              ...   ...         ...   \n",
              "86          30           1.0         6               40    15      0.1484   \n",
              "87          30           1.0         6               40    30      0.1252   \n",
              "88          30           1.0         6               40    45      0.0791   \n",
              "89          30           1.0         6               40    60      0.0563   \n",
              "90          30           1.0         6               40   120      0.0200   \n",
              "\n",
              "        conc  real conc    removal  %removal    \n",
              "0   0.789655   0.789655  29.210345   97.270448  \n",
              "1   0.527586   0.527586  29.472414   98.143138  \n",
              "2   0.524138   0.524138  29.475862   98.154621  \n",
              "3   0.482759   0.482759  29.517241   98.292414  \n",
              "4   0.379310   0.379310  29.620690   98.636897  \n",
              "..       ...        ...        ...         ...  \n",
              "86  5.117241   5.117241  24.882759   82.859586  \n",
              "87  4.317241   4.317241  25.682759   85.523586  \n",
              "88  2.727586   2.727586  27.272414   90.817138  \n",
              "89  1.941379   1.941379  28.058621   93.435207  \n",
              "90  0.689655   0.689655  29.310345   97.603448  \n",
              "\n",
              "[91 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PowerTransformer"
      ],
      "metadata": {
        "id": "sWZ6R-_3mdAS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pt = PowerTransformer()\n"
      ],
      "metadata": {
        "id": "0fkMlh7xozWx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff=pt.fit_transform(data)"
      ],
      "metadata": {
        "id": "RnMPFGbfo1Cf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=data"
      ],
      "metadata": {
        "id": "UE5lqSjJpLcw"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "0dUiZ8VqLX0J",
        "outputId": "58b8d7dc-e7a2-424c-9fb9-69aca0739c2a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-41a7ac62-7afd-4d6c-bd0e-bdfd0b75de74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2.774094</td>\n",
              "      <td>-0.101091</td>\n",
              "      <td>-0.016075</td>\n",
              "      <td>-0.080550</td>\n",
              "      <td>-1.266266</td>\n",
              "      <td>-0.586941</td>\n",
              "      <td>-0.454824</td>\n",
              "      <td>-0.461947</td>\n",
              "      <td>0.581451</td>\n",
              "      <td>0.578585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-2.774094</td>\n",
              "      <td>-0.101091</td>\n",
              "      <td>-0.016075</td>\n",
              "      <td>-0.080550</td>\n",
              "      <td>-0.526452</td>\n",
              "      <td>-0.775195</td>\n",
              "      <td>-0.807595</td>\n",
              "      <td>-0.807275</td>\n",
              "      <td>0.675453</td>\n",
              "      <td>0.668526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.774094</td>\n",
              "      <td>-0.101091</td>\n",
              "      <td>-0.016075</td>\n",
              "      <td>-0.080550</td>\n",
              "      <td>-0.007143</td>\n",
              "      <td>-0.777772</td>\n",
              "      <td>-0.812981</td>\n",
              "      <td>-0.812542</td>\n",
              "      <td>0.676705</td>\n",
              "      <td>0.669722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-2.774094</td>\n",
              "      <td>-0.101091</td>\n",
              "      <td>-0.016075</td>\n",
              "      <td>-0.080550</td>\n",
              "      <td>0.405159</td>\n",
              "      <td>-0.808907</td>\n",
              "      <td>-0.879419</td>\n",
              "      <td>-0.877505</td>\n",
              "      <td>0.691759</td>\n",
              "      <td>0.684109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2.774094</td>\n",
              "      <td>-0.101091</td>\n",
              "      <td>-0.016075</td>\n",
              "      <td>-0.080550</td>\n",
              "      <td>1.569231</td>\n",
              "      <td>-0.888468</td>\n",
              "      <td>-1.061567</td>\n",
              "      <td>-1.055498</td>\n",
              "      <td>0.729641</td>\n",
              "      <td>0.720295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>-0.030050</td>\n",
              "      <td>-0.101091</td>\n",
              "      <td>-0.016075</td>\n",
              "      <td>2.610852</td>\n",
              "      <td>-1.266266</td>\n",
              "      <td>1.119409</td>\n",
              "      <td>1.133473</td>\n",
              "      <td>1.104058</td>\n",
              "      <td>-0.672795</td>\n",
              "      <td>-0.640944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>-0.030050</td>\n",
              "      <td>-0.101091</td>\n",
              "      <td>-0.016075</td>\n",
              "      <td>2.610852</td>\n",
              "      <td>-0.526452</td>\n",
              "      <td>0.937541</td>\n",
              "      <td>1.024342</td>\n",
              "      <td>0.995608</td>\n",
              "      <td>-0.480045</td>\n",
              "      <td>-0.450744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>-0.030050</td>\n",
              "      <td>-0.101091</td>\n",
              "      <td>-0.016075</td>\n",
              "      <td>2.610852</td>\n",
              "      <td>-0.007143</td>\n",
              "      <td>0.433301</td>\n",
              "      <td>0.681963</td>\n",
              "      <td>0.656421</td>\n",
              "      <td>-0.046584</td>\n",
              "      <td>-0.027071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>-0.030050</td>\n",
              "      <td>-0.101091</td>\n",
              "      <td>-0.016075</td>\n",
              "      <td>2.610852</td>\n",
              "      <td>0.405159</td>\n",
              "      <td>0.087017</td>\n",
              "      <td>0.389003</td>\n",
              "      <td>0.367217</td>\n",
              "      <td>0.194357</td>\n",
              "      <td>0.206325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>-0.030050</td>\n",
              "      <td>-0.101091</td>\n",
              "      <td>-0.016075</td>\n",
              "      <td>2.610852</td>\n",
              "      <td>1.569231</td>\n",
              "      <td>-0.657034</td>\n",
              "      <td>-0.577484</td>\n",
              "      <td>-0.582095</td>\n",
              "      <td>0.617055</td>\n",
              "      <td>0.612671</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41a7ac62-7afd-4d6c-bd0e-bdfd0b75de74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41a7ac62-7afd-4d6c-bd0e-bdfd0b75de74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41a7ac62-7afd-4d6c-bd0e-bdfd0b75de74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           0         1         2         3         4         5         6  \\\n",
              "0  -2.774094 -0.101091 -0.016075 -0.080550 -1.266266 -0.586941 -0.454824   \n",
              "1  -2.774094 -0.101091 -0.016075 -0.080550 -0.526452 -0.775195 -0.807595   \n",
              "2  -2.774094 -0.101091 -0.016075 -0.080550 -0.007143 -0.777772 -0.812981   \n",
              "3  -2.774094 -0.101091 -0.016075 -0.080550  0.405159 -0.808907 -0.879419   \n",
              "4  -2.774094 -0.101091 -0.016075 -0.080550  1.569231 -0.888468 -1.061567   \n",
              "..       ...       ...       ...       ...       ...       ...       ...   \n",
              "86 -0.030050 -0.101091 -0.016075  2.610852 -1.266266  1.119409  1.133473   \n",
              "87 -0.030050 -0.101091 -0.016075  2.610852 -0.526452  0.937541  1.024342   \n",
              "88 -0.030050 -0.101091 -0.016075  2.610852 -0.007143  0.433301  0.681963   \n",
              "89 -0.030050 -0.101091 -0.016075  2.610852  0.405159  0.087017  0.389003   \n",
              "90 -0.030050 -0.101091 -0.016075  2.610852  1.569231 -0.657034 -0.577484   \n",
              "\n",
              "           7         8         9  \n",
              "0  -0.461947  0.581451  0.578585  \n",
              "1  -0.807275  0.675453  0.668526  \n",
              "2  -0.812542  0.676705  0.669722  \n",
              "3  -0.877505  0.691759  0.684109  \n",
              "4  -1.055498  0.729641  0.720295  \n",
              "..       ...       ...       ...  \n",
              "86  1.104058 -0.672795 -0.640944  \n",
              "87  0.995608 -0.480045 -0.450744  \n",
              "88  0.656421 -0.046584 -0.027071  \n",
              "89  0.367217  0.194357  0.206325  \n",
              "90 -0.582095  0.617055  0.612671  \n",
              "\n",
              "[91 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_cols = ['conc (ppm)', 'ad dose(g/L)', 'ph value', 'Temperature(⁰C)', 'time',\n",
        "       'absorbance', 'conc', 'real conc', 'removal', '%removal  ']"
      ],
      "metadata": {
        "id": "HcCW-v6YX1KP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=data.iloc[:,-1]\n",
        "x=data.iloc[:,0:5]"
      ],
      "metadata": {
        "id": "hOkCc9eF8ct4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split as tts\n",
        "Xtrain,Xtest,ytrain,ytest=tts(x,y,test_size=0.3,random_state=42)"
      ],
      "metadata": {
        "id": "zlxBHv5z8Wx4"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "xGPiIRChrS5Z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAN():\n",
        "    \n",
        "    def __init__(self, gan_args):\n",
        "        [self.batch_size, lr, self.noise_dim,\n",
        "         self.data_dim, layers_dim] = gan_args\n",
        "\n",
        "        self.generator = Generator(self.batch_size).\\\n",
        "            build_model(input_shape=(self.noise_dim,), dim=layers_dim, data_dim=self.data_dim)\n",
        "\n",
        "        self.discriminator = Discriminator(self.batch_size).\\\n",
        "            build_model(input_shape=(self.data_dim,), dim=layers_dim)\n",
        "\n",
        "        optimizer = Adam(lr, 0.5)\n",
        "\n",
        "        # Build and compile the discriminator\n",
        "        self.discriminator.compile(loss='binary_crossentropy',\n",
        "                                   optimizer=optimizer,\n",
        "                                   metrics=['accuracy'])\n",
        "\n",
        "        # The generator takes noise as input and generates imgs\n",
        "        z = Input(shape=(self.noise_dim,))\n",
        "        record = self.generator(z)\n",
        "\n",
        "        # For the combined model we will only train the generator\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        # The discriminator takes generated images as input and determines validity\n",
        "        validity = self.discriminator(record)\n",
        "\n",
        "        # The combined model  (stacked generator and discriminator)\n",
        "        # Trains the generator to fool the discriminator\n",
        "        self.combined = Model(z, validity)\n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    def get_data_batch(self, train, batch_size, seed=0):\n",
        "        # # random sampling - some samples will have excessively low or high sampling, but easy to implement\n",
        "        # np.random.seed(seed)\n",
        "        # x = train.loc[ np.random.choice(train.index, batch_size) ].values\n",
        "        # iterate through shuffled indices, so every sample gets covered evenly\n",
        "\n",
        "        start_i = (batch_size * seed) % len(train)\n",
        "        stop_i = start_i + batch_size\n",
        "        shuffle_seed = (batch_size * seed) // len(train)\n",
        "        np.random.seed(shuffle_seed)\n",
        "        train_ix = np.random.choice(list(train.index), replace=False, size=len(train))  # wasteful to shuffle every time\n",
        "        train_ix = list(train_ix) + list(train_ix)  # duplicate to cover ranges past the end of the set\n",
        "        x = train.loc[train_ix[start_i: stop_i]].values\n",
        "        return np.reshape(x, (batch_size, -1))\n",
        "        \n",
        "    def train(self, data, train_arguments):\n",
        "        [cache_prefix, epochs, sample_interval] = train_arguments\n",
        "        \n",
        "        data_cols = data.columns\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = np.ones((self.batch_size, 1))\n",
        "        fake = np.zeros((self.batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):    \n",
        "            # ---------------------\n",
        "            #  Train Discriminator\n",
        "            # ---------------------\n",
        "            batch_data = self.get_data_batch(data, self.batch_size)\n",
        "            noise = tf.random.normal((self.batch_size, self.noise_dim))\n",
        "\n",
        "            # Generate a batch of new images\n",
        "            gen_data = self.generator.predict(noise)\n",
        "    \n",
        "            # Train the discriminator\n",
        "            d_loss_real = self.discriminator.train_on_batch(batch_data, valid)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_data, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "    \n",
        "            # ---------------------\n",
        "            #  Train Generator\n",
        "            # ---------------------\n",
        "            noise = tf.random.normal((self.batch_size, self.noise_dim))\n",
        "            # Train the generator (to have the discriminator label samples as valid)\n",
        "            g_loss = self.combined.train_on_batch(noise, valid)\n",
        "    \n",
        "            # Plot the progress\n",
        "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100 * d_loss[1], g_loss))\n",
        "    \n",
        "            # If at save interval => save generated events\n",
        "            if epoch % sample_interval == 0:\n",
        "                #Test here data generation step\n",
        "                # save model checkpoints\n",
        "                model_checkpoint_base_name = 'model/' + cache_prefix + '_{}_model_weights_step_{}.h5'\n",
        "                self.generator.save_weights(model_checkpoint_base_name.format('generator', epoch))\n",
        "                self.discriminator.save_weights(model_checkpoint_base_name.format('discriminator', epoch))\n",
        "\n",
        "                #Here is generating the data\n",
        "                z = tf.random.normal((432, self.noise_dim))\n",
        "                gen_data = self.generator(z)\n",
        "                print('generated_data')\n",
        "\n",
        "    def save(self, path, name):\n",
        "        assert os.path.isdir(path) == True, \\\n",
        "            \"Please provide a valid path. Path must be a directory.\"\n",
        "        model_path = os.path.join(path, name)\n",
        "        self.generator.save_weights(model_path)  # Load the generator\n",
        "        return\n",
        "    \n",
        "    def load(self, path):\n",
        "        assert os.path.isdir(path) == True, \\\n",
        "            \"Please provide a valid path. Path must be a directory.\"\n",
        "        self.generator = Generator(self.batch_size)\n",
        "        self.generator = self.generator.load_weights(path)\n",
        "        return self.generator\n",
        "    \n",
        "class Generator():\n",
        "    def __init__(self, batch_size):\n",
        "        self.batch_size=batch_size\n",
        "        \n",
        "    def build_model(self, input_shape, dim, data_dim):\n",
        "        input= Input(shape=input_shape, batch_size=self.batch_size)\n",
        "        x = Dense(dim, activation='relu')(input)\n",
        "        x = Dense(dim * 2, activation='relu')(x)\n",
        "        x = Dense(dim * 4, activation='relu')(x)\n",
        "        x = Dense(data_dim)(x)\n",
        "        return Model(inputs=input, outputs=x)\n",
        "\n",
        "class Discriminator():\n",
        "    def __init__(self,batch_size):\n",
        "        self.batch_size=batch_size\n",
        "    \n",
        "    def build_model(self, input_shape, dim):\n",
        "        input = Input(shape=input_shape, batch_size=self.batch_size)\n",
        "        x = Dense(dim * 4, activation='relu')(input)\n",
        "        x = Dropout(0.1)(x)\n",
        "        x = Dense(dim * 2, activation='relu')(x)\n",
        "        x = Dropout(0.1)(x)\n",
        "        x = Dense(dim, activation='relu')(x)\n",
        "        x = Dense(1, activation='sigmoid')(x)\n",
        "        return Model(inputs=input, outputs=x)"
      ],
      "metadata": {
        "id": "yXP_nCPos_L4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqoa6BT_8Rf4",
        "outputId": "4b13cfd8-cbdb-4aca-ef05-8b64f01693ff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise_dim = 32\n",
        "dim = 128\n",
        "batch_size = 32\n",
        "\n",
        "log_step = 100\n",
        "epochs = 5000+1\n",
        "learning_rate = 5e-4\n",
        "models_dir = 'model'\n",
        "\n",
        "\n",
        "\n",
        "gan_args = [batch_size, learning_rate, noise_dim, df.shape[1], dim]\n",
        "train_args = ['', epochs, log_step]"
      ],
      "metadata": {
        "id": "H1ecnbtT7KD6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir model"
      ],
      "metadata": {
        "id": "jMnChK0u-sh2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GAN\n",
        "\n",
        "#Training the GAN model chosen: Vanilla GAN, CGAN, DCGAN, etc.\n",
        "synthesizer = model(gan_args)\n",
        "synthesizer.train(df,train_args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbG_az3l85NA",
        "outputId": "da607b0f-3808-4f2d-dbde-ddf02e27a8cd"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "51 [D loss: 0.595485, acc.: 50.00%] [G loss: 0.807551]\n",
            "52 [D loss: 0.494691, acc.: 51.56%] [G loss: 0.709626]\n",
            "53 [D loss: 0.455056, acc.: 64.06%] [G loss: 0.796149]\n",
            "54 [D loss: 0.493709, acc.: 60.94%] [G loss: 0.913466]\n",
            "55 [D loss: 0.352490, acc.: 87.50%] [G loss: 1.185205]\n",
            "56 [D loss: 0.400666, acc.: 81.25%] [G loss: 1.138453]\n",
            "57 [D loss: 0.627782, acc.: 48.44%] [G loss: 0.852632]\n",
            "58 [D loss: 0.542318, acc.: 50.00%] [G loss: 0.855050]\n",
            "59 [D loss: 0.573975, acc.: 45.31%] [G loss: 0.881803]\n",
            "60 [D loss: 0.568620, acc.: 53.12%] [G loss: 0.811717]\n",
            "61 [D loss: 0.529307, acc.: 50.00%] [G loss: 0.811808]\n",
            "62 [D loss: 0.495764, acc.: 54.69%] [G loss: 0.851987]\n",
            "63 [D loss: 0.577664, acc.: 43.75%] [G loss: 0.767389]\n",
            "64 [D loss: 0.454873, acc.: 59.38%] [G loss: 0.897777]\n",
            "65 [D loss: 0.370225, acc.: 92.19%] [G loss: 1.063193]\n",
            "66 [D loss: 0.404121, acc.: 85.94%] [G loss: 1.153931]\n",
            "67 [D loss: 0.369670, acc.: 92.19%] [G loss: 1.077587]\n",
            "68 [D loss: 0.472385, acc.: 62.50%] [G loss: 0.922083]\n",
            "69 [D loss: 0.578960, acc.: 46.88%] [G loss: 0.792480]\n",
            "70 [D loss: 0.609326, acc.: 39.06%] [G loss: 0.729279]\n",
            "71 [D loss: 0.455017, acc.: 65.62%] [G loss: 0.885771]\n",
            "72 [D loss: 0.445463, acc.: 76.56%] [G loss: 1.007460]\n",
            "73 [D loss: 0.442501, acc.: 73.44%] [G loss: 0.984947]\n",
            "74 [D loss: 0.435750, acc.: 71.88%] [G loss: 1.074517]\n",
            "75 [D loss: 0.545462, acc.: 56.25%] [G loss: 0.869664]\n",
            "76 [D loss: 0.444445, acc.: 70.31%] [G loss: 0.848257]\n",
            "77 [D loss: 0.546912, acc.: 59.38%] [G loss: 0.770243]\n",
            "78 [D loss: 0.427845, acc.: 64.06%] [G loss: 0.862652]\n",
            "79 [D loss: 0.479535, acc.: 64.06%] [G loss: 0.819583]\n",
            "80 [D loss: 0.432715, acc.: 65.62%] [G loss: 0.894569]\n",
            "81 [D loss: 0.473420, acc.: 59.38%] [G loss: 0.839156]\n",
            "82 [D loss: 0.428827, acc.: 70.31%] [G loss: 0.953900]\n",
            "83 [D loss: 0.442834, acc.: 78.12%] [G loss: 1.046049]\n",
            "84 [D loss: 0.667737, acc.: 40.62%] [G loss: 0.732104]\n",
            "85 [D loss: 0.594565, acc.: 50.00%] [G loss: 0.876038]\n",
            "86 [D loss: 0.628033, acc.: 42.19%] [G loss: 0.814483]\n",
            "87 [D loss: 0.439161, acc.: 76.56%] [G loss: 1.031664]\n",
            "88 [D loss: 0.438192, acc.: 87.50%] [G loss: 1.003203]\n",
            "89 [D loss: 0.386821, acc.: 92.19%] [G loss: 1.070167]\n",
            "90 [D loss: 0.370939, acc.: 89.06%] [G loss: 1.155122]\n",
            "91 [D loss: 0.425041, acc.: 93.75%] [G loss: 0.939466]\n",
            "92 [D loss: 0.376900, acc.: 93.75%] [G loss: 0.909376]\n",
            "93 [D loss: 0.372080, acc.: 89.06%] [G loss: 0.972207]\n",
            "94 [D loss: 0.444173, acc.: 78.12%] [G loss: 0.971544]\n",
            "95 [D loss: 0.390469, acc.: 92.19%] [G loss: 1.072756]\n",
            "96 [D loss: 0.375313, acc.: 92.19%] [G loss: 1.083271]\n",
            "97 [D loss: 0.310657, acc.: 98.44%] [G loss: 1.130541]\n",
            "98 [D loss: 0.308941, acc.: 98.44%] [G loss: 1.239294]\n",
            "99 [D loss: 0.355482, acc.: 92.19%] [G loss: 1.153552]\n",
            "100 [D loss: 0.355055, acc.: 90.62%] [G loss: 1.101646]\n",
            "generated_data\n",
            "101 [D loss: 0.344763, acc.: 93.75%] [G loss: 1.076347]\n",
            "102 [D loss: 0.356661, acc.: 93.75%] [G loss: 1.081699]\n",
            "103 [D loss: 0.379107, acc.: 89.06%] [G loss: 1.057738]\n",
            "104 [D loss: 0.300801, acc.: 95.31%] [G loss: 1.078578]\n",
            "105 [D loss: 0.299986, acc.: 96.88%] [G loss: 1.097053]\n",
            "106 [D loss: 0.355312, acc.: 92.19%] [G loss: 1.056821]\n",
            "107 [D loss: 0.385374, acc.: 92.19%] [G loss: 1.055896]\n",
            "108 [D loss: 0.327775, acc.: 96.88%] [G loss: 1.138585]\n",
            "109 [D loss: 0.301574, acc.: 96.88%] [G loss: 1.128312]\n",
            "110 [D loss: 0.368500, acc.: 85.94%] [G loss: 0.992668]\n",
            "111 [D loss: 0.519145, acc.: 57.81%] [G loss: 1.006378]\n",
            "112 [D loss: 0.489393, acc.: 64.06%] [G loss: 1.321544]\n",
            "113 [D loss: 0.268614, acc.: 98.44%] [G loss: 2.122406]\n",
            "114 [D loss: 0.294090, acc.: 87.50%] [G loss: 1.616838]\n",
            "115 [D loss: 0.341674, acc.: 79.69%] [G loss: 1.266442]\n",
            "116 [D loss: 0.762720, acc.: 46.88%] [G loss: 0.507075]\n",
            "117 [D loss: 0.729318, acc.: 50.00%] [G loss: 0.773210]\n",
            "118 [D loss: 0.384701, acc.: 82.81%] [G loss: 1.111458]\n",
            "119 [D loss: 0.702940, acc.: 48.44%] [G loss: 0.595548]\n",
            "120 [D loss: 0.523335, acc.: 54.69%] [G loss: 0.787101]\n",
            "121 [D loss: 0.529943, acc.: 57.81%] [G loss: 0.931568]\n",
            "122 [D loss: 0.513028, acc.: 62.50%] [G loss: 0.875270]\n",
            "123 [D loss: 0.424515, acc.: 70.31%] [G loss: 0.955559]\n",
            "124 [D loss: 0.522616, acc.: 54.69%] [G loss: 0.742480]\n",
            "125 [D loss: 0.393582, acc.: 71.88%] [G loss: 0.963725]\n",
            "126 [D loss: 0.582908, acc.: 54.69%] [G loss: 0.791700]\n",
            "127 [D loss: 0.529171, acc.: 54.69%] [G loss: 0.781295]\n",
            "128 [D loss: 0.541487, acc.: 53.12%] [G loss: 0.792326]\n",
            "129 [D loss: 0.490860, acc.: 67.19%] [G loss: 0.848062]\n",
            "130 [D loss: 0.551868, acc.: 59.38%] [G loss: 0.768222]\n",
            "131 [D loss: 0.466217, acc.: 67.19%] [G loss: 0.839952]\n",
            "132 [D loss: 0.444819, acc.: 78.12%] [G loss: 0.974979]\n",
            "133 [D loss: 0.482590, acc.: 70.31%] [G loss: 0.966150]\n",
            "134 [D loss: 0.504357, acc.: 75.00%] [G loss: 0.983406]\n",
            "135 [D loss: 0.470197, acc.: 81.25%] [G loss: 0.983241]\n",
            "136 [D loss: 0.499988, acc.: 73.44%] [G loss: 0.917160]\n",
            "137 [D loss: 0.430925, acc.: 84.38%] [G loss: 0.955780]\n",
            "138 [D loss: 0.476730, acc.: 78.12%] [G loss: 1.057099]\n",
            "139 [D loss: 0.456013, acc.: 79.69%] [G loss: 1.039104]\n",
            "140 [D loss: 0.476763, acc.: 79.69%] [G loss: 0.904034]\n",
            "141 [D loss: 0.475490, acc.: 78.12%] [G loss: 0.927783]\n",
            "142 [D loss: 0.507791, acc.: 70.31%] [G loss: 0.850410]\n",
            "143 [D loss: 0.544732, acc.: 67.19%] [G loss: 0.927019]\n",
            "144 [D loss: 0.520445, acc.: 71.88%] [G loss: 1.008971]\n",
            "145 [D loss: 0.527859, acc.: 64.06%] [G loss: 0.968076]\n",
            "146 [D loss: 0.494891, acc.: 70.31%] [G loss: 0.965931]\n",
            "147 [D loss: 0.650941, acc.: 53.12%] [G loss: 0.879879]\n",
            "148 [D loss: 0.555591, acc.: 68.75%] [G loss: 0.801131]\n",
            "149 [D loss: 0.603617, acc.: 59.38%] [G loss: 0.825223]\n",
            "150 [D loss: 0.560965, acc.: 59.38%] [G loss: 0.793270]\n",
            "151 [D loss: 0.586804, acc.: 56.25%] [G loss: 0.757549]\n",
            "152 [D loss: 0.515869, acc.: 68.75%] [G loss: 0.831601]\n",
            "153 [D loss: 0.480119, acc.: 82.81%] [G loss: 0.852327]\n",
            "154 [D loss: 0.539886, acc.: 73.44%] [G loss: 0.902611]\n",
            "155 [D loss: 0.481471, acc.: 79.69%] [G loss: 0.989156]\n",
            "156 [D loss: 0.552307, acc.: 71.88%] [G loss: 0.967831]\n",
            "157 [D loss: 0.535428, acc.: 73.44%] [G loss: 0.871615]\n",
            "158 [D loss: 0.653226, acc.: 60.94%] [G loss: 0.861732]\n",
            "159 [D loss: 0.602748, acc.: 73.44%] [G loss: 0.886921]\n",
            "160 [D loss: 0.675545, acc.: 54.69%] [G loss: 0.929690]\n",
            "161 [D loss: 0.621102, acc.: 64.06%] [G loss: 0.954656]\n",
            "162 [D loss: 0.635251, acc.: 62.50%] [G loss: 0.892804]\n",
            "163 [D loss: 0.597228, acc.: 67.19%] [G loss: 0.884175]\n",
            "164 [D loss: 0.519621, acc.: 75.00%] [G loss: 0.943340]\n",
            "165 [D loss: 0.542197, acc.: 75.00%] [G loss: 0.988510]\n",
            "166 [D loss: 0.704093, acc.: 54.69%] [G loss: 0.876095]\n",
            "167 [D loss: 0.594919, acc.: 62.50%] [G loss: 0.983401]\n",
            "168 [D loss: 0.664744, acc.: 51.56%] [G loss: 0.865207]\n",
            "169 [D loss: 0.663399, acc.: 48.44%] [G loss: 0.869993]\n",
            "170 [D loss: 0.594681, acc.: 68.75%] [G loss: 0.829468]\n",
            "171 [D loss: 0.618958, acc.: 59.38%] [G loss: 0.965989]\n",
            "172 [D loss: 0.598956, acc.: 60.94%] [G loss: 1.006661]\n",
            "173 [D loss: 0.587040, acc.: 62.50%] [G loss: 1.003937]\n",
            "174 [D loss: 0.636873, acc.: 48.44%] [G loss: 1.040757]\n",
            "175 [D loss: 0.652947, acc.: 54.69%] [G loss: 0.931400]\n",
            "176 [D loss: 0.662512, acc.: 50.00%] [G loss: 0.838970]\n",
            "177 [D loss: 0.631226, acc.: 62.50%] [G loss: 0.861559]\n",
            "178 [D loss: 0.588066, acc.: 60.94%] [G loss: 0.878471]\n",
            "179 [D loss: 0.620780, acc.: 60.94%] [G loss: 1.076783]\n",
            "180 [D loss: 0.661865, acc.: 51.56%] [G loss: 0.942357]\n",
            "181 [D loss: 0.620870, acc.: 57.81%] [G loss: 0.860204]\n",
            "182 [D loss: 0.663344, acc.: 48.44%] [G loss: 0.931664]\n",
            "183 [D loss: 0.696251, acc.: 39.06%] [G loss: 0.881205]\n",
            "184 [D loss: 0.611983, acc.: 56.25%] [G loss: 0.987312]\n",
            "185 [D loss: 0.599722, acc.: 62.50%] [G loss: 0.957877]\n",
            "186 [D loss: 0.624938, acc.: 54.69%] [G loss: 1.079674]\n",
            "187 [D loss: 0.596529, acc.: 70.31%] [G loss: 0.993513]\n",
            "188 [D loss: 0.655437, acc.: 56.25%] [G loss: 1.028203]\n",
            "189 [D loss: 0.624763, acc.: 59.38%] [G loss: 0.992218]\n",
            "190 [D loss: 0.598363, acc.: 64.06%] [G loss: 0.960385]\n",
            "191 [D loss: 0.628497, acc.: 59.38%] [G loss: 0.926291]\n",
            "192 [D loss: 0.616744, acc.: 59.38%] [G loss: 1.042278]\n",
            "193 [D loss: 0.609012, acc.: 60.94%] [G loss: 0.975099]\n",
            "194 [D loss: 0.643474, acc.: 54.69%] [G loss: 0.991179]\n",
            "195 [D loss: 0.607341, acc.: 60.94%] [G loss: 0.912662]\n",
            "196 [D loss: 0.561806, acc.: 68.75%] [G loss: 0.919727]\n",
            "197 [D loss: 0.602411, acc.: 56.25%] [G loss: 0.882949]\n",
            "198 [D loss: 0.606915, acc.: 57.81%] [G loss: 0.973018]\n",
            "199 [D loss: 0.623943, acc.: 60.94%] [G loss: 0.912925]\n",
            "200 [D loss: 0.608466, acc.: 65.62%] [G loss: 1.063603]\n",
            "generated_data\n",
            "201 [D loss: 0.642547, acc.: 62.50%] [G loss: 0.931582]\n",
            "202 [D loss: 0.628541, acc.: 65.62%] [G loss: 1.027069]\n",
            "203 [D loss: 0.626333, acc.: 59.38%] [G loss: 0.980517]\n",
            "204 [D loss: 0.640202, acc.: 53.12%] [G loss: 1.075830]\n",
            "205 [D loss: 0.613334, acc.: 65.62%] [G loss: 1.027596]\n",
            "206 [D loss: 0.663288, acc.: 54.69%] [G loss: 0.982824]\n",
            "207 [D loss: 0.600397, acc.: 60.94%] [G loss: 1.090465]\n",
            "208 [D loss: 0.586386, acc.: 65.62%] [G loss: 1.070089]\n",
            "209 [D loss: 0.620252, acc.: 59.38%] [G loss: 1.121760]\n",
            "210 [D loss: 0.617469, acc.: 64.06%] [G loss: 0.948077]\n",
            "211 [D loss: 0.659782, acc.: 59.38%] [G loss: 0.914458]\n",
            "212 [D loss: 0.638738, acc.: 51.56%] [G loss: 1.012538]\n",
            "213 [D loss: 0.648512, acc.: 57.81%] [G loss: 0.994029]\n",
            "214 [D loss: 0.593672, acc.: 64.06%] [G loss: 1.114796]\n",
            "215 [D loss: 0.567771, acc.: 65.62%] [G loss: 1.090136]\n",
            "216 [D loss: 0.594050, acc.: 65.62%] [G loss: 1.095940]\n",
            "217 [D loss: 0.627638, acc.: 60.94%] [G loss: 1.085505]\n",
            "218 [D loss: 0.601400, acc.: 67.19%] [G loss: 1.111868]\n",
            "219 [D loss: 0.629080, acc.: 64.06%] [G loss: 1.075023]\n",
            "220 [D loss: 0.633260, acc.: 62.50%] [G loss: 0.985050]\n",
            "221 [D loss: 0.588364, acc.: 64.06%] [G loss: 1.014939]\n",
            "222 [D loss: 0.661869, acc.: 53.12%] [G loss: 1.081782]\n",
            "223 [D loss: 0.572428, acc.: 62.50%] [G loss: 1.086327]\n",
            "224 [D loss: 0.561774, acc.: 70.31%] [G loss: 1.107108]\n",
            "225 [D loss: 0.590513, acc.: 67.19%] [G loss: 1.074677]\n",
            "226 [D loss: 0.633357, acc.: 65.62%] [G loss: 1.018864]\n",
            "227 [D loss: 0.638370, acc.: 59.38%] [G loss: 1.090699]\n",
            "228 [D loss: 0.606417, acc.: 67.19%] [G loss: 1.031061]\n",
            "229 [D loss: 0.669394, acc.: 56.25%] [G loss: 1.055710]\n",
            "230 [D loss: 0.632131, acc.: 59.38%] [G loss: 1.072965]\n",
            "231 [D loss: 0.620935, acc.: 62.50%] [G loss: 1.049180]\n",
            "232 [D loss: 0.644903, acc.: 60.94%] [G loss: 0.967015]\n",
            "233 [D loss: 0.577723, acc.: 65.62%] [G loss: 1.631868]\n",
            "234 [D loss: 0.791225, acc.: 60.94%] [G loss: 1.090411]\n",
            "235 [D loss: 0.600537, acc.: 64.06%] [G loss: 1.092070]\n",
            "236 [D loss: 0.633071, acc.: 64.06%] [G loss: 1.010579]\n",
            "237 [D loss: 0.610916, acc.: 57.81%] [G loss: 0.879811]\n",
            "238 [D loss: 0.701472, acc.: 50.00%] [G loss: 0.910957]\n",
            "239 [D loss: 0.674600, acc.: 53.12%] [G loss: 1.105915]\n",
            "240 [D loss: 0.657322, acc.: 54.69%] [G loss: 1.147839]\n",
            "241 [D loss: 0.655261, acc.: 59.38%] [G loss: 1.115916]\n",
            "242 [D loss: 0.621690, acc.: 65.62%] [G loss: 1.127359]\n",
            "243 [D loss: 0.597673, acc.: 62.50%] [G loss: 1.028653]\n",
            "244 [D loss: 0.605228, acc.: 60.94%] [G loss: 1.033902]\n",
            "245 [D loss: 0.586877, acc.: 62.50%] [G loss: 1.143983]\n",
            "246 [D loss: 0.629160, acc.: 62.50%] [G loss: 0.969169]\n",
            "247 [D loss: 0.607743, acc.: 65.62%] [G loss: 0.957839]\n",
            "248 [D loss: 0.605362, acc.: 67.19%] [G loss: 1.042143]\n",
            "249 [D loss: 0.631854, acc.: 60.94%] [G loss: 1.008427]\n",
            "250 [D loss: 0.601923, acc.: 57.81%] [G loss: 1.017062]\n",
            "251 [D loss: 0.591469, acc.: 60.94%] [G loss: 1.147951]\n",
            "252 [D loss: 0.599693, acc.: 64.06%] [G loss: 0.914837]\n",
            "253 [D loss: 0.654291, acc.: 53.12%] [G loss: 0.925805]\n",
            "254 [D loss: 0.649101, acc.: 56.25%] [G loss: 0.989387]\n",
            "255 [D loss: 0.574048, acc.: 60.94%] [G loss: 1.119911]\n",
            "256 [D loss: 0.584826, acc.: 62.50%] [G loss: 1.200156]\n",
            "257 [D loss: 0.650856, acc.: 60.94%] [G loss: 1.064070]\n",
            "258 [D loss: 0.640437, acc.: 57.81%] [G loss: 1.080252]\n",
            "259 [D loss: 0.603899, acc.: 59.38%] [G loss: 0.978899]\n",
            "260 [D loss: 0.599754, acc.: 62.50%] [G loss: 0.928654]\n",
            "261 [D loss: 0.609278, acc.: 57.81%] [G loss: 1.083787]\n",
            "262 [D loss: 0.612696, acc.: 62.50%] [G loss: 1.031463]\n",
            "263 [D loss: 0.594183, acc.: 62.50%] [G loss: 1.052920]\n",
            "264 [D loss: 0.601667, acc.: 62.50%] [G loss: 1.065323]\n",
            "265 [D loss: 0.594227, acc.: 65.62%] [G loss: 0.978141]\n",
            "266 [D loss: 0.598018, acc.: 65.62%] [G loss: 0.974564]\n",
            "267 [D loss: 0.607108, acc.: 62.50%] [G loss: 0.947970]\n",
            "268 [D loss: 0.623066, acc.: 54.69%] [G loss: 0.960828]\n",
            "269 [D loss: 0.608934, acc.: 65.62%] [G loss: 0.980713]\n",
            "270 [D loss: 0.583798, acc.: 64.06%] [G loss: 0.966736]\n",
            "271 [D loss: 0.592536, acc.: 67.19%] [G loss: 0.976818]\n",
            "272 [D loss: 0.618284, acc.: 60.94%] [G loss: 0.955286]\n",
            "273 [D loss: 0.593777, acc.: 64.06%] [G loss: 0.995530]\n",
            "274 [D loss: 0.578148, acc.: 68.75%] [G loss: 1.034035]\n",
            "275 [D loss: 0.615829, acc.: 62.50%] [G loss: 1.090504]\n",
            "276 [D loss: 0.606581, acc.: 64.06%] [G loss: 0.965991]\n",
            "277 [D loss: 0.585738, acc.: 64.06%] [G loss: 0.971370]\n",
            "278 [D loss: 0.605445, acc.: 62.50%] [G loss: 0.992767]\n",
            "279 [D loss: 0.572871, acc.: 65.62%] [G loss: 1.030046]\n",
            "280 [D loss: 0.626749, acc.: 54.69%] [G loss: 1.053472]\n",
            "281 [D loss: 0.609165, acc.: 59.38%] [G loss: 0.990914]\n",
            "282 [D loss: 0.566585, acc.: 65.62%] [G loss: 0.991396]\n",
            "283 [D loss: 0.599709, acc.: 62.50%] [G loss: 1.005109]\n",
            "284 [D loss: 0.583044, acc.: 65.62%] [G loss: 0.996435]\n",
            "285 [D loss: 0.584518, acc.: 67.19%] [G loss: 1.066531]\n",
            "286 [D loss: 0.595353, acc.: 64.06%] [G loss: 1.046056]\n",
            "287 [D loss: 0.569084, acc.: 67.19%] [G loss: 1.027445]\n",
            "288 [D loss: 0.574809, acc.: 68.75%] [G loss: 1.017388]\n",
            "289 [D loss: 0.603546, acc.: 70.31%] [G loss: 0.932754]\n",
            "290 [D loss: 0.585042, acc.: 68.75%] [G loss: 0.910997]\n",
            "291 [D loss: 0.565156, acc.: 68.75%] [G loss: 0.935496]\n",
            "292 [D loss: 0.559400, acc.: 68.75%] [G loss: 0.967475]\n",
            "293 [D loss: 0.577708, acc.: 65.62%] [G loss: 0.951915]\n",
            "294 [D loss: 0.621963, acc.: 60.94%] [G loss: 0.989848]\n",
            "295 [D loss: 0.603192, acc.: 71.88%] [G loss: 1.006539]\n",
            "296 [D loss: 0.643761, acc.: 59.38%] [G loss: 1.119752]\n",
            "297 [D loss: 0.622957, acc.: 62.50%] [G loss: 1.062453]\n",
            "298 [D loss: 0.583176, acc.: 67.19%] [G loss: 1.113239]\n",
            "299 [D loss: 0.582436, acc.: 70.31%] [G loss: 1.053351]\n",
            "300 [D loss: 0.545957, acc.: 73.44%] [G loss: 1.056489]\n",
            "generated_data\n",
            "301 [D loss: 0.558403, acc.: 73.44%] [G loss: 1.075598]\n",
            "302 [D loss: 0.514598, acc.: 76.56%] [G loss: 1.169577]\n",
            "303 [D loss: 0.483517, acc.: 78.12%] [G loss: 1.140701]\n",
            "304 [D loss: 0.618537, acc.: 51.56%] [G loss: 1.263007]\n",
            "305 [D loss: 0.515908, acc.: 76.56%] [G loss: 1.156090]\n",
            "306 [D loss: 0.586733, acc.: 71.88%] [G loss: 1.098631]\n",
            "307 [D loss: 0.541557, acc.: 71.88%] [G loss: 1.024863]\n",
            "308 [D loss: 0.608553, acc.: 59.38%] [G loss: 1.116302]\n",
            "309 [D loss: 0.565931, acc.: 67.19%] [G loss: 1.039694]\n",
            "310 [D loss: 0.656748, acc.: 60.94%] [G loss: 1.069434]\n",
            "311 [D loss: 0.614076, acc.: 59.38%] [G loss: 1.052774]\n",
            "312 [D loss: 0.557377, acc.: 68.75%] [G loss: 1.072936]\n",
            "313 [D loss: 0.569444, acc.: 65.62%] [G loss: 1.073873]\n",
            "314 [D loss: 0.602745, acc.: 67.19%] [G loss: 1.017295]\n",
            "315 [D loss: 0.587632, acc.: 65.62%] [G loss: 0.946793]\n",
            "316 [D loss: 0.602735, acc.: 65.62%] [G loss: 0.939039]\n",
            "317 [D loss: 0.574009, acc.: 67.19%] [G loss: 1.041812]\n",
            "318 [D loss: 0.553331, acc.: 70.31%] [G loss: 0.917534]\n",
            "319 [D loss: 0.562092, acc.: 67.19%] [G loss: 1.006095]\n",
            "320 [D loss: 0.573832, acc.: 67.19%] [G loss: 1.037672]\n",
            "321 [D loss: 0.595945, acc.: 68.75%] [G loss: 1.029696]\n",
            "322 [D loss: 0.586440, acc.: 65.62%] [G loss: 1.004359]\n",
            "323 [D loss: 0.607285, acc.: 65.62%] [G loss: 1.001409]\n",
            "324 [D loss: 0.554645, acc.: 70.31%] [G loss: 0.948715]\n",
            "325 [D loss: 0.555678, acc.: 65.62%] [G loss: 1.010587]\n",
            "326 [D loss: 0.522060, acc.: 76.56%] [G loss: 0.990433]\n",
            "327 [D loss: 0.522098, acc.: 73.44%] [G loss: 1.022680]\n",
            "328 [D loss: 0.597908, acc.: 57.81%] [G loss: 1.063443]\n",
            "329 [D loss: 0.636290, acc.: 54.69%] [G loss: 1.058570]\n",
            "330 [D loss: 0.638659, acc.: 56.25%] [G loss: 1.108809]\n",
            "331 [D loss: 0.579266, acc.: 65.62%] [G loss: 1.193802]\n",
            "332 [D loss: 0.576956, acc.: 64.06%] [G loss: 1.135381]\n",
            "333 [D loss: 0.558713, acc.: 62.50%] [G loss: 1.186720]\n",
            "334 [D loss: 0.516011, acc.: 71.88%] [G loss: 1.148697]\n",
            "335 [D loss: 0.553989, acc.: 71.88%] [G loss: 1.247090]\n",
            "336 [D loss: 0.559062, acc.: 73.44%] [G loss: 1.271062]\n",
            "337 [D loss: 0.627288, acc.: 65.62%] [G loss: 1.071593]\n",
            "338 [D loss: 0.804493, acc.: 51.56%] [G loss: 0.890310]\n",
            "339 [D loss: 0.650300, acc.: 59.38%] [G loss: 0.942721]\n",
            "340 [D loss: 0.576076, acc.: 67.19%] [G loss: 1.173458]\n",
            "341 [D loss: 0.555613, acc.: 68.75%] [G loss: 1.344778]\n",
            "342 [D loss: 0.540330, acc.: 70.31%] [G loss: 1.118074]\n",
            "343 [D loss: 0.502990, acc.: 78.12%] [G loss: 1.031257]\n",
            "344 [D loss: 0.443357, acc.: 85.94%] [G loss: 1.053046]\n",
            "345 [D loss: 0.411487, acc.: 84.38%] [G loss: 0.992863]\n",
            "346 [D loss: 0.559153, acc.: 60.94%] [G loss: 1.042599]\n",
            "347 [D loss: 0.572898, acc.: 67.19%] [G loss: 1.048975]\n",
            "348 [D loss: 0.653180, acc.: 56.25%] [G loss: 0.950256]\n",
            "349 [D loss: 0.637687, acc.: 57.81%] [G loss: 1.044821]\n",
            "350 [D loss: 0.595511, acc.: 62.50%] [G loss: 1.492688]\n",
            "351 [D loss: 0.685359, acc.: 57.81%] [G loss: 1.112600]\n",
            "352 [D loss: 0.609018, acc.: 57.81%] [G loss: 1.173203]\n",
            "353 [D loss: 0.582491, acc.: 67.19%] [G loss: 1.187973]\n",
            "354 [D loss: 0.559761, acc.: 64.06%] [G loss: 1.093309]\n",
            "355 [D loss: 0.586879, acc.: 64.06%] [G loss: 1.077554]\n",
            "356 [D loss: 0.614277, acc.: 59.38%] [G loss: 0.900167]\n",
            "357 [D loss: 0.613004, acc.: 60.94%] [G loss: 0.858087]\n",
            "358 [D loss: 0.678537, acc.: 40.62%] [G loss: 0.816172]\n",
            "359 [D loss: 0.635384, acc.: 51.56%] [G loss: 0.820539]\n",
            "360 [D loss: 0.606901, acc.: 62.50%] [G loss: 0.879024]\n",
            "361 [D loss: 0.582948, acc.: 67.19%] [G loss: 0.902510]\n",
            "362 [D loss: 0.569596, acc.: 68.75%] [G loss: 0.948005]\n",
            "363 [D loss: 0.576674, acc.: 64.06%] [G loss: 1.050064]\n",
            "364 [D loss: 0.590325, acc.: 64.06%] [G loss: 0.943313]\n",
            "365 [D loss: 0.620160, acc.: 57.81%] [G loss: 0.838546]\n",
            "366 [D loss: 0.615437, acc.: 56.25%] [G loss: 0.822915]\n",
            "367 [D loss: 0.607711, acc.: 59.38%] [G loss: 0.831015]\n",
            "368 [D loss: 0.600303, acc.: 62.50%] [G loss: 0.879450]\n",
            "369 [D loss: 0.597754, acc.: 64.06%] [G loss: 0.920472]\n",
            "370 [D loss: 0.583603, acc.: 67.19%] [G loss: 0.978357]\n",
            "371 [D loss: 0.583559, acc.: 67.19%] [G loss: 0.939792]\n",
            "372 [D loss: 0.576531, acc.: 64.06%] [G loss: 0.959859]\n",
            "373 [D loss: 0.553865, acc.: 65.62%] [G loss: 0.973770]\n",
            "374 [D loss: 0.580808, acc.: 64.06%] [G loss: 0.979188]\n",
            "375 [D loss: 0.571373, acc.: 60.94%] [G loss: 0.997290]\n",
            "376 [D loss: 0.585369, acc.: 65.62%] [G loss: 0.961562]\n",
            "377 [D loss: 0.601847, acc.: 64.06%] [G loss: 0.969100]\n",
            "378 [D loss: 0.589571, acc.: 67.19%] [G loss: 0.978177]\n",
            "379 [D loss: 0.603109, acc.: 62.50%] [G loss: 0.951832]\n",
            "380 [D loss: 0.569619, acc.: 67.19%] [G loss: 0.948803]\n",
            "381 [D loss: 0.573293, acc.: 67.19%] [G loss: 0.913218]\n",
            "382 [D loss: 0.567416, acc.: 65.62%] [G loss: 0.937321]\n",
            "383 [D loss: 0.588678, acc.: 56.25%] [G loss: 0.937454]\n",
            "384 [D loss: 0.571232, acc.: 65.62%] [G loss: 1.033949]\n",
            "385 [D loss: 0.636872, acc.: 56.25%] [G loss: 1.095499]\n",
            "386 [D loss: 0.565759, acc.: 68.75%] [G loss: 1.073451]\n",
            "387 [D loss: 0.593858, acc.: 67.19%] [G loss: 1.030150]\n",
            "388 [D loss: 0.590429, acc.: 64.06%] [G loss: 1.053310]\n",
            "389 [D loss: 0.596559, acc.: 65.62%] [G loss: 1.048720]\n",
            "390 [D loss: 0.597302, acc.: 59.38%] [G loss: 1.003793]\n",
            "391 [D loss: 0.579044, acc.: 67.19%] [G loss: 0.953258]\n",
            "392 [D loss: 0.580486, acc.: 65.62%] [G loss: 1.050307]\n",
            "393 [D loss: 0.583483, acc.: 64.06%] [G loss: 1.012950]\n",
            "394 [D loss: 0.555402, acc.: 70.31%] [G loss: 1.055096]\n",
            "395 [D loss: 0.560403, acc.: 73.44%] [G loss: 1.081509]\n",
            "396 [D loss: 0.547144, acc.: 73.44%] [G loss: 1.001977]\n",
            "397 [D loss: 0.576193, acc.: 76.56%] [G loss: 0.967939]\n",
            "398 [D loss: 0.565507, acc.: 68.75%] [G loss: 1.052662]\n",
            "399 [D loss: 0.509954, acc.: 73.44%] [G loss: 1.094991]\n",
            "400 [D loss: 0.546163, acc.: 71.88%] [G loss: 1.078762]\n",
            "generated_data\n",
            "401 [D loss: 0.510801, acc.: 76.56%] [G loss: 1.080408]\n",
            "402 [D loss: 0.519876, acc.: 75.00%] [G loss: 1.036165]\n",
            "403 [D loss: 0.527777, acc.: 75.00%] [G loss: 1.011178]\n",
            "404 [D loss: 0.517666, acc.: 73.44%] [G loss: 0.941341]\n",
            "405 [D loss: 0.510563, acc.: 75.00%] [G loss: 0.966091]\n",
            "406 [D loss: 0.546110, acc.: 68.75%] [G loss: 0.966003]\n",
            "407 [D loss: 0.546275, acc.: 75.00%] [G loss: 0.945862]\n",
            "408 [D loss: 0.547482, acc.: 70.31%] [G loss: 0.951556]\n",
            "409 [D loss: 0.561757, acc.: 67.19%] [G loss: 0.940655]\n",
            "410 [D loss: 0.603421, acc.: 60.94%] [G loss: 0.963118]\n",
            "411 [D loss: 0.519044, acc.: 76.56%] [G loss: 0.997693]\n",
            "412 [D loss: 0.543887, acc.: 71.88%] [G loss: 1.050205]\n",
            "413 [D loss: 0.515371, acc.: 79.69%] [G loss: 1.042005]\n",
            "414 [D loss: 0.542273, acc.: 68.75%] [G loss: 1.004035]\n",
            "415 [D loss: 0.519734, acc.: 76.56%] [G loss: 0.953491]\n",
            "416 [D loss: 0.566306, acc.: 70.31%] [G loss: 1.083711]\n",
            "417 [D loss: 0.568214, acc.: 70.31%] [G loss: 1.014421]\n",
            "418 [D loss: 0.547535, acc.: 68.75%] [G loss: 0.953926]\n",
            "419 [D loss: 0.550140, acc.: 67.19%] [G loss: 0.925068]\n",
            "420 [D loss: 0.623936, acc.: 54.69%] [G loss: 0.950022]\n",
            "421 [D loss: 0.636131, acc.: 53.12%] [G loss: 0.939072]\n",
            "422 [D loss: 0.580170, acc.: 67.19%] [G loss: 1.006463]\n",
            "423 [D loss: 0.543124, acc.: 65.62%] [G loss: 1.072904]\n",
            "424 [D loss: 0.508644, acc.: 78.12%] [G loss: 1.186649]\n",
            "425 [D loss: 0.476737, acc.: 78.12%] [G loss: 1.185503]\n",
            "426 [D loss: 0.469977, acc.: 79.69%] [G loss: 1.186255]\n",
            "427 [D loss: 0.540005, acc.: 70.31%] [G loss: 1.379241]\n",
            "428 [D loss: 0.588896, acc.: 67.19%] [G loss: 1.246225]\n",
            "429 [D loss: 0.556365, acc.: 70.31%] [G loss: 1.112042]\n",
            "430 [D loss: 0.528418, acc.: 71.88%] [G loss: 1.207610]\n",
            "431 [D loss: 0.555460, acc.: 71.88%] [G loss: 1.175059]\n",
            "432 [D loss: 0.484010, acc.: 81.25%] [G loss: 1.089236]\n",
            "433 [D loss: 0.404321, acc.: 79.69%] [G loss: 1.356994]\n",
            "434 [D loss: 0.444734, acc.: 75.00%] [G loss: 1.572062]\n",
            "435 [D loss: 0.550579, acc.: 70.31%] [G loss: 1.078055]\n",
            "436 [D loss: 0.707174, acc.: 53.12%] [G loss: 0.998389]\n",
            "437 [D loss: 0.633392, acc.: 50.00%] [G loss: 0.989553]\n",
            "438 [D loss: 0.592215, acc.: 70.31%] [G loss: 1.087222]\n",
            "439 [D loss: 0.567104, acc.: 65.62%] [G loss: 1.224290]\n",
            "440 [D loss: 0.500773, acc.: 81.25%] [G loss: 1.199250]\n",
            "441 [D loss: 0.542194, acc.: 76.56%] [G loss: 1.174218]\n",
            "442 [D loss: 0.520561, acc.: 76.56%] [G loss: 1.231084]\n",
            "443 [D loss: 0.481710, acc.: 84.38%] [G loss: 1.167073]\n",
            "444 [D loss: 0.509008, acc.: 82.81%] [G loss: 1.087209]\n",
            "445 [D loss: 0.618837, acc.: 68.75%] [G loss: 0.948055]\n",
            "446 [D loss: 0.705232, acc.: 59.38%] [G loss: 0.975073]\n",
            "447 [D loss: 0.715575, acc.: 37.50%] [G loss: 0.898586]\n",
            "448 [D loss: 0.610004, acc.: 62.50%] [G loss: 1.004567]\n",
            "449 [D loss: 0.557369, acc.: 68.75%] [G loss: 1.145480]\n",
            "450 [D loss: 0.544237, acc.: 70.31%] [G loss: 1.125534]\n",
            "451 [D loss: 0.549939, acc.: 68.75%] [G loss: 0.971703]\n",
            "452 [D loss: 0.546312, acc.: 68.75%] [G loss: 1.048209]\n",
            "453 [D loss: 0.553571, acc.: 68.75%] [G loss: 1.060684]\n",
            "454 [D loss: 0.543246, acc.: 73.44%] [G loss: 1.052069]\n",
            "455 [D loss: 0.609344, acc.: 60.94%] [G loss: 0.959695]\n",
            "456 [D loss: 0.582470, acc.: 62.50%] [G loss: 0.949468]\n",
            "457 [D loss: 0.559557, acc.: 70.31%] [G loss: 0.962397]\n",
            "458 [D loss: 0.505095, acc.: 78.12%] [G loss: 1.043605]\n",
            "459 [D loss: 0.512687, acc.: 75.00%] [G loss: 1.024875]\n",
            "460 [D loss: 0.462293, acc.: 87.50%] [G loss: 1.096335]\n",
            "461 [D loss: 0.565816, acc.: 68.75%] [G loss: 1.039020]\n",
            "462 [D loss: 0.594444, acc.: 67.19%] [G loss: 1.090354]\n",
            "463 [D loss: 0.566793, acc.: 70.31%] [G loss: 1.096663]\n",
            "464 [D loss: 0.571131, acc.: 68.75%] [G loss: 0.981499]\n",
            "465 [D loss: 0.550862, acc.: 71.88%] [G loss: 0.899938]\n",
            "466 [D loss: 0.530466, acc.: 70.31%] [G loss: 0.903931]\n",
            "467 [D loss: 0.530609, acc.: 75.00%] [G loss: 0.823736]\n",
            "468 [D loss: 0.546130, acc.: 71.88%] [G loss: 0.892690]\n",
            "469 [D loss: 0.561926, acc.: 68.75%] [G loss: 0.941971]\n",
            "470 [D loss: 0.536415, acc.: 70.31%] [G loss: 1.006688]\n",
            "471 [D loss: 0.526836, acc.: 73.44%] [G loss: 0.983751]\n",
            "472 [D loss: 0.572781, acc.: 59.38%] [G loss: 0.964349]\n",
            "473 [D loss: 0.548861, acc.: 67.19%] [G loss: 0.988644]\n",
            "474 [D loss: 0.547695, acc.: 68.75%] [G loss: 0.992018]\n",
            "475 [D loss: 0.546816, acc.: 65.62%] [G loss: 0.975358]\n",
            "476 [D loss: 0.547284, acc.: 65.62%] [G loss: 1.002610]\n",
            "477 [D loss: 0.539619, acc.: 68.75%] [G loss: 0.982199]\n",
            "478 [D loss: 0.570269, acc.: 64.06%] [G loss: 0.956295]\n",
            "479 [D loss: 0.555176, acc.: 68.75%] [G loss: 0.983022]\n",
            "480 [D loss: 0.559122, acc.: 62.50%] [G loss: 0.956259]\n",
            "481 [D loss: 0.520417, acc.: 71.88%] [G loss: 0.943290]\n",
            "482 [D loss: 0.527617, acc.: 75.00%] [G loss: 0.969060]\n",
            "483 [D loss: 0.556809, acc.: 59.38%] [G loss: 0.983394]\n",
            "484 [D loss: 0.539013, acc.: 68.75%] [G loss: 0.995370]\n",
            "485 [D loss: 0.517675, acc.: 76.56%] [G loss: 0.951215]\n",
            "486 [D loss: 0.570691, acc.: 62.50%] [G loss: 0.952359]\n",
            "487 [D loss: 0.543300, acc.: 68.75%] [G loss: 0.932636]\n",
            "488 [D loss: 0.564800, acc.: 68.75%] [G loss: 0.896424]\n",
            "489 [D loss: 0.572720, acc.: 73.44%] [G loss: 0.899044]\n",
            "490 [D loss: 0.566120, acc.: 67.19%] [G loss: 0.969276]\n",
            "491 [D loss: 0.557678, acc.: 68.75%] [G loss: 1.000297]\n",
            "492 [D loss: 0.565031, acc.: 68.75%] [G loss: 0.963457]\n",
            "493 [D loss: 0.530671, acc.: 71.88%] [G loss: 1.017946]\n",
            "494 [D loss: 0.503549, acc.: 70.31%] [G loss: 1.036837]\n",
            "495 [D loss: 0.476498, acc.: 79.69%] [G loss: 1.024056]\n",
            "496 [D loss: 0.564057, acc.: 70.31%] [G loss: 0.908124]\n",
            "497 [D loss: 0.610135, acc.: 67.19%] [G loss: 1.021040]\n",
            "498 [D loss: 0.683644, acc.: 43.75%] [G loss: 0.963253]\n",
            "499 [D loss: 0.561415, acc.: 70.31%] [G loss: 0.999103]\n",
            "500 [D loss: 0.562812, acc.: 68.75%] [G loss: 1.002214]\n",
            "generated_data\n",
            "501 [D loss: 0.547689, acc.: 67.19%] [G loss: 1.055518]\n",
            "502 [D loss: 0.544264, acc.: 67.19%] [G loss: 1.129893]\n",
            "503 [D loss: 0.523410, acc.: 71.88%] [G loss: 1.230995]\n",
            "504 [D loss: 0.529351, acc.: 71.88%] [G loss: 1.359551]\n",
            "505 [D loss: 0.552923, acc.: 60.94%] [G loss: 1.180291]\n",
            "506 [D loss: 0.560290, acc.: 68.75%] [G loss: 1.078598]\n",
            "507 [D loss: 0.616610, acc.: 57.81%] [G loss: 0.857306]\n",
            "508 [D loss: 0.562608, acc.: 64.06%] [G loss: 0.912422]\n",
            "509 [D loss: 0.546279, acc.: 70.31%] [G loss: 1.058028]\n",
            "510 [D loss: 0.529151, acc.: 70.31%] [G loss: 0.967656]\n",
            "511 [D loss: 0.544171, acc.: 68.75%] [G loss: 1.079653]\n",
            "512 [D loss: 0.512225, acc.: 70.31%] [G loss: 1.182930]\n",
            "513 [D loss: 0.518665, acc.: 68.75%] [G loss: 1.103168]\n",
            "514 [D loss: 0.481940, acc.: 73.44%] [G loss: 1.048656]\n",
            "515 [D loss: 0.471038, acc.: 79.69%] [G loss: 1.062573]\n",
            "516 [D loss: 0.555413, acc.: 73.44%] [G loss: 1.172774]\n",
            "517 [D loss: 0.667653, acc.: 59.38%] [G loss: 1.167465]\n",
            "518 [D loss: 0.583590, acc.: 68.75%] [G loss: 1.032543]\n",
            "519 [D loss: 0.593399, acc.: 65.62%] [G loss: 1.025111]\n",
            "520 [D loss: 0.595199, acc.: 67.19%] [G loss: 0.997772]\n",
            "521 [D loss: 0.571862, acc.: 62.50%] [G loss: 0.970091]\n",
            "522 [D loss: 0.544687, acc.: 64.06%] [G loss: 0.993849]\n",
            "523 [D loss: 0.577937, acc.: 59.38%] [G loss: 0.984457]\n",
            "524 [D loss: 0.554075, acc.: 70.31%] [G loss: 1.018788]\n",
            "525 [D loss: 0.524756, acc.: 70.31%] [G loss: 1.139921]\n",
            "526 [D loss: 0.593318, acc.: 64.06%] [G loss: 0.982327]\n",
            "527 [D loss: 0.627637, acc.: 53.12%] [G loss: 0.947326]\n",
            "528 [D loss: 0.615466, acc.: 59.38%] [G loss: 0.973108]\n",
            "529 [D loss: 0.552777, acc.: 68.75%] [G loss: 1.191670]\n",
            "530 [D loss: 0.550728, acc.: 64.06%] [G loss: 1.205315]\n",
            "531 [D loss: 0.556395, acc.: 67.19%] [G loss: 1.100450]\n",
            "532 [D loss: 0.564151, acc.: 67.19%] [G loss: 1.046718]\n",
            "533 [D loss: 0.590996, acc.: 64.06%] [G loss: 0.954492]\n",
            "534 [D loss: 0.593598, acc.: 60.94%] [G loss: 1.007041]\n",
            "535 [D loss: 0.571962, acc.: 67.19%] [G loss: 1.035595]\n",
            "536 [D loss: 0.592873, acc.: 64.06%] [G loss: 1.037381]\n",
            "537 [D loss: 0.571636, acc.: 64.06%] [G loss: 1.058823]\n",
            "538 [D loss: 0.574959, acc.: 65.62%] [G loss: 1.008957]\n",
            "539 [D loss: 0.537876, acc.: 68.75%] [G loss: 0.960198]\n",
            "540 [D loss: 0.552386, acc.: 70.31%] [G loss: 0.979490]\n",
            "541 [D loss: 0.546132, acc.: 67.19%] [G loss: 0.915361]\n",
            "542 [D loss: 0.598786, acc.: 60.94%] [G loss: 0.963711]\n",
            "543 [D loss: 0.547961, acc.: 67.19%] [G loss: 1.078368]\n",
            "544 [D loss: 0.570116, acc.: 62.50%] [G loss: 0.917099]\n",
            "545 [D loss: 0.573630, acc.: 57.81%] [G loss: 0.985113]\n",
            "546 [D loss: 0.650423, acc.: 57.81%] [G loss: 0.986881]\n",
            "547 [D loss: 0.549066, acc.: 71.88%] [G loss: 1.030589]\n",
            "548 [D loss: 0.591876, acc.: 67.19%] [G loss: 1.009584]\n",
            "549 [D loss: 0.543164, acc.: 71.88%] [G loss: 1.019212]\n",
            "550 [D loss: 0.561698, acc.: 68.75%] [G loss: 1.082469]\n",
            "551 [D loss: 0.560803, acc.: 68.75%] [G loss: 1.033171]\n",
            "552 [D loss: 0.571139, acc.: 75.00%] [G loss: 0.962740]\n",
            "553 [D loss: 0.573648, acc.: 73.44%] [G loss: 1.054705]\n",
            "554 [D loss: 0.584612, acc.: 65.62%] [G loss: 0.995862]\n",
            "555 [D loss: 0.544190, acc.: 67.19%] [G loss: 0.903057]\n",
            "556 [D loss: 0.598668, acc.: 62.50%] [G loss: 1.040669]\n",
            "557 [D loss: 0.563590, acc.: 62.50%] [G loss: 1.042827]\n",
            "558 [D loss: 0.554455, acc.: 70.31%] [G loss: 1.051610]\n",
            "559 [D loss: 0.575499, acc.: 62.50%] [G loss: 1.044956]\n",
            "560 [D loss: 0.623271, acc.: 56.25%] [G loss: 0.999898]\n",
            "561 [D loss: 0.574614, acc.: 67.19%] [G loss: 1.002371]\n",
            "562 [D loss: 0.545992, acc.: 68.75%] [G loss: 0.940789]\n",
            "563 [D loss: 0.569376, acc.: 64.06%] [G loss: 0.986869]\n",
            "564 [D loss: 0.567336, acc.: 62.50%] [G loss: 0.996051]\n",
            "565 [D loss: 0.536894, acc.: 70.31%] [G loss: 0.948611]\n",
            "566 [D loss: 0.544002, acc.: 70.31%] [G loss: 0.914806]\n",
            "567 [D loss: 0.541831, acc.: 68.75%] [G loss: 0.920258]\n",
            "568 [D loss: 0.563285, acc.: 67.19%] [G loss: 0.919799]\n",
            "569 [D loss: 0.559964, acc.: 64.06%] [G loss: 1.002759]\n",
            "570 [D loss: 0.586834, acc.: 67.19%] [G loss: 1.004948]\n",
            "571 [D loss: 0.552364, acc.: 65.62%] [G loss: 1.048368]\n",
            "572 [D loss: 0.639804, acc.: 64.06%] [G loss: 0.914098]\n",
            "573 [D loss: 0.584694, acc.: 64.06%] [G loss: 0.943438]\n",
            "574 [D loss: 0.552407, acc.: 64.06%] [G loss: 1.007822]\n",
            "575 [D loss: 0.601168, acc.: 60.94%] [G loss: 1.002730]\n",
            "576 [D loss: 0.586396, acc.: 65.62%] [G loss: 0.903811]\n",
            "577 [D loss: 0.614007, acc.: 54.69%] [G loss: 0.961430]\n",
            "578 [D loss: 0.595631, acc.: 59.38%] [G loss: 0.974662]\n",
            "579 [D loss: 0.636577, acc.: 64.06%] [G loss: 0.945476]\n",
            "580 [D loss: 0.664619, acc.: 56.25%] [G loss: 0.934343]\n",
            "581 [D loss: 0.683991, acc.: 56.25%] [G loss: 1.060861]\n",
            "582 [D loss: 0.661010, acc.: 57.81%] [G loss: 1.016111]\n",
            "583 [D loss: 0.659308, acc.: 59.38%] [G loss: 1.079446]\n",
            "584 [D loss: 0.595751, acc.: 62.50%] [G loss: 1.250304]\n",
            "585 [D loss: 0.595270, acc.: 65.62%] [G loss: 1.081448]\n",
            "586 [D loss: 0.570194, acc.: 68.75%] [G loss: 1.052863]\n",
            "587 [D loss: 0.568955, acc.: 67.19%] [G loss: 0.959143]\n",
            "588 [D loss: 0.605243, acc.: 57.81%] [G loss: 0.849823]\n",
            "589 [D loss: 0.615884, acc.: 62.50%] [G loss: 0.922386]\n",
            "590 [D loss: 0.664531, acc.: 51.56%] [G loss: 0.985926]\n",
            "591 [D loss: 0.613674, acc.: 60.94%] [G loss: 0.999902]\n",
            "592 [D loss: 0.615886, acc.: 62.50%] [G loss: 0.939268]\n",
            "593 [D loss: 0.614332, acc.: 65.62%] [G loss: 0.937395]\n",
            "594 [D loss: 0.630222, acc.: 56.25%] [G loss: 1.009486]\n",
            "595 [D loss: 0.610974, acc.: 60.94%] [G loss: 0.996217]\n",
            "596 [D loss: 0.609831, acc.: 57.81%] [G loss: 1.065458]\n",
            "597 [D loss: 0.632251, acc.: 59.38%] [G loss: 0.917891]\n",
            "598 [D loss: 0.620231, acc.: 59.38%] [G loss: 0.919475]\n",
            "599 [D loss: 0.616577, acc.: 59.38%] [G loss: 0.899336]\n",
            "600 [D loss: 0.617557, acc.: 59.38%] [G loss: 0.986484]\n",
            "generated_data\n",
            "601 [D loss: 0.592777, acc.: 62.50%] [G loss: 0.995762]\n",
            "602 [D loss: 0.592990, acc.: 62.50%] [G loss: 0.945426]\n",
            "603 [D loss: 0.591647, acc.: 64.06%] [G loss: 0.971242]\n",
            "604 [D loss: 0.584999, acc.: 65.62%] [G loss: 0.973025]\n",
            "605 [D loss: 0.598189, acc.: 60.94%] [G loss: 0.951670]\n",
            "606 [D loss: 0.606522, acc.: 60.94%] [G loss: 0.959897]\n",
            "607 [D loss: 0.602759, acc.: 60.94%] [G loss: 0.951953]\n",
            "608 [D loss: 0.614845, acc.: 59.38%] [G loss: 0.974347]\n",
            "609 [D loss: 0.598117, acc.: 60.94%] [G loss: 0.959670]\n",
            "610 [D loss: 0.621538, acc.: 57.81%] [G loss: 0.963161]\n",
            "611 [D loss: 0.617184, acc.: 56.25%] [G loss: 0.980375]\n",
            "612 [D loss: 0.596228, acc.: 60.94%] [G loss: 0.928612]\n",
            "613 [D loss: 0.598182, acc.: 59.38%] [G loss: 1.003672]\n",
            "614 [D loss: 0.582712, acc.: 64.06%] [G loss: 0.990550]\n",
            "615 [D loss: 0.608655, acc.: 59.38%] [G loss: 0.955521]\n",
            "616 [D loss: 0.603450, acc.: 64.06%] [G loss: 0.939960]\n",
            "617 [D loss: 0.594592, acc.: 62.50%] [G loss: 0.924243]\n",
            "618 [D loss: 0.615626, acc.: 57.81%] [G loss: 0.945833]\n",
            "619 [D loss: 0.637698, acc.: 57.81%] [G loss: 0.984264]\n",
            "620 [D loss: 0.604202, acc.: 59.38%] [G loss: 1.040334]\n",
            "621 [D loss: 0.607778, acc.: 64.06%] [G loss: 1.022168]\n",
            "622 [D loss: 0.615363, acc.: 60.94%] [G loss: 1.002770]\n",
            "623 [D loss: 0.602575, acc.: 60.94%] [G loss: 1.069028]\n",
            "624 [D loss: 0.591346, acc.: 62.50%] [G loss: 1.030400]\n",
            "625 [D loss: 0.576176, acc.: 62.50%] [G loss: 1.028803]\n",
            "626 [D loss: 0.613514, acc.: 59.38%] [G loss: 1.011150]\n",
            "627 [D loss: 0.616394, acc.: 62.50%] [G loss: 0.988592]\n",
            "628 [D loss: 0.608744, acc.: 62.50%] [G loss: 0.968331]\n",
            "629 [D loss: 0.596661, acc.: 60.94%] [G loss: 0.970552]\n",
            "630 [D loss: 0.600788, acc.: 62.50%] [G loss: 0.977512]\n",
            "631 [D loss: 0.611772, acc.: 62.50%] [G loss: 0.962636]\n",
            "632 [D loss: 0.609357, acc.: 60.94%] [G loss: 0.931896]\n",
            "633 [D loss: 0.585741, acc.: 62.50%] [G loss: 0.974780]\n",
            "634 [D loss: 0.596285, acc.: 59.38%] [G loss: 0.903814]\n",
            "635 [D loss: 0.607683, acc.: 57.81%] [G loss: 0.926739]\n",
            "636 [D loss: 0.600209, acc.: 64.06%] [G loss: 0.964535]\n",
            "637 [D loss: 0.607700, acc.: 57.81%] [G loss: 0.982210]\n",
            "638 [D loss: 0.584399, acc.: 62.50%] [G loss: 1.029593]\n",
            "639 [D loss: 0.595941, acc.: 64.06%] [G loss: 0.960752]\n",
            "640 [D loss: 0.617157, acc.: 57.81%] [G loss: 0.931113]\n",
            "641 [D loss: 0.594043, acc.: 62.50%] [G loss: 0.936967]\n",
            "642 [D loss: 0.595478, acc.: 62.50%] [G loss: 0.911875]\n",
            "643 [D loss: 0.601495, acc.: 57.81%] [G loss: 0.953194]\n",
            "644 [D loss: 0.604476, acc.: 59.38%] [G loss: 0.949290]\n",
            "645 [D loss: 0.598269, acc.: 60.94%] [G loss: 0.904625]\n",
            "646 [D loss: 0.739149, acc.: 42.19%] [G loss: 0.941253]\n",
            "647 [D loss: 0.636312, acc.: 59.38%] [G loss: 0.991504]\n",
            "648 [D loss: 0.603345, acc.: 65.62%] [G loss: 0.962587]\n",
            "649 [D loss: 0.605908, acc.: 59.38%] [G loss: 0.981477]\n",
            "650 [D loss: 0.619266, acc.: 59.38%] [G loss: 0.999720]\n",
            "651 [D loss: 0.611066, acc.: 62.50%] [G loss: 0.980294]\n",
            "652 [D loss: 0.613498, acc.: 60.94%] [G loss: 0.999274]\n",
            "653 [D loss: 0.601096, acc.: 64.06%] [G loss: 0.982489]\n",
            "654 [D loss: 0.612329, acc.: 62.50%] [G loss: 1.018251]\n",
            "655 [D loss: 0.601880, acc.: 62.50%] [G loss: 1.030899]\n",
            "656 [D loss: 0.609673, acc.: 64.06%] [G loss: 0.989989]\n",
            "657 [D loss: 0.595528, acc.: 64.06%] [G loss: 0.966642]\n",
            "658 [D loss: 0.601112, acc.: 64.06%] [G loss: 0.980393]\n",
            "659 [D loss: 0.600193, acc.: 64.06%] [G loss: 0.979508]\n",
            "660 [D loss: 0.592403, acc.: 64.06%] [G loss: 0.992440]\n",
            "661 [D loss: 0.597498, acc.: 64.06%] [G loss: 0.988533]\n",
            "662 [D loss: 0.600003, acc.: 62.50%] [G loss: 0.965411]\n",
            "663 [D loss: 0.606058, acc.: 62.50%] [G loss: 0.992407]\n",
            "664 [D loss: 0.599039, acc.: 62.50%] [G loss: 0.972332]\n",
            "665 [D loss: 0.586925, acc.: 64.06%] [G loss: 0.984444]\n",
            "666 [D loss: 0.592038, acc.: 62.50%] [G loss: 0.981771]\n",
            "667 [D loss: 0.600344, acc.: 59.38%] [G loss: 0.993394]\n",
            "668 [D loss: 0.601528, acc.: 62.50%] [G loss: 0.955187]\n",
            "669 [D loss: 0.599113, acc.: 62.50%] [G loss: 0.936620]\n",
            "670 [D loss: 0.590517, acc.: 67.19%] [G loss: 0.956863]\n",
            "671 [D loss: 0.609600, acc.: 60.94%] [G loss: 0.950223]\n",
            "672 [D loss: 0.596775, acc.: 59.38%] [G loss: 0.970428]\n",
            "673 [D loss: 0.603623, acc.: 59.38%] [G loss: 0.960643]\n",
            "674 [D loss: 0.614183, acc.: 57.81%] [G loss: 1.002675]\n",
            "675 [D loss: 0.592797, acc.: 64.06%] [G loss: 1.015141]\n",
            "676 [D loss: 0.592948, acc.: 64.06%] [G loss: 1.039076]\n",
            "677 [D loss: 0.605869, acc.: 64.06%] [G loss: 1.003786]\n",
            "678 [D loss: 0.597286, acc.: 64.06%] [G loss: 0.975266]\n",
            "679 [D loss: 0.615866, acc.: 60.94%] [G loss: 1.029277]\n",
            "680 [D loss: 0.606089, acc.: 64.06%] [G loss: 0.978657]\n",
            "681 [D loss: 0.603499, acc.: 64.06%] [G loss: 1.005675]\n",
            "682 [D loss: 0.596362, acc.: 62.50%] [G loss: 0.991391]\n",
            "683 [D loss: 0.599053, acc.: 62.50%] [G loss: 1.004459]\n",
            "684 [D loss: 0.587454, acc.: 62.50%] [G loss: 1.099659]\n",
            "685 [D loss: 0.623453, acc.: 60.94%] [G loss: 0.933200]\n",
            "686 [D loss: 0.596540, acc.: 62.50%] [G loss: 0.974053]\n",
            "687 [D loss: 0.592235, acc.: 60.94%] [G loss: 0.986604]\n",
            "688 [D loss: 0.592680, acc.: 62.50%] [G loss: 1.026642]\n",
            "689 [D loss: 0.593561, acc.: 60.94%] [G loss: 1.067777]\n",
            "690 [D loss: 0.594329, acc.: 62.50%] [G loss: 1.033992]\n",
            "691 [D loss: 0.625477, acc.: 56.25%] [G loss: 0.996787]\n",
            "692 [D loss: 0.603935, acc.: 57.81%] [G loss: 0.946799]\n",
            "693 [D loss: 0.621770, acc.: 54.69%] [G loss: 1.007453]\n",
            "694 [D loss: 0.594636, acc.: 64.06%] [G loss: 0.961127]\n",
            "695 [D loss: 0.599427, acc.: 62.50%] [G loss: 0.977703]\n",
            "696 [D loss: 0.593710, acc.: 62.50%] [G loss: 0.942771]\n",
            "697 [D loss: 0.606226, acc.: 62.50%] [G loss: 0.908003]\n",
            "698 [D loss: 0.592139, acc.: 64.06%] [G loss: 0.941713]\n",
            "699 [D loss: 0.593380, acc.: 64.06%] [G loss: 0.954144]\n",
            "700 [D loss: 0.608653, acc.: 59.38%] [G loss: 0.946666]\n",
            "generated_data\n",
            "701 [D loss: 0.597120, acc.: 62.50%] [G loss: 0.878929]\n",
            "702 [D loss: 0.608259, acc.: 62.50%] [G loss: 0.954927]\n",
            "703 [D loss: 0.593813, acc.: 64.06%] [G loss: 0.965950]\n",
            "704 [D loss: 0.593047, acc.: 64.06%] [G loss: 0.968572]\n",
            "705 [D loss: 0.591615, acc.: 64.06%] [G loss: 0.966398]\n",
            "706 [D loss: 0.595185, acc.: 59.38%] [G loss: 0.962920]\n",
            "707 [D loss: 0.581267, acc.: 65.62%] [G loss: 0.967833]\n",
            "708 [D loss: 0.568682, acc.: 65.62%] [G loss: 1.061413]\n",
            "709 [D loss: 0.573737, acc.: 65.62%] [G loss: 1.096653]\n",
            "710 [D loss: 0.609564, acc.: 64.06%] [G loss: 0.967687]\n",
            "711 [D loss: 0.613797, acc.: 64.06%] [G loss: 1.000325]\n",
            "712 [D loss: 0.585135, acc.: 65.62%] [G loss: 0.983812]\n",
            "713 [D loss: 0.589200, acc.: 64.06%] [G loss: 0.989452]\n",
            "714 [D loss: 0.602676, acc.: 64.06%] [G loss: 0.954765]\n",
            "715 [D loss: 0.597534, acc.: 62.50%] [G loss: 0.954743]\n",
            "716 [D loss: 0.587455, acc.: 65.62%] [G loss: 0.987997]\n",
            "717 [D loss: 0.577135, acc.: 65.62%] [G loss: 0.973108]\n",
            "718 [D loss: 0.575816, acc.: 65.62%] [G loss: 0.960956]\n",
            "719 [D loss: 0.582460, acc.: 62.50%] [G loss: 0.953468]\n",
            "720 [D loss: 0.589077, acc.: 65.62%] [G loss: 0.962643]\n",
            "721 [D loss: 0.593591, acc.: 64.06%] [G loss: 0.952609]\n",
            "722 [D loss: 0.588722, acc.: 62.50%] [G loss: 0.984299]\n",
            "723 [D loss: 0.587748, acc.: 64.06%] [G loss: 1.012514]\n",
            "724 [D loss: 0.597117, acc.: 62.50%] [G loss: 0.920926]\n",
            "725 [D loss: 0.582644, acc.: 64.06%] [G loss: 0.918710]\n",
            "726 [D loss: 0.581033, acc.: 64.06%] [G loss: 0.959159]\n",
            "727 [D loss: 0.578703, acc.: 64.06%] [G loss: 0.938935]\n",
            "728 [D loss: 0.585845, acc.: 64.06%] [G loss: 0.971369]\n",
            "729 [D loss: 0.580935, acc.: 64.06%] [G loss: 0.965950]\n",
            "730 [D loss: 0.571511, acc.: 60.94%] [G loss: 1.014101]\n",
            "731 [D loss: 0.580196, acc.: 64.06%] [G loss: 1.093520]\n",
            "732 [D loss: 0.575694, acc.: 65.62%] [G loss: 1.133753]\n",
            "733 [D loss: 0.621189, acc.: 60.94%] [G loss: 1.045825]\n",
            "734 [D loss: 0.608639, acc.: 62.50%] [G loss: 1.043430]\n",
            "735 [D loss: 0.604685, acc.: 60.94%] [G loss: 1.054041]\n",
            "736 [D loss: 0.577298, acc.: 64.06%] [G loss: 0.989555]\n",
            "737 [D loss: 0.597809, acc.: 64.06%] [G loss: 0.972416]\n",
            "738 [D loss: 0.582086, acc.: 68.75%] [G loss: 1.070802]\n",
            "739 [D loss: 0.568338, acc.: 65.62%] [G loss: 1.017561]\n",
            "740 [D loss: 0.610064, acc.: 60.94%] [G loss: 1.021718]\n",
            "741 [D loss: 0.598788, acc.: 60.94%] [G loss: 0.970426]\n",
            "742 [D loss: 0.619450, acc.: 62.50%] [G loss: 0.976968]\n",
            "743 [D loss: 0.588406, acc.: 60.94%] [G loss: 0.979298]\n",
            "744 [D loss: 0.597167, acc.: 64.06%] [G loss: 0.971425]\n",
            "745 [D loss: 0.599090, acc.: 62.50%] [G loss: 1.018823]\n",
            "746 [D loss: 0.572046, acc.: 64.06%] [G loss: 0.999634]\n",
            "747 [D loss: 0.584604, acc.: 65.62%] [G loss: 0.971146]\n",
            "748 [D loss: 0.590442, acc.: 62.50%] [G loss: 0.951964]\n",
            "749 [D loss: 0.578278, acc.: 65.62%] [G loss: 0.963733]\n",
            "750 [D loss: 0.582690, acc.: 64.06%] [G loss: 0.923208]\n",
            "751 [D loss: 0.591658, acc.: 62.50%] [G loss: 0.927461]\n",
            "752 [D loss: 0.569415, acc.: 68.75%] [G loss: 0.932233]\n",
            "753 [D loss: 0.605697, acc.: 62.50%] [G loss: 0.902418]\n",
            "754 [D loss: 0.593335, acc.: 62.50%] [G loss: 0.962187]\n",
            "755 [D loss: 0.608054, acc.: 60.94%] [G loss: 0.917229]\n",
            "756 [D loss: 0.588824, acc.: 62.50%] [G loss: 0.928304]\n",
            "757 [D loss: 0.584047, acc.: 64.06%] [G loss: 0.947513]\n",
            "758 [D loss: 0.578519, acc.: 64.06%] [G loss: 0.962346]\n",
            "759 [D loss: 0.580401, acc.: 62.50%] [G loss: 1.008565]\n",
            "760 [D loss: 0.583806, acc.: 64.06%] [G loss: 1.023824]\n",
            "761 [D loss: 0.604885, acc.: 60.94%] [G loss: 0.972042]\n",
            "762 [D loss: 0.593386, acc.: 62.50%] [G loss: 0.961092]\n",
            "763 [D loss: 0.585581, acc.: 65.62%] [G loss: 1.019451]\n",
            "764 [D loss: 0.573761, acc.: 64.06%] [G loss: 0.938119]\n",
            "765 [D loss: 0.607735, acc.: 64.06%] [G loss: 0.946038]\n",
            "766 [D loss: 0.566675, acc.: 67.19%] [G loss: 1.000777]\n",
            "767 [D loss: 0.595744, acc.: 64.06%] [G loss: 0.978402]\n",
            "768 [D loss: 0.584145, acc.: 64.06%] [G loss: 1.026756]\n",
            "769 [D loss: 0.587707, acc.: 65.62%] [G loss: 1.044686]\n",
            "770 [D loss: 0.594180, acc.: 64.06%] [G loss: 0.894343]\n",
            "771 [D loss: 0.610379, acc.: 57.81%] [G loss: 1.011691]\n",
            "772 [D loss: 0.583299, acc.: 62.50%] [G loss: 0.987712]\n",
            "773 [D loss: 0.565286, acc.: 62.50%] [G loss: 0.994673]\n",
            "774 [D loss: 0.579009, acc.: 64.06%] [G loss: 0.999443]\n",
            "775 [D loss: 0.572824, acc.: 64.06%] [G loss: 0.999531]\n",
            "776 [D loss: 0.589420, acc.: 57.81%] [G loss: 1.095399]\n",
            "777 [D loss: 0.600241, acc.: 62.50%] [G loss: 0.967026]\n",
            "778 [D loss: 0.599082, acc.: 64.06%] [G loss: 0.959803]\n",
            "779 [D loss: 0.597318, acc.: 60.94%] [G loss: 0.928762]\n",
            "780 [D loss: 0.585628, acc.: 62.50%] [G loss: 0.931669]\n",
            "781 [D loss: 0.601715, acc.: 64.06%] [G loss: 0.893609]\n",
            "782 [D loss: 0.590929, acc.: 62.50%] [G loss: 0.933654]\n",
            "783 [D loss: 0.603424, acc.: 64.06%] [G loss: 0.912927]\n",
            "784 [D loss: 0.578116, acc.: 65.62%] [G loss: 0.935234]\n",
            "785 [D loss: 0.578595, acc.: 62.50%] [G loss: 0.992732]\n",
            "786 [D loss: 0.583760, acc.: 64.06%] [G loss: 0.937721]\n",
            "787 [D loss: 0.598714, acc.: 67.19%] [G loss: 0.967750]\n",
            "788 [D loss: 0.587842, acc.: 62.50%] [G loss: 0.986750]\n",
            "789 [D loss: 0.592513, acc.: 64.06%] [G loss: 0.949134]\n",
            "790 [D loss: 0.597974, acc.: 60.94%] [G loss: 0.986613]\n",
            "791 [D loss: 0.577691, acc.: 64.06%] [G loss: 0.937429]\n",
            "792 [D loss: 0.597040, acc.: 62.50%] [G loss: 0.967915]\n",
            "793 [D loss: 0.580016, acc.: 64.06%] [G loss: 0.934257]\n",
            "794 [D loss: 0.585574, acc.: 64.06%] [G loss: 0.946979]\n",
            "795 [D loss: 0.591206, acc.: 64.06%] [G loss: 0.928155]\n",
            "796 [D loss: 0.605955, acc.: 62.50%] [G loss: 0.935572]\n",
            "797 [D loss: 0.602522, acc.: 64.06%] [G loss: 1.019868]\n",
            "798 [D loss: 0.611256, acc.: 64.06%] [G loss: 0.978954]\n",
            "799 [D loss: 0.584438, acc.: 64.06%] [G loss: 0.965960]\n",
            "800 [D loss: 0.576773, acc.: 64.06%] [G loss: 0.928488]\n",
            "generated_data\n",
            "801 [D loss: 0.761191, acc.: 56.25%] [G loss: 1.031389]\n",
            "802 [D loss: 0.591120, acc.: 67.19%] [G loss: 0.932433]\n",
            "803 [D loss: 0.615330, acc.: 60.94%] [G loss: 0.913690]\n",
            "804 [D loss: 0.598460, acc.: 67.19%] [G loss: 1.011416]\n",
            "805 [D loss: 0.592458, acc.: 67.19%] [G loss: 0.904570]\n",
            "806 [D loss: 0.592886, acc.: 65.62%] [G loss: 0.917068]\n",
            "807 [D loss: 0.629586, acc.: 62.50%] [G loss: 0.899312]\n",
            "808 [D loss: 0.614108, acc.: 59.38%] [G loss: 0.881419]\n",
            "809 [D loss: 0.597793, acc.: 64.06%] [G loss: 0.903842]\n",
            "810 [D loss: 0.598794, acc.: 64.06%] [G loss: 0.897807]\n",
            "811 [D loss: 0.596961, acc.: 62.50%] [G loss: 0.905836]\n",
            "812 [D loss: 0.608419, acc.: 57.81%] [G loss: 0.895937]\n",
            "813 [D loss: 0.615622, acc.: 59.38%] [G loss: 0.871011]\n",
            "814 [D loss: 0.594046, acc.: 62.50%] [G loss: 0.922450]\n",
            "815 [D loss: 0.606861, acc.: 59.38%] [G loss: 0.873689]\n",
            "816 [D loss: 0.608584, acc.: 60.94%] [G loss: 0.896325]\n",
            "817 [D loss: 0.611589, acc.: 60.94%] [G loss: 0.880092]\n",
            "818 [D loss: 0.606399, acc.: 57.81%] [G loss: 0.901585]\n",
            "819 [D loss: 0.619204, acc.: 60.94%] [G loss: 0.919450]\n",
            "820 [D loss: 0.604460, acc.: 54.69%] [G loss: 0.997325]\n",
            "821 [D loss: 0.597892, acc.: 62.50%] [G loss: 1.074684]\n",
            "822 [D loss: 0.619881, acc.: 60.94%] [G loss: 0.970562]\n",
            "823 [D loss: 0.611705, acc.: 62.50%] [G loss: 0.967044]\n",
            "824 [D loss: 0.607217, acc.: 62.50%] [G loss: 0.947888]\n",
            "825 [D loss: 0.603068, acc.: 62.50%] [G loss: 0.954337]\n",
            "826 [D loss: 0.590130, acc.: 62.50%] [G loss: 0.986848]\n",
            "827 [D loss: 0.588248, acc.: 62.50%] [G loss: 0.982631]\n",
            "828 [D loss: 0.611194, acc.: 60.94%] [G loss: 0.953092]\n",
            "829 [D loss: 0.598347, acc.: 62.50%] [G loss: 0.953251]\n",
            "830 [D loss: 0.605650, acc.: 62.50%] [G loss: 0.907755]\n",
            "831 [D loss: 0.598370, acc.: 62.50%] [G loss: 0.902405]\n",
            "832 [D loss: 0.608440, acc.: 60.94%] [G loss: 0.937813]\n",
            "833 [D loss: 0.601208, acc.: 60.94%] [G loss: 0.944263]\n",
            "834 [D loss: 0.599762, acc.: 62.50%] [G loss: 0.938065]\n",
            "835 [D loss: 0.599521, acc.: 62.50%] [G loss: 0.937575]\n",
            "836 [D loss: 0.597448, acc.: 62.50%] [G loss: 0.931824]\n",
            "837 [D loss: 0.613524, acc.: 62.50%] [G loss: 0.925533]\n",
            "838 [D loss: 0.608659, acc.: 62.50%] [G loss: 0.930304]\n",
            "839 [D loss: 0.599887, acc.: 62.50%] [G loss: 0.928265]\n",
            "840 [D loss: 0.597286, acc.: 60.94%] [G loss: 0.939303]\n",
            "841 [D loss: 0.599205, acc.: 62.50%] [G loss: 0.942496]\n",
            "842 [D loss: 0.600653, acc.: 62.50%] [G loss: 0.927176]\n",
            "843 [D loss: 0.594499, acc.: 62.50%] [G loss: 0.929396]\n",
            "844 [D loss: 0.594495, acc.: 62.50%] [G loss: 0.937932]\n",
            "845 [D loss: 0.603156, acc.: 62.50%] [G loss: 0.953126]\n",
            "846 [D loss: 0.607492, acc.: 62.50%] [G loss: 0.943751]\n",
            "847 [D loss: 0.603117, acc.: 62.50%] [G loss: 0.913563]\n",
            "848 [D loss: 0.593808, acc.: 62.50%] [G loss: 0.933710]\n",
            "849 [D loss: 0.604450, acc.: 62.50%] [G loss: 0.961493]\n",
            "850 [D loss: 0.615031, acc.: 62.50%] [G loss: 0.902524]\n",
            "851 [D loss: 0.607794, acc.: 62.50%] [G loss: 0.911801]\n",
            "852 [D loss: 0.607602, acc.: 62.50%] [G loss: 0.918708]\n",
            "853 [D loss: 0.597307, acc.: 62.50%] [G loss: 0.923399]\n",
            "854 [D loss: 0.587567, acc.: 64.06%] [G loss: 0.965056]\n",
            "855 [D loss: 0.596034, acc.: 64.06%] [G loss: 0.944914]\n",
            "856 [D loss: 0.589574, acc.: 64.06%] [G loss: 0.922401]\n",
            "857 [D loss: 0.625891, acc.: 57.81%] [G loss: 0.948708]\n",
            "858 [D loss: 0.599516, acc.: 62.50%] [G loss: 0.963245]\n",
            "859 [D loss: 0.602650, acc.: 62.50%] [G loss: 0.935548]\n",
            "860 [D loss: 0.601748, acc.: 62.50%] [G loss: 0.944667]\n",
            "861 [D loss: 0.605931, acc.: 62.50%] [G loss: 0.934305]\n",
            "862 [D loss: 0.599437, acc.: 62.50%] [G loss: 0.946576]\n",
            "863 [D loss: 0.601270, acc.: 62.50%] [G loss: 0.925171]\n",
            "864 [D loss: 0.606297, acc.: 60.94%] [G loss: 0.905319]\n",
            "865 [D loss: 0.602255, acc.: 62.50%] [G loss: 0.926659]\n",
            "866 [D loss: 0.600152, acc.: 62.50%] [G loss: 0.897290]\n",
            "867 [D loss: 0.602833, acc.: 64.06%] [G loss: 0.911791]\n",
            "868 [D loss: 0.586531, acc.: 62.50%] [G loss: 0.922869]\n",
            "869 [D loss: 0.602703, acc.: 60.94%] [G loss: 0.914944]\n",
            "870 [D loss: 0.611050, acc.: 60.94%] [G loss: 0.918622]\n",
            "871 [D loss: 0.607970, acc.: 62.50%] [G loss: 0.897354]\n",
            "872 [D loss: 0.583960, acc.: 65.62%] [G loss: 0.950783]\n",
            "873 [D loss: 0.614521, acc.: 60.94%] [G loss: 0.924128]\n",
            "874 [D loss: 0.592245, acc.: 64.06%] [G loss: 0.913956]\n",
            "875 [D loss: 0.600083, acc.: 64.06%] [G loss: 0.925629]\n",
            "876 [D loss: 0.601525, acc.: 62.50%] [G loss: 0.973119]\n",
            "877 [D loss: 0.588993, acc.: 64.06%] [G loss: 0.951284]\n",
            "878 [D loss: 0.603069, acc.: 64.06%] [G loss: 0.944044]\n",
            "879 [D loss: 0.595340, acc.: 62.50%] [G loss: 0.923811]\n",
            "880 [D loss: 0.595475, acc.: 65.62%] [G loss: 0.939997]\n",
            "881 [D loss: 0.590300, acc.: 65.62%] [G loss: 0.907040]\n",
            "882 [D loss: 0.590009, acc.: 64.06%] [G loss: 0.910815]\n",
            "883 [D loss: 0.588145, acc.: 65.62%] [G loss: 0.920173]\n",
            "884 [D loss: 0.582456, acc.: 64.06%] [G loss: 0.920959]\n",
            "885 [D loss: 0.592730, acc.: 64.06%] [G loss: 0.907007]\n",
            "886 [D loss: 0.587055, acc.: 64.06%] [G loss: 0.916812]\n",
            "887 [D loss: 0.585171, acc.: 64.06%] [G loss: 0.893609]\n",
            "888 [D loss: 0.585692, acc.: 64.06%] [G loss: 0.911904]\n",
            "889 [D loss: 0.595142, acc.: 64.06%] [G loss: 0.882260]\n",
            "890 [D loss: 0.578903, acc.: 67.19%] [G loss: 0.870316]\n",
            "891 [D loss: 0.596705, acc.: 64.06%] [G loss: 0.857117]\n",
            "892 [D loss: 0.622562, acc.: 57.81%] [G loss: 0.904579]\n",
            "893 [D loss: 0.585469, acc.: 65.62%] [G loss: 0.883826]\n",
            "894 [D loss: 0.584289, acc.: 64.06%] [G loss: 0.905040]\n",
            "895 [D loss: 0.583072, acc.: 62.50%] [G loss: 0.916790]\n",
            "896 [D loss: 0.574320, acc.: 65.62%] [G loss: 0.880146]\n",
            "897 [D loss: 0.600616, acc.: 62.50%] [G loss: 0.871133]\n",
            "898 [D loss: 0.588040, acc.: 64.06%] [G loss: 0.860460]\n",
            "899 [D loss: 0.589297, acc.: 65.62%] [G loss: 0.855122]\n",
            "900 [D loss: 0.592243, acc.: 65.62%] [G loss: 0.872616]\n",
            "generated_data\n",
            "901 [D loss: 0.578725, acc.: 65.62%] [G loss: 0.931773]\n",
            "902 [D loss: 0.592821, acc.: 67.19%] [G loss: 0.869418]\n",
            "903 [D loss: 0.579955, acc.: 62.50%] [G loss: 0.853047]\n",
            "904 [D loss: 0.571194, acc.: 65.62%] [G loss: 0.918420]\n",
            "905 [D loss: 0.592079, acc.: 64.06%] [G loss: 0.897406]\n",
            "906 [D loss: 0.592233, acc.: 60.94%] [G loss: 0.905417]\n",
            "907 [D loss: 0.595361, acc.: 65.62%] [G loss: 0.894926]\n",
            "908 [D loss: 0.614720, acc.: 62.50%] [G loss: 0.886679]\n",
            "909 [D loss: 0.606311, acc.: 64.06%] [G loss: 0.912083]\n",
            "910 [D loss: 0.575962, acc.: 62.50%] [G loss: 0.927095]\n",
            "911 [D loss: 0.595379, acc.: 64.06%] [G loss: 0.910693]\n",
            "912 [D loss: 0.592037, acc.: 64.06%] [G loss: 0.890405]\n",
            "913 [D loss: 0.600027, acc.: 64.06%] [G loss: 0.912819]\n",
            "914 [D loss: 0.584527, acc.: 65.62%] [G loss: 0.933275]\n",
            "915 [D loss: 0.576804, acc.: 64.06%] [G loss: 0.969439]\n",
            "916 [D loss: 0.572122, acc.: 64.06%] [G loss: 0.932168]\n",
            "917 [D loss: 0.591649, acc.: 62.50%] [G loss: 1.020502]\n",
            "918 [D loss: 0.577230, acc.: 64.06%] [G loss: 0.961904]\n",
            "919 [D loss: 0.606396, acc.: 65.62%] [G loss: 0.925427]\n",
            "920 [D loss: 0.586962, acc.: 64.06%] [G loss: 0.945142]\n",
            "921 [D loss: 0.567075, acc.: 65.62%] [G loss: 0.925507]\n",
            "922 [D loss: 0.577613, acc.: 65.62%] [G loss: 0.894809]\n",
            "923 [D loss: 0.587196, acc.: 65.62%] [G loss: 0.921591]\n",
            "924 [D loss: 0.619919, acc.: 60.94%] [G loss: 0.930345]\n",
            "925 [D loss: 0.590706, acc.: 64.06%] [G loss: 0.903470]\n",
            "926 [D loss: 0.598131, acc.: 64.06%] [G loss: 0.903760]\n",
            "927 [D loss: 0.598768, acc.: 64.06%] [G loss: 0.946259]\n",
            "928 [D loss: 0.586926, acc.: 64.06%] [G loss: 0.915023]\n",
            "929 [D loss: 0.582647, acc.: 64.06%] [G loss: 0.903970]\n",
            "930 [D loss: 0.592517, acc.: 65.62%] [G loss: 0.885190]\n",
            "931 [D loss: 0.574801, acc.: 65.62%] [G loss: 0.903156]\n",
            "932 [D loss: 0.588540, acc.: 62.50%] [G loss: 0.911075]\n",
            "933 [D loss: 0.576613, acc.: 62.50%] [G loss: 0.903184]\n",
            "934 [D loss: 0.587115, acc.: 64.06%] [G loss: 0.881743]\n",
            "935 [D loss: 0.591606, acc.: 62.50%] [G loss: 0.876632]\n",
            "936 [D loss: 0.583446, acc.: 64.06%] [G loss: 0.874006]\n",
            "937 [D loss: 0.585896, acc.: 64.06%] [G loss: 0.860563]\n",
            "938 [D loss: 0.585584, acc.: 60.94%] [G loss: 0.857743]\n",
            "939 [D loss: 0.638322, acc.: 59.38%] [G loss: 0.879427]\n",
            "940 [D loss: 0.586697, acc.: 62.50%] [G loss: 0.858173]\n",
            "941 [D loss: 0.605611, acc.: 62.50%] [G loss: 0.856171]\n",
            "942 [D loss: 0.590914, acc.: 64.06%] [G loss: 0.870796]\n",
            "943 [D loss: 0.591351, acc.: 64.06%] [G loss: 0.874724]\n",
            "944 [D loss: 0.587524, acc.: 64.06%] [G loss: 0.911192]\n",
            "945 [D loss: 0.600299, acc.: 59.38%] [G loss: 0.937423]\n",
            "946 [D loss: 0.595870, acc.: 64.06%] [G loss: 0.906016]\n",
            "947 [D loss: 0.622356, acc.: 56.25%] [G loss: 0.895448]\n",
            "948 [D loss: 0.605243, acc.: 59.38%] [G loss: 0.886722]\n",
            "949 [D loss: 0.605228, acc.: 62.50%] [G loss: 0.882078]\n",
            "950 [D loss: 0.603844, acc.: 62.50%] [G loss: 0.867422]\n",
            "951 [D loss: 0.584508, acc.: 62.50%] [G loss: 0.901109]\n",
            "952 [D loss: 0.584044, acc.: 62.50%] [G loss: 0.946838]\n",
            "953 [D loss: 0.590035, acc.: 64.06%] [G loss: 0.883136]\n",
            "954 [D loss: 0.615567, acc.: 60.94%] [G loss: 0.930444]\n",
            "955 [D loss: 0.596811, acc.: 65.62%] [G loss: 0.882132]\n",
            "956 [D loss: 0.596486, acc.: 62.50%] [G loss: 0.907099]\n",
            "957 [D loss: 0.585594, acc.: 62.50%] [G loss: 0.908118]\n",
            "958 [D loss: 0.585203, acc.: 64.06%] [G loss: 0.889694]\n",
            "959 [D loss: 0.595849, acc.: 64.06%] [G loss: 0.922394]\n",
            "960 [D loss: 0.590950, acc.: 65.62%] [G loss: 0.921896]\n",
            "961 [D loss: 0.594509, acc.: 62.50%] [G loss: 0.905484]\n",
            "962 [D loss: 0.586325, acc.: 65.62%] [G loss: 0.901667]\n",
            "963 [D loss: 0.587418, acc.: 62.50%] [G loss: 0.900090]\n",
            "964 [D loss: 0.588861, acc.: 64.06%] [G loss: 0.874804]\n",
            "965 [D loss: 0.594951, acc.: 64.06%] [G loss: 0.923409]\n",
            "966 [D loss: 0.588075, acc.: 62.50%] [G loss: 0.884983]\n",
            "967 [D loss: 0.596901, acc.: 60.94%] [G loss: 0.936950]\n",
            "968 [D loss: 0.587956, acc.: 62.50%] [G loss: 0.901515]\n",
            "969 [D loss: 0.595729, acc.: 62.50%] [G loss: 0.931836]\n",
            "970 [D loss: 0.586992, acc.: 64.06%] [G loss: 0.943035]\n",
            "971 [D loss: 0.589009, acc.: 65.62%] [G loss: 0.934153]\n",
            "972 [D loss: 0.599395, acc.: 62.50%] [G loss: 0.922033]\n",
            "973 [D loss: 0.605460, acc.: 60.94%] [G loss: 0.903420]\n",
            "974 [D loss: 0.596957, acc.: 64.06%] [G loss: 0.895477]\n",
            "975 [D loss: 0.589481, acc.: 62.50%] [G loss: 0.901726]\n",
            "976 [D loss: 0.590642, acc.: 64.06%] [G loss: 0.918794]\n",
            "977 [D loss: 0.596057, acc.: 62.50%] [G loss: 0.925788]\n",
            "978 [D loss: 0.592444, acc.: 62.50%] [G loss: 0.941625]\n",
            "979 [D loss: 0.597587, acc.: 64.06%] [G loss: 0.897016]\n",
            "980 [D loss: 0.594089, acc.: 64.06%] [G loss: 0.907399]\n",
            "981 [D loss: 0.571421, acc.: 64.06%] [G loss: 0.938673]\n",
            "982 [D loss: 0.603590, acc.: 60.94%] [G loss: 0.911456]\n",
            "983 [D loss: 0.603771, acc.: 64.06%] [G loss: 0.901869]\n",
            "984 [D loss: 0.676422, acc.: 57.81%] [G loss: 0.902491]\n",
            "985 [D loss: 0.590814, acc.: 64.06%] [G loss: 0.865921]\n",
            "986 [D loss: 0.603931, acc.: 59.38%] [G loss: 0.890467]\n",
            "987 [D loss: 0.592046, acc.: 64.06%] [G loss: 0.878560]\n",
            "988 [D loss: 0.591824, acc.: 64.06%] [G loss: 0.903330]\n",
            "989 [D loss: 0.584578, acc.: 67.19%] [G loss: 0.885117]\n",
            "990 [D loss: 0.608620, acc.: 60.94%] [G loss: 0.918849]\n",
            "991 [D loss: 0.609020, acc.: 64.06%] [G loss: 0.878626]\n",
            "992 [D loss: 0.607882, acc.: 64.06%] [G loss: 0.864565]\n",
            "993 [D loss: 0.598126, acc.: 60.94%] [G loss: 0.893059]\n",
            "994 [D loss: 0.593790, acc.: 64.06%] [G loss: 0.914441]\n",
            "995 [D loss: 0.620595, acc.: 60.94%] [G loss: 0.865660]\n",
            "996 [D loss: 0.609762, acc.: 59.38%] [G loss: 0.874103]\n",
            "997 [D loss: 0.597126, acc.: 62.50%] [G loss: 0.871343]\n",
            "998 [D loss: 0.592860, acc.: 62.50%] [G loss: 0.860624]\n",
            "999 [D loss: 0.597375, acc.: 59.38%] [G loss: 0.886328]\n",
            "1000 [D loss: 0.597973, acc.: 60.94%] [G loss: 0.900641]\n",
            "generated_data\n",
            "1001 [D loss: 0.611855, acc.: 59.38%] [G loss: 0.889605]\n",
            "1002 [D loss: 0.598470, acc.: 60.94%] [G loss: 0.904112]\n",
            "1003 [D loss: 0.598880, acc.: 62.50%] [G loss: 0.908379]\n",
            "1004 [D loss: 0.590269, acc.: 62.50%] [G loss: 0.905051]\n",
            "1005 [D loss: 0.591559, acc.: 62.50%] [G loss: 0.923654]\n",
            "1006 [D loss: 0.596371, acc.: 60.94%] [G loss: 0.886079]\n",
            "1007 [D loss: 0.607898, acc.: 60.94%] [G loss: 0.904103]\n",
            "1008 [D loss: 0.599136, acc.: 62.50%] [G loss: 0.900029]\n",
            "1009 [D loss: 0.594907, acc.: 62.50%] [G loss: 0.899550]\n",
            "1010 [D loss: 0.596287, acc.: 62.50%] [G loss: 0.875244]\n",
            "1011 [D loss: 0.593376, acc.: 62.50%] [G loss: 0.908202]\n",
            "1012 [D loss: 0.600172, acc.: 62.50%] [G loss: 0.896333]\n",
            "1013 [D loss: 0.598217, acc.: 64.06%] [G loss: 0.884877]\n",
            "1014 [D loss: 0.590809, acc.: 64.06%] [G loss: 0.920424]\n",
            "1015 [D loss: 0.603029, acc.: 60.94%] [G loss: 0.906749]\n",
            "1016 [D loss: 0.587859, acc.: 64.06%] [G loss: 0.923204]\n",
            "1017 [D loss: 0.604847, acc.: 62.50%] [G loss: 0.926469]\n",
            "1018 [D loss: 0.606076, acc.: 62.50%] [G loss: 0.904873]\n",
            "1019 [D loss: 0.602427, acc.: 62.50%] [G loss: 0.937696]\n",
            "1020 [D loss: 0.595840, acc.: 64.06%] [G loss: 0.932489]\n",
            "1021 [D loss: 0.594737, acc.: 64.06%] [G loss: 0.920211]\n",
            "1022 [D loss: 0.601589, acc.: 62.50%] [G loss: 0.932062]\n",
            "1023 [D loss: 0.609846, acc.: 59.38%] [G loss: 0.922232]\n",
            "1024 [D loss: 0.600796, acc.: 62.50%] [G loss: 0.929270]\n",
            "1025 [D loss: 0.592368, acc.: 64.06%] [G loss: 0.928427]\n",
            "1026 [D loss: 0.588028, acc.: 60.94%] [G loss: 0.917035]\n",
            "1027 [D loss: 0.589758, acc.: 60.94%] [G loss: 0.909729]\n",
            "1028 [D loss: 0.591029, acc.: 60.94%] [G loss: 0.896782]\n",
            "1029 [D loss: 0.601462, acc.: 60.94%] [G loss: 0.908615]\n",
            "1030 [D loss: 0.590455, acc.: 62.50%] [G loss: 0.879480]\n",
            "1031 [D loss: 0.607967, acc.: 59.38%] [G loss: 0.860151]\n",
            "1032 [D loss: 0.597474, acc.: 62.50%] [G loss: 0.889050]\n",
            "1033 [D loss: 0.599427, acc.: 62.50%] [G loss: 0.874748]\n",
            "1034 [D loss: 0.594732, acc.: 62.50%] [G loss: 0.887672]\n",
            "1035 [D loss: 0.594157, acc.: 62.50%] [G loss: 0.894151]\n",
            "1036 [D loss: 0.599974, acc.: 60.94%] [G loss: 0.918649]\n",
            "1037 [D loss: 0.592784, acc.: 62.50%] [G loss: 0.922211]\n",
            "1038 [D loss: 0.607014, acc.: 62.50%] [G loss: 0.912807]\n",
            "1039 [D loss: 0.592323, acc.: 62.50%] [G loss: 0.912748]\n",
            "1040 [D loss: 0.579910, acc.: 62.50%] [G loss: 0.886450]\n",
            "1041 [D loss: 0.601963, acc.: 59.38%] [G loss: 0.958145]\n",
            "1042 [D loss: 0.602903, acc.: 62.50%] [G loss: 0.931469]\n",
            "1043 [D loss: 0.603795, acc.: 60.94%] [G loss: 0.898831]\n",
            "1044 [D loss: 0.614870, acc.: 62.50%] [G loss: 0.881310]\n",
            "1045 [D loss: 0.589181, acc.: 62.50%] [G loss: 0.918622]\n",
            "1046 [D loss: 0.595299, acc.: 62.50%] [G loss: 0.957077]\n",
            "1047 [D loss: 0.614971, acc.: 62.50%] [G loss: 0.898839]\n",
            "1048 [D loss: 0.605020, acc.: 62.50%] [G loss: 0.927142]\n",
            "1049 [D loss: 0.592441, acc.: 62.50%] [G loss: 0.917846]\n",
            "1050 [D loss: 0.588433, acc.: 62.50%] [G loss: 0.970479]\n",
            "1051 [D loss: 0.602468, acc.: 64.06%] [G loss: 0.917000]\n",
            "1052 [D loss: 0.605944, acc.: 64.06%] [G loss: 0.895078]\n",
            "1053 [D loss: 0.597985, acc.: 64.06%] [G loss: 0.889521]\n",
            "1054 [D loss: 0.588120, acc.: 64.06%] [G loss: 0.905044]\n",
            "1055 [D loss: 0.589900, acc.: 64.06%] [G loss: 0.923832]\n",
            "1056 [D loss: 0.607150, acc.: 59.38%] [G loss: 0.908362]\n",
            "1057 [D loss: 0.597570, acc.: 64.06%] [G loss: 0.881267]\n",
            "1058 [D loss: 0.600966, acc.: 64.06%] [G loss: 0.879252]\n",
            "1059 [D loss: 0.595196, acc.: 60.94%] [G loss: 0.885231]\n",
            "1060 [D loss: 0.593623, acc.: 62.50%] [G loss: 0.879430]\n",
            "1061 [D loss: 0.584732, acc.: 65.62%] [G loss: 0.867255]\n",
            "1062 [D loss: 0.583134, acc.: 64.06%] [G loss: 0.867862]\n",
            "1063 [D loss: 0.582915, acc.: 64.06%] [G loss: 0.882124]\n",
            "1064 [D loss: 0.580628, acc.: 64.06%] [G loss: 0.896121]\n",
            "1065 [D loss: 0.591054, acc.: 60.94%] [G loss: 0.874680]\n",
            "1066 [D loss: 0.608870, acc.: 59.38%] [G loss: 0.857428]\n",
            "1067 [D loss: 0.592391, acc.: 62.50%] [G loss: 0.904486]\n",
            "1068 [D loss: 0.578679, acc.: 65.62%] [G loss: 0.941585]\n",
            "1069 [D loss: 0.590748, acc.: 62.50%] [G loss: 0.942296]\n",
            "1070 [D loss: 0.610790, acc.: 62.50%] [G loss: 0.889119]\n",
            "1071 [D loss: 0.594999, acc.: 62.50%] [G loss: 0.885789]\n",
            "1072 [D loss: 0.601024, acc.: 62.50%] [G loss: 0.887789]\n",
            "1073 [D loss: 0.589364, acc.: 60.94%] [G loss: 0.876920]\n",
            "1074 [D loss: 0.597615, acc.: 60.94%] [G loss: 0.896875]\n",
            "1075 [D loss: 0.598815, acc.: 60.94%] [G loss: 0.920363]\n",
            "1076 [D loss: 0.601982, acc.: 62.50%] [G loss: 0.933030]\n",
            "1077 [D loss: 0.602625, acc.: 62.50%] [G loss: 0.935556]\n",
            "1078 [D loss: 0.598625, acc.: 64.06%] [G loss: 0.919284]\n",
            "1079 [D loss: 0.606885, acc.: 57.81%] [G loss: 0.919130]\n",
            "1080 [D loss: 0.592188, acc.: 64.06%] [G loss: 0.885430]\n",
            "1081 [D loss: 0.595522, acc.: 65.62%] [G loss: 0.905504]\n",
            "1082 [D loss: 0.597716, acc.: 64.06%] [G loss: 0.889931]\n",
            "1083 [D loss: 0.582820, acc.: 67.19%] [G loss: 0.857787]\n",
            "1084 [D loss: 0.600028, acc.: 62.50%] [G loss: 0.820514]\n",
            "1085 [D loss: 0.597205, acc.: 62.50%] [G loss: 0.865109]\n",
            "1086 [D loss: 0.599305, acc.: 60.94%] [G loss: 0.905183]\n",
            "1087 [D loss: 0.600763, acc.: 62.50%] [G loss: 0.894158]\n",
            "1088 [D loss: 0.602514, acc.: 57.81%] [G loss: 0.920579]\n",
            "1089 [D loss: 0.587749, acc.: 60.94%] [G loss: 0.902509]\n",
            "1090 [D loss: 0.603804, acc.: 60.94%] [G loss: 0.886304]\n",
            "1091 [D loss: 0.604092, acc.: 60.94%] [G loss: 0.928386]\n",
            "1092 [D loss: 0.601719, acc.: 62.50%] [G loss: 0.915463]\n",
            "1093 [D loss: 0.599862, acc.: 62.50%] [G loss: 0.898872]\n",
            "1094 [D loss: 0.598102, acc.: 60.94%] [G loss: 0.913455]\n",
            "1095 [D loss: 0.581292, acc.: 65.62%] [G loss: 0.928074]\n",
            "1096 [D loss: 0.618875, acc.: 60.94%] [G loss: 0.916755]\n",
            "1097 [D loss: 0.616556, acc.: 62.50%] [G loss: 0.928518]\n",
            "1098 [D loss: 0.619345, acc.: 59.38%] [G loss: 0.902698]\n",
            "1099 [D loss: 0.622695, acc.: 59.38%] [G loss: 0.869730]\n",
            "1100 [D loss: 0.616994, acc.: 59.38%] [G loss: 0.883395]\n",
            "generated_data\n",
            "1101 [D loss: 0.639871, acc.: 57.81%] [G loss: 0.935785]\n",
            "1102 [D loss: 0.567046, acc.: 65.62%] [G loss: 0.989690]\n",
            "1103 [D loss: 0.573142, acc.: 65.62%] [G loss: 0.895814]\n",
            "1104 [D loss: 0.577553, acc.: 64.06%] [G loss: 0.921969]\n",
            "1105 [D loss: 0.597056, acc.: 59.38%] [G loss: 0.918725]\n",
            "1106 [D loss: 0.620670, acc.: 64.06%] [G loss: 0.832905]\n",
            "1107 [D loss: 0.595870, acc.: 57.81%] [G loss: 0.874048]\n",
            "1108 [D loss: 0.632713, acc.: 54.69%] [G loss: 0.836137]\n",
            "1109 [D loss: 0.642193, acc.: 54.69%] [G loss: 0.939988]\n",
            "1110 [D loss: 0.583081, acc.: 64.06%] [G loss: 0.952119]\n",
            "1111 [D loss: 0.613950, acc.: 56.25%] [G loss: 0.961839]\n",
            "1112 [D loss: 0.611052, acc.: 60.94%] [G loss: 0.948992]\n",
            "1113 [D loss: 0.610426, acc.: 60.94%] [G loss: 0.902497]\n",
            "1114 [D loss: 0.611616, acc.: 62.50%] [G loss: 0.899031]\n",
            "1115 [D loss: 0.595804, acc.: 60.94%] [G loss: 0.916155]\n",
            "1116 [D loss: 0.592160, acc.: 62.50%] [G loss: 0.894847]\n",
            "1117 [D loss: 0.600349, acc.: 59.38%] [G loss: 0.901623]\n",
            "1118 [D loss: 0.591265, acc.: 62.50%] [G loss: 0.889533]\n",
            "1119 [D loss: 0.601604, acc.: 64.06%] [G loss: 0.883010]\n",
            "1120 [D loss: 0.605936, acc.: 60.94%] [G loss: 0.885709]\n",
            "1121 [D loss: 0.602153, acc.: 60.94%] [G loss: 0.885867]\n",
            "1122 [D loss: 0.633509, acc.: 54.69%] [G loss: 0.909561]\n",
            "1123 [D loss: 0.606131, acc.: 57.81%] [G loss: 0.921387]\n",
            "1124 [D loss: 0.592421, acc.: 62.50%] [G loss: 0.929169]\n",
            "1125 [D loss: 0.607949, acc.: 62.50%] [G loss: 0.883989]\n",
            "1126 [D loss: 0.614451, acc.: 59.38%] [G loss: 0.904093]\n",
            "1127 [D loss: 0.614211, acc.: 60.94%] [G loss: 0.928068]\n",
            "1128 [D loss: 0.595382, acc.: 62.50%] [G loss: 0.940880]\n",
            "1129 [D loss: 0.604879, acc.: 62.50%] [G loss: 0.929388]\n",
            "1130 [D loss: 0.614679, acc.: 62.50%] [G loss: 0.924758]\n",
            "1131 [D loss: 0.598362, acc.: 62.50%] [G loss: 0.939156]\n",
            "1132 [D loss: 0.596289, acc.: 62.50%] [G loss: 0.944147]\n",
            "1133 [D loss: 0.597495, acc.: 62.50%] [G loss: 0.926779]\n",
            "1134 [D loss: 0.607465, acc.: 62.50%] [G loss: 0.918009]\n",
            "1135 [D loss: 0.604656, acc.: 62.50%] [G loss: 0.884177]\n",
            "1136 [D loss: 0.603229, acc.: 62.50%] [G loss: 0.891483]\n",
            "1137 [D loss: 0.596241, acc.: 62.50%] [G loss: 0.886799]\n",
            "1138 [D loss: 0.598514, acc.: 62.50%] [G loss: 0.877010]\n",
            "1139 [D loss: 0.599878, acc.: 62.50%] [G loss: 0.915451]\n",
            "1140 [D loss: 0.597129, acc.: 62.50%] [G loss: 0.916617]\n",
            "1141 [D loss: 0.612868, acc.: 62.50%] [G loss: 0.916220]\n",
            "1142 [D loss: 0.603023, acc.: 62.50%] [G loss: 0.902895]\n",
            "1143 [D loss: 0.601107, acc.: 62.50%] [G loss: 0.900240]\n",
            "1144 [D loss: 0.602111, acc.: 62.50%] [G loss: 0.893235]\n",
            "1145 [D loss: 0.603831, acc.: 62.50%] [G loss: 0.891712]\n",
            "1146 [D loss: 0.600323, acc.: 62.50%] [G loss: 0.896373]\n",
            "1147 [D loss: 0.603930, acc.: 62.50%] [G loss: 0.897563]\n",
            "1148 [D loss: 0.595863, acc.: 62.50%] [G loss: 0.893585]\n",
            "1149 [D loss: 0.598180, acc.: 62.50%] [G loss: 0.890213]\n",
            "1150 [D loss: 0.603397, acc.: 62.50%] [G loss: 0.892452]\n",
            "1151 [D loss: 0.603113, acc.: 62.50%] [G loss: 0.901452]\n",
            "1152 [D loss: 0.604105, acc.: 62.50%] [G loss: 0.898606]\n",
            "1153 [D loss: 0.595687, acc.: 62.50%] [G loss: 0.885709]\n",
            "1154 [D loss: 0.597438, acc.: 62.50%] [G loss: 0.876348]\n",
            "1155 [D loss: 0.592454, acc.: 60.94%] [G loss: 0.906511]\n",
            "1156 [D loss: 0.603467, acc.: 60.94%] [G loss: 0.905718]\n",
            "1157 [D loss: 0.599942, acc.: 62.50%] [G loss: 0.908583]\n",
            "1158 [D loss: 0.587894, acc.: 62.50%] [G loss: 0.889514]\n",
            "1159 [D loss: 0.598399, acc.: 62.50%] [G loss: 0.903015]\n",
            "1160 [D loss: 0.597526, acc.: 59.38%] [G loss: 0.882721]\n",
            "1161 [D loss: 0.599703, acc.: 62.50%] [G loss: 0.925591]\n",
            "1162 [D loss: 0.600706, acc.: 62.50%] [G loss: 0.886184]\n",
            "1163 [D loss: 0.593008, acc.: 62.50%] [G loss: 0.860578]\n",
            "1164 [D loss: 0.605202, acc.: 62.50%] [G loss: 0.878466]\n",
            "1165 [D loss: 0.600473, acc.: 62.50%] [G loss: 0.882283]\n",
            "1166 [D loss: 0.611537, acc.: 60.94%] [G loss: 0.875463]\n",
            "1167 [D loss: 0.602176, acc.: 62.50%] [G loss: 0.903028]\n",
            "1168 [D loss: 0.607600, acc.: 62.50%] [G loss: 0.877913]\n",
            "1169 [D loss: 0.599542, acc.: 62.50%] [G loss: 0.883498]\n",
            "1170 [D loss: 0.596771, acc.: 62.50%] [G loss: 0.862800]\n",
            "1171 [D loss: 0.597989, acc.: 62.50%] [G loss: 0.893817]\n",
            "1172 [D loss: 0.596284, acc.: 62.50%] [G loss: 0.886066]\n",
            "1173 [D loss: 0.606854, acc.: 62.50%] [G loss: 0.903188]\n",
            "1174 [D loss: 0.598774, acc.: 62.50%] [G loss: 0.872326]\n",
            "1175 [D loss: 0.604584, acc.: 59.38%] [G loss: 0.938236]\n",
            "1176 [D loss: 0.625365, acc.: 57.81%] [G loss: 0.914867]\n",
            "1177 [D loss: 0.611499, acc.: 62.50%] [G loss: 0.898470]\n",
            "1178 [D loss: 0.598095, acc.: 62.50%] [G loss: 0.874816]\n",
            "1179 [D loss: 0.593552, acc.: 62.50%] [G loss: 0.874742]\n",
            "1180 [D loss: 0.604660, acc.: 60.94%] [G loss: 0.884234]\n",
            "1181 [D loss: 0.597713, acc.: 62.50%] [G loss: 0.890567]\n",
            "1182 [D loss: 0.594502, acc.: 62.50%] [G loss: 0.892396]\n",
            "1183 [D loss: 0.598094, acc.: 60.94%] [G loss: 0.910339]\n",
            "1184 [D loss: 0.606108, acc.: 62.50%] [G loss: 0.892451]\n",
            "1185 [D loss: 0.604589, acc.: 62.50%] [G loss: 0.882033]\n",
            "1186 [D loss: 0.603066, acc.: 62.50%] [G loss: 0.907303]\n",
            "1187 [D loss: 0.602787, acc.: 62.50%] [G loss: 0.884054]\n",
            "1188 [D loss: 0.598592, acc.: 59.38%] [G loss: 0.898785]\n",
            "1189 [D loss: 0.604273, acc.: 64.06%] [G loss: 0.902948]\n",
            "1190 [D loss: 0.592563, acc.: 60.94%] [G loss: 0.906537]\n",
            "1191 [D loss: 0.595454, acc.: 62.50%] [G loss: 0.885161]\n",
            "1192 [D loss: 0.600429, acc.: 64.06%] [G loss: 0.843167]\n",
            "1193 [D loss: 0.578611, acc.: 65.62%] [G loss: 0.854305]\n",
            "1194 [D loss: 0.616623, acc.: 60.94%] [G loss: 0.891788]\n",
            "1195 [D loss: 0.633768, acc.: 56.25%] [G loss: 0.927534]\n",
            "1196 [D loss: 0.633239, acc.: 56.25%] [G loss: 0.914436]\n",
            "1197 [D loss: 0.606625, acc.: 59.38%] [G loss: 0.862888]\n",
            "1198 [D loss: 0.607857, acc.: 62.50%] [G loss: 0.933079]\n",
            "1199 [D loss: 0.608406, acc.: 62.50%] [G loss: 0.946021]\n",
            "1200 [D loss: 0.599284, acc.: 62.50%] [G loss: 0.972551]\n",
            "generated_data\n",
            "1201 [D loss: 0.605815, acc.: 62.50%] [G loss: 0.932201]\n",
            "1202 [D loss: 0.605311, acc.: 62.50%] [G loss: 0.919125]\n",
            "1203 [D loss: 0.619131, acc.: 59.38%] [G loss: 0.914727]\n",
            "1204 [D loss: 0.601599, acc.: 62.50%] [G loss: 0.898907]\n",
            "1205 [D loss: 0.600239, acc.: 62.50%] [G loss: 0.907749]\n",
            "1206 [D loss: 0.592082, acc.: 62.50%] [G loss: 0.901457]\n",
            "1207 [D loss: 0.601165, acc.: 62.50%] [G loss: 0.906497]\n",
            "1208 [D loss: 0.595981, acc.: 62.50%] [G loss: 0.899544]\n",
            "1209 [D loss: 0.600492, acc.: 62.50%] [G loss: 0.907352]\n",
            "1210 [D loss: 0.595737, acc.: 62.50%] [G loss: 0.911282]\n",
            "1211 [D loss: 0.590042, acc.: 62.50%] [G loss: 0.917102]\n",
            "1212 [D loss: 0.591526, acc.: 62.50%] [G loss: 0.901283]\n",
            "1213 [D loss: 0.585281, acc.: 62.50%] [G loss: 0.905232]\n",
            "1214 [D loss: 0.594243, acc.: 64.06%] [G loss: 0.872003]\n",
            "1215 [D loss: 0.603420, acc.: 64.06%] [G loss: 0.900890]\n",
            "1216 [D loss: 0.594002, acc.: 64.06%] [G loss: 0.907637]\n",
            "1217 [D loss: 0.603764, acc.: 62.50%] [G loss: 0.895127]\n",
            "1218 [D loss: 0.604913, acc.: 60.94%] [G loss: 0.909741]\n",
            "1219 [D loss: 0.596067, acc.: 62.50%] [G loss: 0.907239]\n",
            "1220 [D loss: 0.611610, acc.: 62.50%] [G loss: 0.907840]\n",
            "1221 [D loss: 0.597732, acc.: 62.50%] [G loss: 0.893848]\n",
            "1222 [D loss: 0.594280, acc.: 64.06%] [G loss: 0.880442]\n",
            "1223 [D loss: 0.595530, acc.: 62.50%] [G loss: 0.900339]\n",
            "1224 [D loss: 0.599625, acc.: 60.94%] [G loss: 0.897975]\n",
            "1225 [D loss: 0.593566, acc.: 60.94%] [G loss: 0.902492]\n",
            "1226 [D loss: 0.601574, acc.: 60.94%] [G loss: 0.891473]\n",
            "1227 [D loss: 0.597864, acc.: 60.94%] [G loss: 0.896954]\n",
            "1228 [D loss: 0.591651, acc.: 62.50%] [G loss: 0.892228]\n",
            "1229 [D loss: 0.601507, acc.: 60.94%] [G loss: 0.891074]\n",
            "1230 [D loss: 0.606268, acc.: 60.94%] [G loss: 0.923302]\n",
            "1231 [D loss: 0.598611, acc.: 62.50%] [G loss: 0.919209]\n",
            "1232 [D loss: 0.599102, acc.: 62.50%] [G loss: 0.915320]\n",
            "1233 [D loss: 0.614262, acc.: 56.25%] [G loss: 0.938746]\n",
            "1234 [D loss: 0.594206, acc.: 62.50%] [G loss: 0.949785]\n",
            "1235 [D loss: 0.598906, acc.: 62.50%] [G loss: 0.904307]\n",
            "1236 [D loss: 0.596497, acc.: 64.06%] [G loss: 0.909703]\n",
            "1237 [D loss: 0.598964, acc.: 62.50%] [G loss: 0.894979]\n",
            "1238 [D loss: 0.597450, acc.: 64.06%] [G loss: 0.891038]\n",
            "1239 [D loss: 0.596521, acc.: 64.06%] [G loss: 0.906366]\n",
            "1240 [D loss: 0.592395, acc.: 64.06%] [G loss: 0.892471]\n",
            "1241 [D loss: 0.595870, acc.: 64.06%] [G loss: 0.911711]\n",
            "1242 [D loss: 0.591068, acc.: 64.06%] [G loss: 0.901520]\n",
            "1243 [D loss: 0.602790, acc.: 60.94%] [G loss: 0.870106]\n",
            "1244 [D loss: 0.600400, acc.: 60.94%] [G loss: 0.875871]\n",
            "1245 [D loss: 0.621609, acc.: 57.81%] [G loss: 0.900938]\n",
            "1246 [D loss: 0.598538, acc.: 62.50%] [G loss: 0.892587]\n",
            "1247 [D loss: 0.601819, acc.: 57.81%] [G loss: 0.895614]\n",
            "1248 [D loss: 0.605195, acc.: 62.50%] [G loss: 0.905318]\n",
            "1249 [D loss: 0.590981, acc.: 62.50%] [G loss: 0.929908]\n",
            "1250 [D loss: 0.591186, acc.: 62.50%] [G loss: 0.921823]\n",
            "1251 [D loss: 0.592575, acc.: 62.50%] [G loss: 0.913826]\n",
            "1252 [D loss: 0.599698, acc.: 62.50%] [G loss: 0.893630]\n",
            "1253 [D loss: 0.589052, acc.: 62.50%] [G loss: 0.903807]\n",
            "1254 [D loss: 0.600232, acc.: 62.50%] [G loss: 0.884498]\n",
            "1255 [D loss: 0.742577, acc.: 32.81%] [G loss: 0.894787]\n",
            "1256 [D loss: 0.599821, acc.: 62.50%] [G loss: 0.887720]\n",
            "1257 [D loss: 0.594321, acc.: 62.50%] [G loss: 0.905838]\n",
            "1258 [D loss: 0.605950, acc.: 62.50%] [G loss: 0.914934]\n",
            "1259 [D loss: 0.593501, acc.: 62.50%] [G loss: 0.899505]\n",
            "1260 [D loss: 0.598809, acc.: 62.50%] [G loss: 0.867257]\n",
            "1261 [D loss: 0.605957, acc.: 59.38%] [G loss: 0.892506]\n",
            "1262 [D loss: 0.596455, acc.: 62.50%] [G loss: 0.912907]\n",
            "1263 [D loss: 0.601391, acc.: 62.50%] [G loss: 0.882582]\n",
            "1264 [D loss: 0.593691, acc.: 62.50%] [G loss: 0.894124]\n",
            "1265 [D loss: 0.599564, acc.: 62.50%] [G loss: 0.875416]\n",
            "1266 [D loss: 0.595229, acc.: 60.94%] [G loss: 0.840166]\n",
            "1267 [D loss: 0.610824, acc.: 53.12%] [G loss: 0.875372]\n",
            "1268 [D loss: 0.601418, acc.: 59.38%] [G loss: 0.885706]\n",
            "1269 [D loss: 0.600796, acc.: 62.50%] [G loss: 0.882620]\n",
            "1270 [D loss: 0.601516, acc.: 62.50%] [G loss: 0.877000]\n",
            "1271 [D loss: 0.601500, acc.: 62.50%] [G loss: 0.885614]\n",
            "1272 [D loss: 0.595620, acc.: 62.50%] [G loss: 0.881464]\n",
            "1273 [D loss: 0.595306, acc.: 62.50%] [G loss: 0.881358]\n",
            "1274 [D loss: 0.593101, acc.: 62.50%] [G loss: 0.872191]\n",
            "1275 [D loss: 0.600182, acc.: 62.50%] [G loss: 0.889253]\n",
            "1276 [D loss: 0.598246, acc.: 62.50%] [G loss: 0.880150]\n",
            "1277 [D loss: 0.600779, acc.: 62.50%] [G loss: 0.933223]\n",
            "1278 [D loss: 0.598274, acc.: 62.50%] [G loss: 0.887980]\n",
            "1279 [D loss: 0.595243, acc.: 62.50%] [G loss: 0.870325]\n",
            "1280 [D loss: 0.594656, acc.: 62.50%] [G loss: 0.880565]\n",
            "1281 [D loss: 0.601216, acc.: 62.50%] [G loss: 0.867843]\n",
            "1282 [D loss: 0.607785, acc.: 62.50%] [G loss: 0.907599]\n",
            "1283 [D loss: 0.601587, acc.: 62.50%] [G loss: 0.878424]\n",
            "1284 [D loss: 0.600350, acc.: 60.94%] [G loss: 0.893748]\n",
            "1285 [D loss: 0.598259, acc.: 62.50%] [G loss: 0.878390]\n",
            "1286 [D loss: 0.596073, acc.: 62.50%] [G loss: 0.876731]\n",
            "1287 [D loss: 0.602455, acc.: 62.50%] [G loss: 0.879113]\n",
            "1288 [D loss: 0.605119, acc.: 62.50%] [G loss: 0.875535]\n",
            "1289 [D loss: 0.595969, acc.: 62.50%] [G loss: 0.881735]\n",
            "1290 [D loss: 0.591132, acc.: 62.50%] [G loss: 0.894922]\n",
            "1291 [D loss: 0.591423, acc.: 62.50%] [G loss: 0.883035]\n",
            "1292 [D loss: 0.593954, acc.: 62.50%] [G loss: 0.863657]\n",
            "1293 [D loss: 0.611996, acc.: 56.25%] [G loss: 0.852707]\n",
            "1294 [D loss: 0.595485, acc.: 59.38%] [G loss: 0.881799]\n",
            "1295 [D loss: 0.604608, acc.: 60.94%] [G loss: 0.871487]\n",
            "1296 [D loss: 0.593101, acc.: 62.50%] [G loss: 0.899978]\n",
            "1297 [D loss: 0.595607, acc.: 62.50%] [G loss: 0.883449]\n",
            "1298 [D loss: 0.595726, acc.: 62.50%] [G loss: 0.864046]\n",
            "1299 [D loss: 0.601977, acc.: 62.50%] [G loss: 0.876316]\n",
            "1300 [D loss: 0.593405, acc.: 62.50%] [G loss: 0.886808]\n",
            "generated_data\n",
            "1301 [D loss: 0.607287, acc.: 62.50%] [G loss: 0.892496]\n",
            "1302 [D loss: 0.601681, acc.: 60.94%] [G loss: 0.880730]\n",
            "1303 [D loss: 0.605349, acc.: 60.94%] [G loss: 0.867168]\n",
            "1304 [D loss: 0.603444, acc.: 64.06%] [G loss: 0.864910]\n",
            "1305 [D loss: 0.593866, acc.: 62.50%] [G loss: 0.862911]\n",
            "1306 [D loss: 0.601855, acc.: 60.94%] [G loss: 0.878353]\n",
            "1307 [D loss: 0.597646, acc.: 62.50%] [G loss: 0.838472]\n",
            "1308 [D loss: 0.594738, acc.: 62.50%] [G loss: 0.837168]\n",
            "1309 [D loss: 0.595728, acc.: 62.50%] [G loss: 0.845576]\n",
            "1310 [D loss: 0.588570, acc.: 62.50%] [G loss: 0.827229]\n",
            "1311 [D loss: 0.593864, acc.: 59.38%] [G loss: 0.830757]\n",
            "1312 [D loss: 0.595216, acc.: 60.94%] [G loss: 0.817344]\n",
            "1313 [D loss: 0.597644, acc.: 57.81%] [G loss: 0.840843]\n",
            "1314 [D loss: 0.593382, acc.: 57.81%] [G loss: 0.873843]\n",
            "1315 [D loss: 0.593041, acc.: 60.94%] [G loss: 0.869448]\n",
            "1316 [D loss: 0.597227, acc.: 62.50%] [G loss: 0.874066]\n",
            "1317 [D loss: 0.597930, acc.: 62.50%] [G loss: 0.876588]\n",
            "1318 [D loss: 0.592524, acc.: 62.50%] [G loss: 0.875539]\n",
            "1319 [D loss: 0.589857, acc.: 62.50%] [G loss: 1.010206]\n",
            "1320 [D loss: 0.608667, acc.: 64.06%] [G loss: 0.878057]\n",
            "1321 [D loss: 0.600610, acc.: 64.06%] [G loss: 0.856918]\n",
            "1322 [D loss: 0.600986, acc.: 64.06%] [G loss: 0.867182]\n",
            "1323 [D loss: 0.599554, acc.: 60.94%] [G loss: 0.882407]\n",
            "1324 [D loss: 0.596691, acc.: 62.50%] [G loss: 0.867498]\n",
            "1325 [D loss: 0.593906, acc.: 62.50%] [G loss: 0.878996]\n",
            "1326 [D loss: 0.603785, acc.: 60.94%] [G loss: 0.880374]\n",
            "1327 [D loss: 0.587893, acc.: 62.50%] [G loss: 0.886619]\n",
            "1328 [D loss: 0.592825, acc.: 62.50%] [G loss: 0.953738]\n",
            "1329 [D loss: 0.611900, acc.: 62.50%] [G loss: 0.886506]\n",
            "1330 [D loss: 0.591231, acc.: 62.50%] [G loss: 0.890884]\n",
            "1331 [D loss: 0.600806, acc.: 62.50%] [G loss: 0.874350]\n",
            "1332 [D loss: 0.608104, acc.: 62.50%] [G loss: 0.871344]\n",
            "1333 [D loss: 0.607893, acc.: 62.50%] [G loss: 0.870314]\n",
            "1334 [D loss: 0.598737, acc.: 62.50%] [G loss: 0.883809]\n",
            "1335 [D loss: 0.599351, acc.: 62.50%] [G loss: 0.869776]\n",
            "1336 [D loss: 0.597019, acc.: 62.50%] [G loss: 0.887203]\n",
            "1337 [D loss: 0.598237, acc.: 60.94%] [G loss: 0.875614]\n",
            "1338 [D loss: 0.595934, acc.: 62.50%] [G loss: 0.911604]\n",
            "1339 [D loss: 0.602019, acc.: 62.50%] [G loss: 0.874918]\n",
            "1340 [D loss: 0.601956, acc.: 62.50%] [G loss: 0.858777]\n",
            "1341 [D loss: 0.599422, acc.: 62.50%] [G loss: 0.856203]\n",
            "1342 [D loss: 0.595870, acc.: 62.50%] [G loss: 0.867782]\n",
            "1343 [D loss: 0.603857, acc.: 59.38%] [G loss: 0.871208]\n",
            "1344 [D loss: 0.598837, acc.: 62.50%] [G loss: 0.861633]\n",
            "1345 [D loss: 0.590744, acc.: 59.38%] [G loss: 0.857661]\n",
            "1346 [D loss: 0.598507, acc.: 62.50%] [G loss: 0.818424]\n",
            "1347 [D loss: 0.590935, acc.: 62.50%] [G loss: 0.837309]\n",
            "1348 [D loss: 0.593287, acc.: 59.38%] [G loss: 0.839375]\n",
            "1349 [D loss: 0.608305, acc.: 56.25%] [G loss: 0.849988]\n",
            "1350 [D loss: 0.589985, acc.: 60.94%] [G loss: 0.838522]\n",
            "1351 [D loss: 0.590632, acc.: 64.06%] [G loss: 0.845323]\n",
            "1352 [D loss: 0.616250, acc.: 56.25%] [G loss: 0.833849]\n",
            "1353 [D loss: 0.606348, acc.: 60.94%] [G loss: 0.869197]\n",
            "1354 [D loss: 0.596445, acc.: 62.50%] [G loss: 0.850759]\n",
            "1355 [D loss: 0.596617, acc.: 62.50%] [G loss: 0.863751]\n",
            "1356 [D loss: 0.596473, acc.: 62.50%] [G loss: 0.860772]\n",
            "1357 [D loss: 0.587901, acc.: 62.50%] [G loss: 0.875188]\n",
            "1358 [D loss: 0.593977, acc.: 59.38%] [G loss: 0.853947]\n",
            "1359 [D loss: 0.594457, acc.: 60.94%] [G loss: 0.843638]\n",
            "1360 [D loss: 0.595792, acc.: 62.50%] [G loss: 0.850678]\n",
            "1361 [D loss: 0.602379, acc.: 62.50%] [G loss: 0.850574]\n",
            "1362 [D loss: 0.591665, acc.: 62.50%] [G loss: 0.853752]\n",
            "1363 [D loss: 0.599180, acc.: 62.50%] [G loss: 0.878708]\n",
            "1364 [D loss: 0.594378, acc.: 62.50%] [G loss: 0.881803]\n",
            "1365 [D loss: 0.594998, acc.: 62.50%] [G loss: 0.859264]\n",
            "1366 [D loss: 0.587603, acc.: 64.06%] [G loss: 0.863038]\n",
            "1367 [D loss: 0.593953, acc.: 64.06%] [G loss: 0.871673]\n",
            "1368 [D loss: 0.589384, acc.: 60.94%] [G loss: 0.867535]\n",
            "1369 [D loss: 0.593619, acc.: 64.06%] [G loss: 0.886399]\n",
            "1370 [D loss: 0.606930, acc.: 60.94%] [G loss: 0.864177]\n",
            "1371 [D loss: 0.602213, acc.: 60.94%] [G loss: 0.880382]\n",
            "1372 [D loss: 0.600170, acc.: 64.06%] [G loss: 0.871093]\n",
            "1373 [D loss: 0.593603, acc.: 62.50%] [G loss: 0.876521]\n",
            "1374 [D loss: 0.587196, acc.: 64.06%] [G loss: 0.884641]\n",
            "1375 [D loss: 0.593362, acc.: 62.50%] [G loss: 0.876018]\n",
            "1376 [D loss: 0.594119, acc.: 62.50%] [G loss: 0.880101]\n",
            "1377 [D loss: 0.589498, acc.: 62.50%] [G loss: 0.864990]\n",
            "1378 [D loss: 0.602576, acc.: 59.38%] [G loss: 0.874306]\n",
            "1379 [D loss: 0.597277, acc.: 64.06%] [G loss: 0.885386]\n",
            "1380 [D loss: 0.601006, acc.: 62.50%] [G loss: 0.872821]\n",
            "1381 [D loss: 0.589884, acc.: 65.62%] [G loss: 0.869246]\n",
            "1382 [D loss: 0.594016, acc.: 64.06%] [G loss: 0.869441]\n",
            "1383 [D loss: 0.604828, acc.: 64.06%] [G loss: 0.859292]\n",
            "1384 [D loss: 0.596786, acc.: 62.50%] [G loss: 0.871985]\n",
            "1385 [D loss: 0.584062, acc.: 64.06%] [G loss: 0.878479]\n",
            "1386 [D loss: 0.612964, acc.: 59.38%] [G loss: 0.874720]\n",
            "1387 [D loss: 0.601105, acc.: 59.38%] [G loss: 0.878374]\n",
            "1388 [D loss: 0.589227, acc.: 62.50%] [G loss: 0.860809]\n",
            "1389 [D loss: 0.602020, acc.: 62.50%] [G loss: 0.857163]\n",
            "1390 [D loss: 0.589243, acc.: 62.50%] [G loss: 0.865767]\n",
            "1391 [D loss: 0.597756, acc.: 64.06%] [G loss: 0.869141]\n",
            "1392 [D loss: 0.590655, acc.: 62.50%] [G loss: 0.863239]\n",
            "1393 [D loss: 0.597494, acc.: 60.94%] [G loss: 0.863798]\n",
            "1394 [D loss: 0.594109, acc.: 60.94%] [G loss: 0.885906]\n",
            "1395 [D loss: 0.595637, acc.: 62.50%] [G loss: 0.855663]\n",
            "1396 [D loss: 0.618659, acc.: 57.81%] [G loss: 0.885190]\n",
            "1397 [D loss: 0.592730, acc.: 64.06%] [G loss: 0.867395]\n",
            "1398 [D loss: 0.594091, acc.: 62.50%] [G loss: 0.898554]\n",
            "1399 [D loss: 0.602589, acc.: 62.50%] [G loss: 0.870277]\n",
            "1400 [D loss: 0.600033, acc.: 60.94%] [G loss: 0.854958]\n",
            "generated_data\n",
            "1401 [D loss: 0.599053, acc.: 60.94%] [G loss: 0.917290]\n",
            "1402 [D loss: 0.592905, acc.: 62.50%] [G loss: 0.882556]\n",
            "1403 [D loss: 0.610287, acc.: 62.50%] [G loss: 0.892170]\n",
            "1404 [D loss: 0.601401, acc.: 62.50%] [G loss: 0.891329]\n",
            "1405 [D loss: 0.592527, acc.: 62.50%] [G loss: 0.892740]\n",
            "1406 [D loss: 0.600110, acc.: 62.50%] [G loss: 0.921678]\n",
            "1407 [D loss: 0.591961, acc.: 60.94%] [G loss: 0.935671]\n",
            "1408 [D loss: 0.589384, acc.: 62.50%] [G loss: 0.944444]\n",
            "1409 [D loss: 0.589450, acc.: 60.94%] [G loss: 0.927931]\n",
            "1410 [D loss: 0.593345, acc.: 62.50%] [G loss: 0.978609]\n",
            "1411 [D loss: 0.601916, acc.: 62.50%] [G loss: 0.915381]\n",
            "1412 [D loss: 0.590787, acc.: 62.50%] [G loss: 0.889208]\n",
            "1413 [D loss: 0.601202, acc.: 62.50%] [G loss: 0.874644]\n",
            "1414 [D loss: 0.595576, acc.: 62.50%] [G loss: 0.887930]\n",
            "1415 [D loss: 0.599634, acc.: 62.50%] [G loss: 0.870183]\n",
            "1416 [D loss: 0.596728, acc.: 60.94%] [G loss: 0.878572]\n",
            "1417 [D loss: 0.597123, acc.: 60.94%] [G loss: 0.874508]\n",
            "1418 [D loss: 0.604721, acc.: 59.38%] [G loss: 0.882147]\n",
            "1419 [D loss: 0.591470, acc.: 62.50%] [G loss: 0.872441]\n",
            "1420 [D loss: 0.599930, acc.: 60.94%] [G loss: 0.887995]\n",
            "1421 [D loss: 0.590774, acc.: 62.50%] [G loss: 0.897091]\n",
            "1422 [D loss: 0.613441, acc.: 60.94%] [G loss: 0.901024]\n",
            "1423 [D loss: 0.598186, acc.: 62.50%] [G loss: 0.874781]\n",
            "1424 [D loss: 0.588391, acc.: 62.50%] [G loss: 0.887075]\n",
            "1425 [D loss: 0.598158, acc.: 60.94%] [G loss: 0.881447]\n",
            "1426 [D loss: 0.599359, acc.: 59.38%] [G loss: 0.896927]\n",
            "1427 [D loss: 0.589482, acc.: 65.62%] [G loss: 0.890679]\n",
            "1428 [D loss: 0.593006, acc.: 57.81%] [G loss: 0.861975]\n",
            "1429 [D loss: 0.604288, acc.: 62.50%] [G loss: 0.882137]\n",
            "1430 [D loss: 0.588856, acc.: 62.50%] [G loss: 0.878238]\n",
            "1431 [D loss: 0.590476, acc.: 62.50%] [G loss: 0.898532]\n",
            "1432 [D loss: 0.600763, acc.: 59.38%] [G loss: 0.915693]\n",
            "1433 [D loss: 0.600359, acc.: 59.38%] [G loss: 0.864738]\n",
            "1434 [D loss: 0.599878, acc.: 62.50%] [G loss: 0.899381]\n",
            "1435 [D loss: 0.591962, acc.: 62.50%] [G loss: 0.902804]\n",
            "1436 [D loss: 0.594492, acc.: 59.38%] [G loss: 0.862450]\n",
            "1437 [D loss: 0.587605, acc.: 64.06%] [G loss: 0.867452]\n",
            "1438 [D loss: 0.606614, acc.: 60.94%] [G loss: 0.890919]\n",
            "1439 [D loss: 0.602851, acc.: 57.81%] [G loss: 0.900985]\n",
            "1440 [D loss: 0.607712, acc.: 59.38%] [G loss: 0.856082]\n",
            "1441 [D loss: 0.592742, acc.: 64.06%] [G loss: 0.826139]\n",
            "1442 [D loss: 0.615845, acc.: 60.94%] [G loss: 0.877457]\n",
            "1443 [D loss: 0.595573, acc.: 62.50%] [G loss: 0.913072]\n",
            "1444 [D loss: 0.605934, acc.: 62.50%] [G loss: 0.895223]\n",
            "1445 [D loss: 0.587253, acc.: 62.50%] [G loss: 0.898520]\n",
            "1446 [D loss: 0.596348, acc.: 59.38%] [G loss: 0.899446]\n",
            "1447 [D loss: 0.595136, acc.: 62.50%] [G loss: 0.948057]\n",
            "1448 [D loss: 0.602354, acc.: 62.50%] [G loss: 0.949314]\n",
            "1449 [D loss: 0.597560, acc.: 62.50%] [G loss: 0.906614]\n",
            "1450 [D loss: 0.604946, acc.: 60.94%] [G loss: 0.900808]\n",
            "1451 [D loss: 0.600586, acc.: 62.50%] [G loss: 0.918428]\n",
            "1452 [D loss: 0.593447, acc.: 62.50%] [G loss: 0.892870]\n",
            "1453 [D loss: 0.605468, acc.: 62.50%] [G loss: 0.906006]\n",
            "1454 [D loss: 0.599569, acc.: 62.50%] [G loss: 0.898062]\n",
            "1455 [D loss: 0.598124, acc.: 62.50%] [G loss: 0.911895]\n",
            "1456 [D loss: 0.599864, acc.: 62.50%] [G loss: 0.919491]\n",
            "1457 [D loss: 0.604145, acc.: 62.50%] [G loss: 0.900986]\n",
            "1458 [D loss: 0.599711, acc.: 62.50%] [G loss: 0.906496]\n",
            "1459 [D loss: 0.593967, acc.: 62.50%] [G loss: 0.897100]\n",
            "1460 [D loss: 0.591958, acc.: 62.50%] [G loss: 0.900473]\n",
            "1461 [D loss: 0.590114, acc.: 62.50%] [G loss: 0.904108]\n",
            "1462 [D loss: 0.596329, acc.: 62.50%] [G loss: 0.905338]\n",
            "1463 [D loss: 0.593634, acc.: 60.94%] [G loss: 0.901414]\n",
            "1464 [D loss: 0.604810, acc.: 62.50%] [G loss: 0.901686]\n",
            "1465 [D loss: 0.603681, acc.: 62.50%] [G loss: 0.912477]\n",
            "1466 [D loss: 0.595666, acc.: 62.50%] [G loss: 0.879620]\n",
            "1467 [D loss: 0.599517, acc.: 62.50%] [G loss: 0.895321]\n",
            "1468 [D loss: 0.600684, acc.: 62.50%] [G loss: 0.879180]\n",
            "1469 [D loss: 0.600994, acc.: 62.50%] [G loss: 0.872860]\n",
            "1470 [D loss: 0.597706, acc.: 62.50%] [G loss: 0.906420]\n",
            "1471 [D loss: 0.586852, acc.: 62.50%] [G loss: 0.914615]\n",
            "1472 [D loss: 0.596703, acc.: 64.06%] [G loss: 0.912737]\n",
            "1473 [D loss: 0.593630, acc.: 60.94%] [G loss: 0.877703]\n",
            "1474 [D loss: 0.602760, acc.: 62.50%] [G loss: 0.871247]\n",
            "1475 [D loss: 0.604003, acc.: 62.50%] [G loss: 0.875300]\n",
            "1476 [D loss: 0.593410, acc.: 62.50%] [G loss: 0.873744]\n",
            "1477 [D loss: 0.603018, acc.: 60.94%] [G loss: 0.879114]\n",
            "1478 [D loss: 0.603916, acc.: 62.50%] [G loss: 0.862762]\n",
            "1479 [D loss: 0.592236, acc.: 59.38%] [G loss: 0.875105]\n",
            "1480 [D loss: 0.596530, acc.: 60.94%] [G loss: 0.880145]\n",
            "1481 [D loss: 0.582552, acc.: 67.19%] [G loss: 0.881364]\n",
            "1482 [D loss: 0.599867, acc.: 62.50%] [G loss: 0.889061]\n",
            "1483 [D loss: 0.589891, acc.: 60.94%] [G loss: 0.907017]\n",
            "1484 [D loss: 0.605270, acc.: 57.81%] [G loss: 0.936170]\n",
            "1485 [D loss: 0.607944, acc.: 60.94%] [G loss: 0.916735]\n",
            "1486 [D loss: 0.596756, acc.: 64.06%] [G loss: 0.918953]\n",
            "1487 [D loss: 0.596047, acc.: 64.06%] [G loss: 0.941434]\n",
            "1488 [D loss: 0.598157, acc.: 64.06%] [G loss: 0.906944]\n",
            "1489 [D loss: 0.607519, acc.: 62.50%] [G loss: 0.920302]\n",
            "1490 [D loss: 0.598102, acc.: 60.94%] [G loss: 0.956989]\n",
            "1491 [D loss: 0.594600, acc.: 64.06%] [G loss: 0.910920]\n",
            "1492 [D loss: 0.586725, acc.: 62.50%] [G loss: 0.913457]\n",
            "1493 [D loss: 0.614227, acc.: 62.50%] [G loss: 0.894427]\n",
            "1494 [D loss: 0.603331, acc.: 60.94%] [G loss: 0.887103]\n",
            "1495 [D loss: 0.589468, acc.: 64.06%] [G loss: 0.879743]\n",
            "1496 [D loss: 0.595759, acc.: 62.50%] [G loss: 0.884581]\n",
            "1497 [D loss: 0.587366, acc.: 65.62%] [G loss: 0.944883]\n",
            "1498 [D loss: 0.595318, acc.: 62.50%] [G loss: 0.912764]\n",
            "1499 [D loss: 0.596835, acc.: 62.50%] [G loss: 0.879605]\n",
            "1500 [D loss: 0.611207, acc.: 56.25%] [G loss: 0.843055]\n",
            "generated_data\n",
            "1501 [D loss: 0.593374, acc.: 62.50%] [G loss: 0.890091]\n",
            "1502 [D loss: 0.589297, acc.: 65.62%] [G loss: 0.903522]\n",
            "1503 [D loss: 0.603191, acc.: 60.94%] [G loss: 0.891255]\n",
            "1504 [D loss: 0.594480, acc.: 62.50%] [G loss: 0.909278]\n",
            "1505 [D loss: 0.599778, acc.: 62.50%] [G loss: 0.896014]\n",
            "1506 [D loss: 0.589927, acc.: 64.06%] [G loss: 0.918305]\n",
            "1507 [D loss: 0.597748, acc.: 60.94%] [G loss: 0.878112]\n",
            "1508 [D loss: 0.596405, acc.: 62.50%] [G loss: 0.874978]\n",
            "1509 [D loss: 0.604189, acc.: 60.94%] [G loss: 0.873998]\n",
            "1510 [D loss: 0.585971, acc.: 64.06%] [G loss: 0.869805]\n",
            "1511 [D loss: 0.610538, acc.: 57.81%] [G loss: 0.876631]\n",
            "1512 [D loss: 0.607035, acc.: 62.50%] [G loss: 0.875518]\n",
            "1513 [D loss: 0.597259, acc.: 62.50%] [G loss: 0.862426]\n",
            "1514 [D loss: 0.591495, acc.: 62.50%] [G loss: 0.863187]\n",
            "1515 [D loss: 0.596932, acc.: 62.50%] [G loss: 0.864126]\n",
            "1516 [D loss: 0.603230, acc.: 59.38%] [G loss: 0.861991]\n",
            "1517 [D loss: 0.585549, acc.: 64.06%] [G loss: 0.887541]\n",
            "1518 [D loss: 0.605314, acc.: 57.81%] [G loss: 0.872997]\n",
            "1519 [D loss: 0.595520, acc.: 62.50%] [G loss: 0.889005]\n",
            "1520 [D loss: 0.592067, acc.: 64.06%] [G loss: 0.842494]\n",
            "1521 [D loss: 0.603291, acc.: 59.38%] [G loss: 0.881192]\n",
            "1522 [D loss: 0.594755, acc.: 62.50%] [G loss: 0.869890]\n",
            "1523 [D loss: 0.592071, acc.: 60.94%] [G loss: 0.856536]\n",
            "1524 [D loss: 0.605189, acc.: 59.38%] [G loss: 0.872089]\n",
            "1525 [D loss: 0.605677, acc.: 60.94%] [G loss: 0.857818]\n",
            "1526 [D loss: 0.595948, acc.: 62.50%] [G loss: 0.875259]\n",
            "1527 [D loss: 0.600785, acc.: 60.94%] [G loss: 0.874175]\n",
            "1528 [D loss: 0.596658, acc.: 64.06%] [G loss: 0.881629]\n",
            "1529 [D loss: 0.598607, acc.: 62.50%] [G loss: 0.858404]\n",
            "1530 [D loss: 0.594774, acc.: 62.50%] [G loss: 0.873058]\n",
            "1531 [D loss: 0.605812, acc.: 62.50%] [G loss: 0.886217]\n",
            "1532 [D loss: 0.600879, acc.: 60.94%] [G loss: 0.890125]\n",
            "1533 [D loss: 0.601379, acc.: 62.50%] [G loss: 0.874128]\n",
            "1534 [D loss: 0.599229, acc.: 62.50%] [G loss: 0.878465]\n",
            "1535 [D loss: 0.598785, acc.: 60.94%] [G loss: 0.879655]\n",
            "1536 [D loss: 0.601876, acc.: 60.94%] [G loss: 0.878431]\n",
            "1537 [D loss: 0.600097, acc.: 60.94%] [G loss: 0.866086]\n",
            "1538 [D loss: 0.595832, acc.: 62.50%] [G loss: 0.881326]\n",
            "1539 [D loss: 0.593950, acc.: 62.50%] [G loss: 0.897982]\n",
            "1540 [D loss: 0.594701, acc.: 62.50%] [G loss: 0.886110]\n",
            "1541 [D loss: 0.586287, acc.: 62.50%] [G loss: 0.901562]\n",
            "1542 [D loss: 0.591316, acc.: 62.50%] [G loss: 0.881553]\n",
            "1543 [D loss: 0.602543, acc.: 62.50%] [G loss: 0.888159]\n",
            "1544 [D loss: 0.585768, acc.: 60.94%] [G loss: 0.893961]\n",
            "1545 [D loss: 0.611022, acc.: 59.38%] [G loss: 0.872371]\n",
            "1546 [D loss: 0.604224, acc.: 59.38%] [G loss: 0.874915]\n",
            "1547 [D loss: 0.595475, acc.: 62.50%] [G loss: 0.888746]\n",
            "1548 [D loss: 0.595532, acc.: 62.50%] [G loss: 0.891267]\n",
            "1549 [D loss: 0.593090, acc.: 62.50%] [G loss: 0.893177]\n",
            "1550 [D loss: 0.599920, acc.: 62.50%] [G loss: 0.886966]\n",
            "1551 [D loss: 0.594893, acc.: 62.50%] [G loss: 0.885180]\n",
            "1552 [D loss: 0.595262, acc.: 62.50%] [G loss: 0.888547]\n",
            "1553 [D loss: 0.595371, acc.: 62.50%] [G loss: 0.920012]\n",
            "1554 [D loss: 0.583401, acc.: 62.50%] [G loss: 0.895951]\n",
            "1555 [D loss: 0.606364, acc.: 62.50%] [G loss: 0.896625]\n",
            "1556 [D loss: 0.598918, acc.: 62.50%] [G loss: 0.888825]\n",
            "1557 [D loss: 0.595573, acc.: 62.50%] [G loss: 0.883780]\n",
            "1558 [D loss: 0.595175, acc.: 62.50%] [G loss: 0.892593]\n",
            "1559 [D loss: 0.603064, acc.: 62.50%] [G loss: 0.856355]\n",
            "1560 [D loss: 0.594759, acc.: 62.50%] [G loss: 0.884585]\n",
            "1561 [D loss: 0.604779, acc.: 62.50%] [G loss: 0.868792]\n",
            "1562 [D loss: 0.588969, acc.: 62.50%] [G loss: 0.871716]\n",
            "1563 [D loss: 0.577955, acc.: 64.06%] [G loss: 0.909990]\n",
            "1564 [D loss: 0.609100, acc.: 60.94%] [G loss: 0.898857]\n",
            "1565 [D loss: 0.606071, acc.: 62.50%] [G loss: 0.893160]\n",
            "1566 [D loss: 0.600680, acc.: 64.06%] [G loss: 0.901467]\n",
            "1567 [D loss: 0.585357, acc.: 64.06%] [G loss: 0.899309]\n",
            "1568 [D loss: 0.595587, acc.: 62.50%] [G loss: 0.913209]\n",
            "1569 [D loss: 0.603235, acc.: 62.50%] [G loss: 0.898551]\n",
            "1570 [D loss: 0.612502, acc.: 59.38%] [G loss: 0.895751]\n",
            "1571 [D loss: 0.599088, acc.: 60.94%] [G loss: 0.869997]\n",
            "1572 [D loss: 0.592854, acc.: 62.50%] [G loss: 0.864320]\n",
            "1573 [D loss: 0.604118, acc.: 62.50%] [G loss: 0.905146]\n",
            "1574 [D loss: 0.596071, acc.: 62.50%] [G loss: 0.896507]\n",
            "1575 [D loss: 0.592342, acc.: 62.50%] [G loss: 0.890333]\n",
            "1576 [D loss: 0.594208, acc.: 62.50%] [G loss: 0.887924]\n",
            "1577 [D loss: 0.592274, acc.: 60.94%] [G loss: 0.881451]\n",
            "1578 [D loss: 0.592974, acc.: 62.50%] [G loss: 0.878485]\n",
            "1579 [D loss: 0.605089, acc.: 56.25%] [G loss: 0.885422]\n",
            "1580 [D loss: 0.593009, acc.: 64.06%] [G loss: 0.885621]\n",
            "1581 [D loss: 0.584674, acc.: 62.50%] [G loss: 0.886659]\n",
            "1582 [D loss: 0.593215, acc.: 59.38%] [G loss: 0.899855]\n",
            "1583 [D loss: 0.600678, acc.: 60.94%] [G loss: 0.865999]\n",
            "1584 [D loss: 0.597820, acc.: 62.50%] [G loss: 0.887816]\n",
            "1585 [D loss: 0.601696, acc.: 62.50%] [G loss: 0.875280]\n",
            "1586 [D loss: 0.587609, acc.: 62.50%] [G loss: 0.855240]\n",
            "1587 [D loss: 0.596391, acc.: 60.94%] [G loss: 0.865298]\n",
            "1588 [D loss: 0.592936, acc.: 60.94%] [G loss: 0.876249]\n",
            "1589 [D loss: 0.599547, acc.: 60.94%] [G loss: 0.872449]\n",
            "1590 [D loss: 0.587340, acc.: 60.94%] [G loss: 0.888622]\n",
            "1591 [D loss: 0.600329, acc.: 59.38%] [G loss: 0.881293]\n",
            "1592 [D loss: 0.599682, acc.: 64.06%] [G loss: 0.870718]\n",
            "1593 [D loss: 0.589745, acc.: 65.62%] [G loss: 0.832042]\n",
            "1594 [D loss: 0.590965, acc.: 65.62%] [G loss: 0.837181]\n",
            "1595 [D loss: 0.590101, acc.: 62.50%] [G loss: 0.842398]\n",
            "1596 [D loss: 0.604309, acc.: 64.06%] [G loss: 0.878607]\n",
            "1597 [D loss: 0.595186, acc.: 60.94%] [G loss: 0.878388]\n",
            "1598 [D loss: 0.592625, acc.: 62.50%] [G loss: 0.904966]\n",
            "1599 [D loss: 0.607463, acc.: 62.50%] [G loss: 0.878539]\n",
            "1600 [D loss: 0.596392, acc.: 64.06%] [G loss: 0.873427]\n",
            "generated_data\n",
            "1601 [D loss: 0.605895, acc.: 60.94%] [G loss: 0.861741]\n",
            "1602 [D loss: 0.599972, acc.: 62.50%] [G loss: 0.887632]\n",
            "1603 [D loss: 0.587674, acc.: 62.50%] [G loss: 0.865111]\n",
            "1604 [D loss: 0.581449, acc.: 64.06%] [G loss: 0.937019]\n",
            "1605 [D loss: 0.621290, acc.: 59.38%] [G loss: 0.868174]\n",
            "1606 [D loss: 0.589636, acc.: 64.06%] [G loss: 0.891977]\n",
            "1607 [D loss: 0.592894, acc.: 64.06%] [G loss: 0.903775]\n",
            "1608 [D loss: 0.592855, acc.: 64.06%] [G loss: 0.901369]\n",
            "1609 [D loss: 0.598487, acc.: 64.06%] [G loss: 0.885146]\n",
            "1610 [D loss: 0.589195, acc.: 64.06%] [G loss: 0.886209]\n",
            "1611 [D loss: 0.593906, acc.: 62.50%] [G loss: 0.895792]\n",
            "1612 [D loss: 0.601138, acc.: 62.50%] [G loss: 0.883289]\n",
            "1613 [D loss: 0.596732, acc.: 60.94%] [G loss: 0.857289]\n",
            "1614 [D loss: 0.588419, acc.: 64.06%] [G loss: 0.906564]\n",
            "1615 [D loss: 0.611120, acc.: 64.06%] [G loss: 0.885369]\n",
            "1616 [D loss: 0.606483, acc.: 62.50%] [G loss: 0.870909]\n",
            "1617 [D loss: 0.612702, acc.: 60.94%] [G loss: 0.893004]\n",
            "1618 [D loss: 0.601227, acc.: 62.50%] [G loss: 0.888285]\n",
            "1619 [D loss: 0.595693, acc.: 62.50%] [G loss: 0.883081]\n",
            "1620 [D loss: 0.603044, acc.: 62.50%] [G loss: 0.883989]\n",
            "1621 [D loss: 0.599106, acc.: 62.50%] [G loss: 0.881544]\n",
            "1622 [D loss: 0.599869, acc.: 62.50%] [G loss: 0.857601]\n",
            "1623 [D loss: 0.604345, acc.: 60.94%] [G loss: 0.869802]\n",
            "1624 [D loss: 0.598609, acc.: 62.50%] [G loss: 0.860238]\n",
            "1625 [D loss: 0.595768, acc.: 60.94%] [G loss: 0.861442]\n",
            "1626 [D loss: 0.592058, acc.: 62.50%] [G loss: 0.860349]\n",
            "1627 [D loss: 0.596190, acc.: 62.50%] [G loss: 0.854305]\n",
            "1628 [D loss: 0.600401, acc.: 62.50%] [G loss: 0.878882]\n",
            "1629 [D loss: 0.595503, acc.: 62.50%] [G loss: 0.863164]\n",
            "1630 [D loss: 0.602167, acc.: 62.50%] [G loss: 0.879649]\n",
            "1631 [D loss: 0.590760, acc.: 62.50%] [G loss: 0.874364]\n",
            "1632 [D loss: 0.592588, acc.: 60.94%] [G loss: 0.843019]\n",
            "1633 [D loss: 0.600793, acc.: 62.50%] [G loss: 0.844000]\n",
            "1634 [D loss: 0.600913, acc.: 62.50%] [G loss: 0.847996]\n",
            "1635 [D loss: 0.598470, acc.: 62.50%] [G loss: 0.856745]\n",
            "1636 [D loss: 0.604996, acc.: 62.50%] [G loss: 0.860940]\n",
            "1637 [D loss: 0.598587, acc.: 59.38%] [G loss: 0.870275]\n",
            "1638 [D loss: 0.596457, acc.: 59.38%] [G loss: 0.870717]\n",
            "1639 [D loss: 0.595468, acc.: 60.94%] [G loss: 0.881008]\n",
            "1640 [D loss: 0.599860, acc.: 60.94%] [G loss: 0.866030]\n",
            "1641 [D loss: 0.596092, acc.: 62.50%] [G loss: 0.872588]\n",
            "1642 [D loss: 0.595556, acc.: 62.50%] [G loss: 0.867169]\n",
            "1643 [D loss: 0.603334, acc.: 60.94%] [G loss: 0.891841]\n",
            "1644 [D loss: 0.593724, acc.: 62.50%] [G loss: 0.864684]\n",
            "1645 [D loss: 0.596073, acc.: 60.94%] [G loss: 0.874687]\n",
            "1646 [D loss: 0.592639, acc.: 62.50%] [G loss: 0.872796]\n",
            "1647 [D loss: 0.604069, acc.: 62.50%] [G loss: 0.901067]\n",
            "1648 [D loss: 0.601397, acc.: 60.94%] [G loss: 0.872199]\n",
            "1649 [D loss: 0.601951, acc.: 64.06%] [G loss: 0.878082]\n",
            "1650 [D loss: 0.598082, acc.: 65.62%] [G loss: 0.909456]\n",
            "1651 [D loss: 0.587840, acc.: 65.62%] [G loss: 0.906202]\n",
            "1652 [D loss: 0.600643, acc.: 65.62%] [G loss: 0.906705]\n",
            "1653 [D loss: 0.599226, acc.: 64.06%] [G loss: 0.880749]\n",
            "1654 [D loss: 0.591556, acc.: 65.62%] [G loss: 0.890644]\n",
            "1655 [D loss: 0.598521, acc.: 62.50%] [G loss: 0.879677]\n",
            "1656 [D loss: 0.598167, acc.: 64.06%] [G loss: 0.876499]\n",
            "1657 [D loss: 0.605112, acc.: 59.38%] [G loss: 0.868319]\n",
            "1658 [D loss: 0.604837, acc.: 60.94%] [G loss: 0.876854]\n",
            "1659 [D loss: 0.604369, acc.: 60.94%] [G loss: 0.892933]\n",
            "1660 [D loss: 0.597651, acc.: 60.94%] [G loss: 0.850658]\n",
            "1661 [D loss: 0.614337, acc.: 60.94%] [G loss: 0.875276]\n",
            "1662 [D loss: 0.604134, acc.: 57.81%] [G loss: 0.884186]\n",
            "1663 [D loss: 0.612762, acc.: 57.81%] [G loss: 0.874298]\n",
            "1664 [D loss: 0.597016, acc.: 62.50%] [G loss: 0.902560]\n",
            "1665 [D loss: 0.600293, acc.: 62.50%] [G loss: 0.890590]\n",
            "1666 [D loss: 0.591053, acc.: 64.06%] [G loss: 0.879797]\n",
            "1667 [D loss: 0.620209, acc.: 57.81%] [G loss: 0.847573]\n",
            "1668 [D loss: 0.595304, acc.: 60.94%] [G loss: 0.883330]\n",
            "1669 [D loss: 0.612997, acc.: 59.38%] [G loss: 0.871225]\n",
            "1670 [D loss: 0.596997, acc.: 62.50%] [G loss: 0.874854]\n",
            "1671 [D loss: 0.594401, acc.: 57.81%] [G loss: 0.859692]\n",
            "1672 [D loss: 0.592152, acc.: 62.50%] [G loss: 0.908956]\n",
            "1673 [D loss: 0.603714, acc.: 60.94%] [G loss: 0.852315]\n",
            "1674 [D loss: 0.612131, acc.: 57.81%] [G loss: 0.902399]\n",
            "1675 [D loss: 0.606043, acc.: 59.38%] [G loss: 0.870023]\n",
            "1676 [D loss: 0.604202, acc.: 62.50%] [G loss: 0.888698]\n",
            "1677 [D loss: 0.593712, acc.: 62.50%] [G loss: 0.889964]\n",
            "1678 [D loss: 0.589467, acc.: 64.06%] [G loss: 0.934031]\n",
            "1679 [D loss: 0.593432, acc.: 64.06%] [G loss: 0.909113]\n",
            "1680 [D loss: 0.597419, acc.: 62.50%] [G loss: 0.908189]\n",
            "1681 [D loss: 0.597036, acc.: 62.50%] [G loss: 0.896957]\n",
            "1682 [D loss: 0.594662, acc.: 62.50%] [G loss: 0.899108]\n",
            "1683 [D loss: 0.596018, acc.: 62.50%] [G loss: 0.896375]\n",
            "1684 [D loss: 0.595853, acc.: 64.06%] [G loss: 0.883770]\n",
            "1685 [D loss: 0.593888, acc.: 64.06%] [G loss: 0.891145]\n",
            "1686 [D loss: 0.600885, acc.: 64.06%] [G loss: 0.882587]\n",
            "1687 [D loss: 0.593446, acc.: 64.06%] [G loss: 0.887403]\n",
            "1688 [D loss: 0.601109, acc.: 62.50%] [G loss: 0.919485]\n",
            "1689 [D loss: 0.609257, acc.: 62.50%] [G loss: 0.880350]\n",
            "1690 [D loss: 0.589862, acc.: 64.06%] [G loss: 0.858258]\n",
            "1691 [D loss: 0.595334, acc.: 62.50%] [G loss: 0.879934]\n",
            "1692 [D loss: 0.596939, acc.: 62.50%] [G loss: 0.878218]\n",
            "1693 [D loss: 0.593267, acc.: 64.06%] [G loss: 0.891649]\n",
            "1694 [D loss: 0.601036, acc.: 62.50%] [G loss: 0.889104]\n",
            "1695 [D loss: 0.595312, acc.: 62.50%] [G loss: 0.868394]\n",
            "1696 [D loss: 0.596626, acc.: 62.50%] [G loss: 0.871644]\n",
            "1697 [D loss: 0.599410, acc.: 60.94%] [G loss: 0.880645]\n",
            "1698 [D loss: 0.589374, acc.: 62.50%] [G loss: 0.872558]\n",
            "1699 [D loss: 0.596784, acc.: 60.94%] [G loss: 0.864512]\n",
            "1700 [D loss: 0.600178, acc.: 59.38%] [G loss: 0.854592]\n",
            "generated_data\n",
            "1701 [D loss: 0.592414, acc.: 62.50%] [G loss: 0.865948]\n",
            "1702 [D loss: 0.597030, acc.: 62.50%] [G loss: 0.866486]\n",
            "1703 [D loss: 0.592895, acc.: 62.50%] [G loss: 0.862819]\n",
            "1704 [D loss: 0.585646, acc.: 62.50%] [G loss: 0.857955]\n",
            "1705 [D loss: 0.598596, acc.: 62.50%] [G loss: 0.882367]\n",
            "1706 [D loss: 0.602300, acc.: 62.50%] [G loss: 0.882975]\n",
            "1707 [D loss: 0.594962, acc.: 60.94%] [G loss: 0.871317]\n",
            "1708 [D loss: 0.597994, acc.: 62.50%] [G loss: 0.868971]\n",
            "1709 [D loss: 0.605885, acc.: 60.94%] [G loss: 0.893160]\n",
            "1710 [D loss: 0.611120, acc.: 60.94%] [G loss: 0.900625]\n",
            "1711 [D loss: 0.611243, acc.: 62.50%] [G loss: 0.868207]\n",
            "1712 [D loss: 0.633010, acc.: 56.25%] [G loss: 0.874643]\n",
            "1713 [D loss: 0.604601, acc.: 62.50%] [G loss: 0.867832]\n",
            "1714 [D loss: 0.604487, acc.: 62.50%] [G loss: 0.869020]\n",
            "1715 [D loss: 0.598169, acc.: 62.50%] [G loss: 0.883781]\n",
            "1716 [D loss: 0.598170, acc.: 62.50%] [G loss: 0.884965]\n",
            "1717 [D loss: 0.592349, acc.: 62.50%] [G loss: 0.895516]\n",
            "1718 [D loss: 0.596088, acc.: 62.50%] [G loss: 0.933820]\n",
            "1719 [D loss: 0.609868, acc.: 62.50%] [G loss: 0.907135]\n",
            "1720 [D loss: 0.608514, acc.: 62.50%] [G loss: 0.882686]\n",
            "1721 [D loss: 0.590200, acc.: 62.50%] [G loss: 0.906313]\n",
            "1722 [D loss: 0.598504, acc.: 62.50%] [G loss: 0.883515]\n",
            "1723 [D loss: 0.594180, acc.: 62.50%] [G loss: 0.875192]\n",
            "1724 [D loss: 0.601824, acc.: 62.50%] [G loss: 0.877790]\n",
            "1725 [D loss: 0.598983, acc.: 62.50%] [G loss: 0.882525]\n",
            "1726 [D loss: 0.598173, acc.: 62.50%] [G loss: 0.890616]\n",
            "1727 [D loss: 0.597414, acc.: 62.50%] [G loss: 0.888417]\n",
            "1728 [D loss: 0.606396, acc.: 62.50%] [G loss: 0.879076]\n",
            "1729 [D loss: 0.611725, acc.: 62.50%] [G loss: 0.880684]\n",
            "1730 [D loss: 0.601426, acc.: 62.50%] [G loss: 0.870037]\n",
            "1731 [D loss: 0.599777, acc.: 62.50%] [G loss: 0.863699]\n",
            "1732 [D loss: 0.604308, acc.: 62.50%] [G loss: 0.871474]\n",
            "1733 [D loss: 0.606010, acc.: 62.50%] [G loss: 0.871896]\n",
            "1734 [D loss: 0.603996, acc.: 60.94%] [G loss: 0.866432]\n",
            "1735 [D loss: 0.591301, acc.: 62.50%] [G loss: 0.881603]\n",
            "1736 [D loss: 0.594648, acc.: 62.50%] [G loss: 0.878489]\n",
            "1737 [D loss: 0.594587, acc.: 62.50%] [G loss: 0.911041]\n",
            "1738 [D loss: 0.595933, acc.: 60.94%] [G loss: 0.874448]\n",
            "1739 [D loss: 0.599494, acc.: 62.50%] [G loss: 0.864880]\n",
            "1740 [D loss: 0.606210, acc.: 62.50%] [G loss: 0.857799]\n",
            "1741 [D loss: 0.593841, acc.: 60.94%] [G loss: 0.851472]\n",
            "1742 [D loss: 0.605932, acc.: 60.94%] [G loss: 0.882838]\n",
            "1743 [D loss: 0.599990, acc.: 62.50%] [G loss: 0.859358]\n",
            "1744 [D loss: 0.604032, acc.: 60.94%] [G loss: 0.873256]\n",
            "1745 [D loss: 0.600140, acc.: 60.94%] [G loss: 0.867749]\n",
            "1746 [D loss: 0.610737, acc.: 59.38%] [G loss: 0.865560]\n",
            "1747 [D loss: 0.596542, acc.: 62.50%] [G loss: 0.862560]\n",
            "1748 [D loss: 0.590956, acc.: 60.94%] [G loss: 0.861683]\n",
            "1749 [D loss: 0.600822, acc.: 62.50%] [G loss: 0.846047]\n",
            "1750 [D loss: 0.618383, acc.: 57.81%] [G loss: 0.884555]\n",
            "1751 [D loss: 0.596926, acc.: 62.50%] [G loss: 0.867740]\n",
            "1752 [D loss: 0.600350, acc.: 62.50%] [G loss: 0.876791]\n",
            "1753 [D loss: 0.602579, acc.: 62.50%] [G loss: 0.875491]\n",
            "1754 [D loss: 0.598157, acc.: 64.06%] [G loss: 0.867283]\n",
            "1755 [D loss: 0.590315, acc.: 64.06%] [G loss: 0.879856]\n",
            "1756 [D loss: 0.591015, acc.: 60.94%] [G loss: 0.878073]\n",
            "1757 [D loss: 0.615516, acc.: 62.50%] [G loss: 0.849345]\n",
            "1758 [D loss: 0.606950, acc.: 60.94%] [G loss: 0.873265]\n",
            "1759 [D loss: 0.597407, acc.: 62.50%] [G loss: 0.889963]\n",
            "1760 [D loss: 0.589109, acc.: 62.50%] [G loss: 0.896393]\n",
            "1761 [D loss: 0.592463, acc.: 64.06%] [G loss: 0.873575]\n",
            "1762 [D loss: 0.606503, acc.: 60.94%] [G loss: 0.858889]\n",
            "1763 [D loss: 0.596973, acc.: 62.50%] [G loss: 0.874300]\n",
            "1764 [D loss: 0.600751, acc.: 64.06%] [G loss: 0.868580]\n",
            "1765 [D loss: 0.599631, acc.: 65.62%] [G loss: 0.872721]\n",
            "1766 [D loss: 0.607761, acc.: 60.94%] [G loss: 0.860357]\n",
            "1767 [D loss: 0.590967, acc.: 64.06%] [G loss: 0.858967]\n",
            "1768 [D loss: 0.595767, acc.: 62.50%] [G loss: 0.851634]\n",
            "1769 [D loss: 0.585618, acc.: 68.75%] [G loss: 0.816864]\n",
            "1770 [D loss: 0.623743, acc.: 54.69%] [G loss: 0.819826]\n",
            "1771 [D loss: 0.597544, acc.: 62.50%] [G loss: 0.806476]\n",
            "1772 [D loss: 0.598677, acc.: 62.50%] [G loss: 0.848136]\n",
            "1773 [D loss: 0.627154, acc.: 54.69%] [G loss: 0.858099]\n",
            "1774 [D loss: 0.598286, acc.: 62.50%] [G loss: 0.871734]\n",
            "1775 [D loss: 0.595358, acc.: 62.50%] [G loss: 0.871509]\n",
            "1776 [D loss: 0.597403, acc.: 62.50%] [G loss: 0.871007]\n",
            "1777 [D loss: 0.592840, acc.: 62.50%] [G loss: 0.883590]\n",
            "1778 [D loss: 0.598917, acc.: 64.06%] [G loss: 0.871727]\n",
            "1779 [D loss: 0.599765, acc.: 62.50%] [G loss: 0.865076]\n",
            "1780 [D loss: 0.592543, acc.: 64.06%] [G loss: 0.872267]\n",
            "1781 [D loss: 0.589123, acc.: 64.06%] [G loss: 0.861018]\n",
            "1782 [D loss: 0.599143, acc.: 62.50%] [G loss: 0.852865]\n",
            "1783 [D loss: 0.599049, acc.: 64.06%] [G loss: 0.862613]\n",
            "1784 [D loss: 0.609041, acc.: 56.25%] [G loss: 0.861249]\n",
            "1785 [D loss: 0.599892, acc.: 62.50%] [G loss: 0.867365]\n",
            "1786 [D loss: 0.599867, acc.: 60.94%] [G loss: 0.853813]\n",
            "1787 [D loss: 0.597228, acc.: 62.50%] [G loss: 0.841422]\n",
            "1788 [D loss: 0.597109, acc.: 62.50%] [G loss: 0.847272]\n",
            "1789 [D loss: 0.596802, acc.: 62.50%] [G loss: 0.849870]\n",
            "1790 [D loss: 0.611331, acc.: 60.94%] [G loss: 0.862465]\n",
            "1791 [D loss: 0.591181, acc.: 60.94%] [G loss: 0.862566]\n",
            "1792 [D loss: 0.604421, acc.: 60.94%] [G loss: 0.884682]\n",
            "1793 [D loss: 0.605845, acc.: 60.94%] [G loss: 0.902876]\n",
            "1794 [D loss: 0.603252, acc.: 62.50%] [G loss: 0.889577]\n",
            "1795 [D loss: 0.607834, acc.: 62.50%] [G loss: 0.871030]\n",
            "1796 [D loss: 0.594395, acc.: 62.50%] [G loss: 0.880024]\n",
            "1797 [D loss: 0.591797, acc.: 62.50%] [G loss: 0.891083]\n",
            "1798 [D loss: 0.594499, acc.: 62.50%] [G loss: 0.878664]\n",
            "1799 [D loss: 0.595580, acc.: 62.50%] [G loss: 0.895760]\n",
            "1800 [D loss: 0.600645, acc.: 64.06%] [G loss: 0.910172]\n",
            "generated_data\n",
            "1801 [D loss: 0.604479, acc.: 62.50%] [G loss: 0.875837]\n",
            "1802 [D loss: 0.597596, acc.: 62.50%] [G loss: 0.875333]\n",
            "1803 [D loss: 0.591557, acc.: 60.94%] [G loss: 0.867140]\n",
            "1804 [D loss: 0.594381, acc.: 64.06%] [G loss: 0.871954]\n",
            "1805 [D loss: 0.600217, acc.: 59.38%] [G loss: 0.842649]\n",
            "1806 [D loss: 0.602800, acc.: 60.94%] [G loss: 0.850235]\n",
            "1807 [D loss: 0.604680, acc.: 64.06%] [G loss: 0.853244]\n",
            "1808 [D loss: 0.600929, acc.: 62.50%] [G loss: 0.865330]\n",
            "1809 [D loss: 0.592411, acc.: 62.50%] [G loss: 0.867721]\n",
            "1810 [D loss: 0.603871, acc.: 62.50%] [G loss: 0.867717]\n",
            "1811 [D loss: 0.599549, acc.: 62.50%] [G loss: 0.861962]\n",
            "1812 [D loss: 0.594592, acc.: 62.50%] [G loss: 0.857898]\n",
            "1813 [D loss: 0.598651, acc.: 62.50%] [G loss: 0.878374]\n",
            "1814 [D loss: 0.594274, acc.: 62.50%] [G loss: 0.873928]\n",
            "1815 [D loss: 0.595338, acc.: 62.50%] [G loss: 0.893625]\n",
            "1816 [D loss: 0.597965, acc.: 62.50%] [G loss: 0.866333]\n",
            "1817 [D loss: 0.598087, acc.: 62.50%] [G loss: 0.861045]\n",
            "1818 [D loss: 0.599837, acc.: 62.50%] [G loss: 0.869683]\n",
            "1819 [D loss: 0.600461, acc.: 60.94%] [G loss: 0.852795]\n",
            "1820 [D loss: 0.603978, acc.: 59.38%] [G loss: 0.871600]\n",
            "1821 [D loss: 0.585083, acc.: 62.50%] [G loss: 1.079508]\n",
            "1822 [D loss: 0.679806, acc.: 60.94%] [G loss: 0.854486]\n",
            "1823 [D loss: 0.612819, acc.: 60.94%] [G loss: 0.871746]\n",
            "1824 [D loss: 0.607318, acc.: 62.50%] [G loss: 0.872347]\n",
            "1825 [D loss: 0.597098, acc.: 62.50%] [G loss: 0.874292]\n",
            "1826 [D loss: 0.595776, acc.: 62.50%] [G loss: 0.859438]\n",
            "1827 [D loss: 0.601803, acc.: 64.06%] [G loss: 0.866573]\n",
            "1828 [D loss: 0.592765, acc.: 62.50%] [G loss: 0.865190]\n",
            "1829 [D loss: 0.596922, acc.: 62.50%] [G loss: 0.874126]\n",
            "1830 [D loss: 0.599266, acc.: 62.50%] [G loss: 0.880637]\n",
            "1831 [D loss: 0.600830, acc.: 62.50%] [G loss: 0.863599]\n",
            "1832 [D loss: 0.598251, acc.: 62.50%] [G loss: 0.868296]\n",
            "1833 [D loss: 0.606252, acc.: 62.50%] [G loss: 0.869273]\n",
            "1834 [D loss: 0.598581, acc.: 62.50%] [G loss: 0.853227]\n",
            "1835 [D loss: 0.606392, acc.: 62.50%] [G loss: 0.876214]\n",
            "1836 [D loss: 0.594465, acc.: 62.50%] [G loss: 0.859374]\n",
            "1837 [D loss: 0.593709, acc.: 62.50%] [G loss: 0.866923]\n",
            "1838 [D loss: 0.596995, acc.: 62.50%] [G loss: 0.871534]\n",
            "1839 [D loss: 0.591848, acc.: 62.50%] [G loss: 0.859332]\n",
            "1840 [D loss: 0.592844, acc.: 62.50%] [G loss: 0.867973]\n",
            "1841 [D loss: 0.596772, acc.: 62.50%] [G loss: 0.860122]\n",
            "1842 [D loss: 0.600708, acc.: 60.94%] [G loss: 0.850183]\n",
            "1843 [D loss: 0.600287, acc.: 62.50%] [G loss: 0.842433]\n",
            "1844 [D loss: 0.610086, acc.: 60.94%] [G loss: 0.868798]\n",
            "1845 [D loss: 0.598954, acc.: 62.50%] [G loss: 0.863835]\n",
            "1846 [D loss: 0.595534, acc.: 62.50%] [G loss: 0.866467]\n",
            "1847 [D loss: 0.592249, acc.: 62.50%] [G loss: 0.855106]\n",
            "1848 [D loss: 0.600224, acc.: 62.50%] [G loss: 0.868606]\n",
            "1849 [D loss: 0.594267, acc.: 62.50%] [G loss: 0.871224]\n",
            "1850 [D loss: 0.598241, acc.: 62.50%] [G loss: 0.861234]\n",
            "1851 [D loss: 0.596079, acc.: 62.50%] [G loss: 0.863159]\n",
            "1852 [D loss: 0.599524, acc.: 62.50%] [G loss: 0.859889]\n",
            "1853 [D loss: 0.592396, acc.: 62.50%] [G loss: 0.863477]\n",
            "1854 [D loss: 0.605682, acc.: 62.50%] [G loss: 0.867381]\n",
            "1855 [D loss: 0.593889, acc.: 62.50%] [G loss: 0.868980]\n",
            "1856 [D loss: 0.604145, acc.: 60.94%] [G loss: 0.845281]\n",
            "1857 [D loss: 0.595969, acc.: 62.50%] [G loss: 0.861402]\n",
            "1858 [D loss: 0.595215, acc.: 62.50%] [G loss: 0.877113]\n",
            "1859 [D loss: 0.594517, acc.: 62.50%] [G loss: 0.851203]\n",
            "1860 [D loss: 0.593958, acc.: 62.50%] [G loss: 0.859360]\n",
            "1861 [D loss: 0.600009, acc.: 62.50%] [G loss: 0.835656]\n",
            "1862 [D loss: 0.632642, acc.: 53.12%] [G loss: 0.864057]\n",
            "1863 [D loss: 0.596688, acc.: 62.50%] [G loss: 0.852714]\n",
            "1864 [D loss: 0.593344, acc.: 62.50%] [G loss: 0.857611]\n",
            "1865 [D loss: 0.593182, acc.: 62.50%] [G loss: 0.858035]\n",
            "1866 [D loss: 0.592672, acc.: 60.94%] [G loss: 0.887503]\n",
            "1867 [D loss: 0.599525, acc.: 62.50%] [G loss: 0.860081]\n",
            "1868 [D loss: 0.600694, acc.: 62.50%] [G loss: 0.854999]\n",
            "1869 [D loss: 0.590170, acc.: 62.50%] [G loss: 0.864123]\n",
            "1870 [D loss: 0.603218, acc.: 62.50%] [G loss: 0.865614]\n",
            "1871 [D loss: 0.597858, acc.: 60.94%] [G loss: 0.873855]\n",
            "1872 [D loss: 0.593262, acc.: 62.50%] [G loss: 0.870167]\n",
            "1873 [D loss: 0.598373, acc.: 62.50%] [G loss: 0.877144]\n",
            "1874 [D loss: 0.596881, acc.: 62.50%] [G loss: 0.863222]\n",
            "1875 [D loss: 0.592517, acc.: 62.50%] [G loss: 0.878512]\n",
            "1876 [D loss: 0.587392, acc.: 62.50%] [G loss: 0.864627]\n",
            "1877 [D loss: 0.596004, acc.: 62.50%] [G loss: 0.890761]\n",
            "1878 [D loss: 0.595240, acc.: 62.50%] [G loss: 0.865994]\n",
            "1879 [D loss: 0.605196, acc.: 62.50%] [G loss: 0.870781]\n",
            "1880 [D loss: 0.598474, acc.: 60.94%] [G loss: 0.848445]\n",
            "1881 [D loss: 0.600140, acc.: 60.94%] [G loss: 0.869658]\n",
            "1882 [D loss: 0.595807, acc.: 62.50%] [G loss: 0.924920]\n",
            "1883 [D loss: 0.604888, acc.: 62.50%] [G loss: 0.897303]\n",
            "1884 [D loss: 0.605179, acc.: 60.94%] [G loss: 0.854944]\n",
            "1885 [D loss: 0.597110, acc.: 62.50%] [G loss: 0.907659]\n",
            "1886 [D loss: 0.587759, acc.: 62.50%] [G loss: 0.891678]\n",
            "1887 [D loss: 0.590847, acc.: 62.50%] [G loss: 0.870842]\n",
            "1888 [D loss: 0.593151, acc.: 62.50%] [G loss: 0.880236]\n",
            "1889 [D loss: 0.589858, acc.: 62.50%] [G loss: 0.863741]\n",
            "1890 [D loss: 0.600840, acc.: 62.50%] [G loss: 0.854344]\n",
            "1891 [D loss: 0.595461, acc.: 62.50%] [G loss: 0.859352]\n",
            "1892 [D loss: 0.594491, acc.: 62.50%] [G loss: 0.878338]\n",
            "1893 [D loss: 0.597717, acc.: 62.50%] [G loss: 0.869778]\n",
            "1894 [D loss: 0.600932, acc.: 62.50%] [G loss: 0.861520]\n",
            "1895 [D loss: 0.597615, acc.: 62.50%] [G loss: 0.868806]\n",
            "1896 [D loss: 0.599152, acc.: 62.50%] [G loss: 0.854709]\n",
            "1897 [D loss: 0.599029, acc.: 62.50%] [G loss: 0.850475]\n",
            "1898 [D loss: 0.606448, acc.: 62.50%] [G loss: 0.893246]\n",
            "1899 [D loss: 0.599414, acc.: 62.50%] [G loss: 0.865727]\n",
            "1900 [D loss: 0.601466, acc.: 62.50%] [G loss: 0.868573]\n",
            "generated_data\n",
            "1901 [D loss: 0.607572, acc.: 62.50%] [G loss: 0.870782]\n",
            "1902 [D loss: 0.592822, acc.: 62.50%] [G loss: 0.873090]\n",
            "1903 [D loss: 0.600945, acc.: 62.50%] [G loss: 0.899665]\n",
            "1904 [D loss: 0.587835, acc.: 62.50%] [G loss: 0.912468]\n",
            "1905 [D loss: 0.597660, acc.: 62.50%] [G loss: 0.867761]\n",
            "1906 [D loss: 0.595239, acc.: 62.50%] [G loss: 0.886569]\n",
            "1907 [D loss: 0.598760, acc.: 62.50%] [G loss: 0.878738]\n",
            "1908 [D loss: 0.597523, acc.: 62.50%] [G loss: 0.872653]\n",
            "1909 [D loss: 0.600798, acc.: 62.50%] [G loss: 0.864603]\n",
            "1910 [D loss: 0.594861, acc.: 62.50%] [G loss: 0.872902]\n",
            "1911 [D loss: 0.597533, acc.: 62.50%] [G loss: 0.861384]\n",
            "1912 [D loss: 0.593995, acc.: 62.50%] [G loss: 0.877328]\n",
            "1913 [D loss: 0.604226, acc.: 62.50%] [G loss: 0.861505]\n",
            "1914 [D loss: 0.598023, acc.: 59.38%] [G loss: 0.846035]\n",
            "1915 [D loss: 0.594360, acc.: 64.06%] [G loss: 0.854014]\n",
            "1916 [D loss: 0.597954, acc.: 62.50%] [G loss: 0.858086]\n",
            "1917 [D loss: 0.614179, acc.: 56.25%] [G loss: 0.873696]\n",
            "1918 [D loss: 0.598887, acc.: 62.50%] [G loss: 0.878000]\n",
            "1919 [D loss: 0.596344, acc.: 62.50%] [G loss: 0.872463]\n",
            "1920 [D loss: 0.596487, acc.: 62.50%] [G loss: 0.869502]\n",
            "1921 [D loss: 0.595245, acc.: 62.50%] [G loss: 0.868151]\n",
            "1922 [D loss: 0.597692, acc.: 60.94%] [G loss: 0.863718]\n",
            "1923 [D loss: 0.602606, acc.: 64.06%] [G loss: 0.866776]\n",
            "1924 [D loss: 0.595737, acc.: 62.50%] [G loss: 0.880937]\n",
            "1925 [D loss: 0.598133, acc.: 60.94%] [G loss: 0.870620]\n",
            "1926 [D loss: 0.595645, acc.: 62.50%] [G loss: 0.875156]\n",
            "1927 [D loss: 0.597713, acc.: 62.50%] [G loss: 0.881385]\n",
            "1928 [D loss: 0.600270, acc.: 62.50%] [G loss: 0.851990]\n",
            "1929 [D loss: 0.598834, acc.: 62.50%] [G loss: 0.867213]\n",
            "1930 [D loss: 0.594722, acc.: 62.50%] [G loss: 0.865828]\n",
            "1931 [D loss: 0.597927, acc.: 62.50%] [G loss: 0.860016]\n",
            "1932 [D loss: 0.598476, acc.: 62.50%] [G loss: 0.862970]\n",
            "1933 [D loss: 0.596782, acc.: 62.50%] [G loss: 0.862836]\n",
            "1934 [D loss: 0.594886, acc.: 62.50%] [G loss: 0.849929]\n",
            "1935 [D loss: 0.599392, acc.: 62.50%] [G loss: 0.855305]\n",
            "1936 [D loss: 0.591351, acc.: 62.50%] [G loss: 0.871882]\n",
            "1937 [D loss: 0.599492, acc.: 62.50%] [G loss: 0.854766]\n",
            "1938 [D loss: 0.600875, acc.: 60.94%] [G loss: 0.837517]\n",
            "1939 [D loss: 0.599858, acc.: 62.50%] [G loss: 0.844315]\n",
            "1940 [D loss: 0.598835, acc.: 64.06%] [G loss: 0.875251]\n",
            "1941 [D loss: 0.599237, acc.: 62.50%] [G loss: 0.854459]\n",
            "1942 [D loss: 0.600257, acc.: 62.50%] [G loss: 0.877049]\n",
            "1943 [D loss: 0.594906, acc.: 62.50%] [G loss: 0.878446]\n",
            "1944 [D loss: 0.597762, acc.: 62.50%] [G loss: 0.880857]\n",
            "1945 [D loss: 0.593053, acc.: 62.50%] [G loss: 0.878110]\n",
            "1946 [D loss: 0.599428, acc.: 62.50%] [G loss: 0.866700]\n",
            "1947 [D loss: 0.592574, acc.: 62.50%] [G loss: 0.884920]\n",
            "1948 [D loss: 0.596646, acc.: 62.50%] [G loss: 0.874083]\n",
            "1949 [D loss: 0.599837, acc.: 62.50%] [G loss: 0.871952]\n",
            "1950 [D loss: 0.598368, acc.: 62.50%] [G loss: 0.877874]\n",
            "1951 [D loss: 0.596256, acc.: 62.50%] [G loss: 0.864118]\n",
            "1952 [D loss: 0.594621, acc.: 62.50%] [G loss: 0.884250]\n",
            "1953 [D loss: 0.598547, acc.: 62.50%] [G loss: 0.867807]\n",
            "1954 [D loss: 0.589804, acc.: 62.50%] [G loss: 0.856870]\n",
            "1955 [D loss: 0.597876, acc.: 62.50%] [G loss: 0.856019]\n",
            "1956 [D loss: 0.600098, acc.: 62.50%] [G loss: 0.885613]\n",
            "1957 [D loss: 0.598929, acc.: 62.50%] [G loss: 0.883394]\n",
            "1958 [D loss: 0.594226, acc.: 62.50%] [G loss: 0.869894]\n",
            "1959 [D loss: 0.597615, acc.: 62.50%] [G loss: 0.851133]\n",
            "1960 [D loss: 1.110988, acc.: 37.50%] [G loss: 0.904444]\n",
            "1961 [D loss: 0.595954, acc.: 62.50%] [G loss: 0.922608]\n",
            "1962 [D loss: 0.605778, acc.: 62.50%] [G loss: 0.909012]\n",
            "1963 [D loss: 0.606352, acc.: 62.50%] [G loss: 0.886926]\n",
            "1964 [D loss: 0.598967, acc.: 62.50%] [G loss: 0.879155]\n",
            "1965 [D loss: 0.598116, acc.: 62.50%] [G loss: 0.881883]\n",
            "1966 [D loss: 0.595332, acc.: 62.50%] [G loss: 0.883772]\n",
            "1967 [D loss: 0.601157, acc.: 62.50%] [G loss: 0.868379]\n",
            "1968 [D loss: 0.608467, acc.: 62.50%] [G loss: 0.839898]\n",
            "1969 [D loss: 0.611470, acc.: 62.50%] [G loss: 0.851947]\n",
            "1970 [D loss: 0.606012, acc.: 62.50%] [G loss: 0.849934]\n",
            "1971 [D loss: 0.613897, acc.: 62.50%] [G loss: 0.854609]\n",
            "1972 [D loss: 0.603233, acc.: 62.50%] [G loss: 0.856469]\n",
            "1973 [D loss: 0.603993, acc.: 62.50%] [G loss: 0.840650]\n",
            "1974 [D loss: 0.602546, acc.: 62.50%] [G loss: 0.866065]\n",
            "1975 [D loss: 0.605144, acc.: 62.50%] [G loss: 0.874649]\n",
            "1976 [D loss: 0.608500, acc.: 62.50%] [G loss: 0.858933]\n",
            "1977 [D loss: 0.610109, acc.: 60.94%] [G loss: 0.861174]\n",
            "1978 [D loss: 0.604079, acc.: 62.50%] [G loss: 0.845178]\n",
            "1979 [D loss: 0.596769, acc.: 62.50%] [G loss: 0.845495]\n",
            "1980 [D loss: 0.602482, acc.: 62.50%] [G loss: 0.845925]\n",
            "1981 [D loss: 0.597801, acc.: 62.50%] [G loss: 0.849066]\n",
            "1982 [D loss: 0.599684, acc.: 62.50%] [G loss: 0.861914]\n",
            "1983 [D loss: 0.602997, acc.: 62.50%] [G loss: 0.843161]\n",
            "1984 [D loss: 0.601207, acc.: 62.50%] [G loss: 0.840064]\n",
            "1985 [D loss: 0.599863, acc.: 62.50%] [G loss: 0.835160]\n",
            "1986 [D loss: 0.607963, acc.: 62.50%] [G loss: 0.844233]\n",
            "1987 [D loss: 0.601864, acc.: 62.50%] [G loss: 0.848372]\n",
            "1988 [D loss: 0.615468, acc.: 57.81%] [G loss: 0.834017]\n",
            "1989 [D loss: 0.599465, acc.: 62.50%] [G loss: 0.842610]\n",
            "1990 [D loss: 0.614171, acc.: 64.06%] [G loss: 0.832997]\n",
            "1991 [D loss: 0.598751, acc.: 62.50%] [G loss: 0.833238]\n",
            "1992 [D loss: 0.598678, acc.: 64.06%] [G loss: 0.835316]\n",
            "1993 [D loss: 0.589374, acc.: 65.62%] [G loss: 0.839737]\n",
            "1994 [D loss: 0.597965, acc.: 64.06%] [G loss: 0.838066]\n",
            "1995 [D loss: 0.593134, acc.: 64.06%] [G loss: 0.827679]\n",
            "1996 [D loss: 0.592601, acc.: 64.06%] [G loss: 0.834433]\n",
            "1997 [D loss: 0.599137, acc.: 60.94%] [G loss: 0.840207]\n",
            "1998 [D loss: 0.598637, acc.: 62.50%] [G loss: 0.835970]\n",
            "1999 [D loss: 0.592010, acc.: 65.62%] [G loss: 0.836174]\n",
            "2000 [D loss: 0.591687, acc.: 64.06%] [G loss: 0.821730]\n",
            "generated_data\n",
            "2001 [D loss: 0.598712, acc.: 62.50%] [G loss: 0.846227]\n",
            "2002 [D loss: 0.594266, acc.: 60.94%] [G loss: 0.839865]\n",
            "2003 [D loss: 0.602560, acc.: 64.06%] [G loss: 0.825240]\n",
            "2004 [D loss: 0.612109, acc.: 57.81%] [G loss: 0.858933]\n",
            "2005 [D loss: 0.607825, acc.: 60.94%] [G loss: 0.859463]\n",
            "2006 [D loss: 0.595301, acc.: 60.94%] [G loss: 0.889161]\n",
            "2007 [D loss: 0.600867, acc.: 62.50%] [G loss: 0.864474]\n",
            "2008 [D loss: 0.588017, acc.: 62.50%] [G loss: 0.869022]\n",
            "2009 [D loss: 0.602883, acc.: 62.50%] [G loss: 0.863660]\n",
            "2010 [D loss: 0.606842, acc.: 60.94%] [G loss: 0.868966]\n",
            "2011 [D loss: 0.594860, acc.: 62.50%] [G loss: 0.846207]\n",
            "2012 [D loss: 0.599359, acc.: 62.50%] [G loss: 0.861749]\n",
            "2013 [D loss: 0.599493, acc.: 62.50%] [G loss: 0.855325]\n",
            "2014 [D loss: 0.596464, acc.: 62.50%] [G loss: 0.854944]\n",
            "2015 [D loss: 0.599241, acc.: 57.81%] [G loss: 0.878482]\n",
            "2016 [D loss: 0.590614, acc.: 64.06%] [G loss: 0.873058]\n",
            "2017 [D loss: 0.598684, acc.: 62.50%] [G loss: 0.892570]\n",
            "2018 [D loss: 0.602728, acc.: 64.06%] [G loss: 0.896192]\n",
            "2019 [D loss: 0.609157, acc.: 60.94%] [G loss: 0.879092]\n",
            "2020 [D loss: 0.612466, acc.: 59.38%] [G loss: 0.891660]\n",
            "2021 [D loss: 0.598513, acc.: 62.50%] [G loss: 0.885716]\n",
            "2022 [D loss: 0.599701, acc.: 62.50%] [G loss: 0.884895]\n",
            "2023 [D loss: 0.598463, acc.: 62.50%] [G loss: 0.880861]\n",
            "2024 [D loss: 0.599885, acc.: 62.50%] [G loss: 0.863993]\n",
            "2025 [D loss: 0.596934, acc.: 62.50%] [G loss: 0.887174]\n",
            "2026 [D loss: 0.595587, acc.: 60.94%] [G loss: 0.881696]\n",
            "2027 [D loss: 0.598064, acc.: 59.38%] [G loss: 0.883156]\n",
            "2028 [D loss: 0.614227, acc.: 57.81%] [G loss: 0.899939]\n",
            "2029 [D loss: 0.589498, acc.: 62.50%] [G loss: 0.925558]\n",
            "2030 [D loss: 0.605657, acc.: 60.94%] [G loss: 0.884011]\n",
            "2031 [D loss: 0.599907, acc.: 60.94%] [G loss: 0.877375]\n",
            "2032 [D loss: 0.602676, acc.: 59.38%] [G loss: 0.895412]\n",
            "2033 [D loss: 0.599888, acc.: 62.50%] [G loss: 0.896979]\n",
            "2034 [D loss: 0.604317, acc.: 60.94%] [G loss: 0.865139]\n",
            "2035 [D loss: 0.604016, acc.: 62.50%] [G loss: 0.860364]\n",
            "2036 [D loss: 0.601535, acc.: 60.94%] [G loss: 0.876721]\n",
            "2037 [D loss: 0.601160, acc.: 62.50%] [G loss: 0.867658]\n",
            "2038 [D loss: 0.595502, acc.: 62.50%] [G loss: 0.867248]\n",
            "2039 [D loss: 0.603486, acc.: 59.38%] [G loss: 0.873349]\n",
            "2040 [D loss: 0.605713, acc.: 62.50%] [G loss: 0.882276]\n",
            "2041 [D loss: 0.590774, acc.: 64.06%] [G loss: 0.911089]\n",
            "2042 [D loss: 0.596756, acc.: 62.50%] [G loss: 0.907275]\n",
            "2043 [D loss: 0.601763, acc.: 60.94%] [G loss: 0.880742]\n",
            "2044 [D loss: 0.599343, acc.: 57.81%] [G loss: 0.872430]\n",
            "2045 [D loss: 0.601776, acc.: 62.50%] [G loss: 0.891760]\n",
            "2046 [D loss: 0.592633, acc.: 62.50%] [G loss: 0.881989]\n",
            "2047 [D loss: 0.592350, acc.: 65.62%] [G loss: 0.882269]\n",
            "2048 [D loss: 0.599687, acc.: 65.62%] [G loss: 0.879375]\n",
            "2049 [D loss: 0.606704, acc.: 59.38%] [G loss: 0.864126]\n",
            "2050 [D loss: 0.603368, acc.: 62.50%] [G loss: 0.882238]\n",
            "2051 [D loss: 0.596331, acc.: 62.50%] [G loss: 0.878659]\n",
            "2052 [D loss: 0.614198, acc.: 59.38%] [G loss: 0.874363]\n",
            "2053 [D loss: 0.597537, acc.: 62.50%] [G loss: 0.896055]\n",
            "2054 [D loss: 0.599282, acc.: 62.50%] [G loss: 0.896355]\n",
            "2055 [D loss: 0.593232, acc.: 62.50%] [G loss: 0.901738]\n",
            "2056 [D loss: 0.597568, acc.: 62.50%] [G loss: 0.890814]\n",
            "2057 [D loss: 0.598768, acc.: 62.50%] [G loss: 0.878469]\n",
            "2058 [D loss: 0.590982, acc.: 62.50%] [G loss: 0.888253]\n",
            "2059 [D loss: 0.595331, acc.: 62.50%] [G loss: 0.882152]\n",
            "2060 [D loss: 0.598171, acc.: 62.50%] [G loss: 0.879090]\n",
            "2061 [D loss: 0.601353, acc.: 62.50%] [G loss: 0.891294]\n",
            "2062 [D loss: 0.592560, acc.: 62.50%] [G loss: 0.885808]\n",
            "2063 [D loss: 0.593773, acc.: 62.50%] [G loss: 0.881235]\n",
            "2064 [D loss: 0.602124, acc.: 59.38%] [G loss: 0.851120]\n",
            "2065 [D loss: 0.599395, acc.: 62.50%] [G loss: 0.888757]\n",
            "2066 [D loss: 0.598701, acc.: 62.50%] [G loss: 0.882795]\n",
            "2067 [D loss: 0.603840, acc.: 60.94%] [G loss: 0.866369]\n",
            "2068 [D loss: 0.600717, acc.: 62.50%] [G loss: 0.880290]\n",
            "2069 [D loss: 0.597134, acc.: 62.50%] [G loss: 0.871764]\n",
            "2070 [D loss: 0.601242, acc.: 62.50%] [G loss: 0.887717]\n",
            "2071 [D loss: 0.598620, acc.: 62.50%] [G loss: 0.906285]\n",
            "2072 [D loss: 0.592930, acc.: 62.50%] [G loss: 0.886689]\n",
            "2073 [D loss: 0.592712, acc.: 62.50%] [G loss: 0.906334]\n",
            "2074 [D loss: 0.603437, acc.: 62.50%] [G loss: 0.896997]\n",
            "2075 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.874172]\n",
            "2076 [D loss: 0.600408, acc.: 62.50%] [G loss: 0.876152]\n",
            "2077 [D loss: 0.607047, acc.: 62.50%] [G loss: 0.882318]\n",
            "2078 [D loss: 0.600185, acc.: 62.50%] [G loss: 0.884523]\n",
            "2079 [D loss: 0.601137, acc.: 62.50%] [G loss: 0.882968]\n",
            "2080 [D loss: 0.602466, acc.: 62.50%] [G loss: 0.876664]\n",
            "2081 [D loss: 0.598012, acc.: 62.50%] [G loss: 0.893534]\n",
            "2082 [D loss: 0.606020, acc.: 62.50%] [G loss: 0.881824]\n",
            "2083 [D loss: 0.596951, acc.: 62.50%] [G loss: 0.890949]\n",
            "2084 [D loss: 0.598877, acc.: 62.50%] [G loss: 0.877558]\n",
            "2085 [D loss: 0.600070, acc.: 62.50%] [G loss: 0.883819]\n",
            "2086 [D loss: 0.600193, acc.: 62.50%] [G loss: 0.886257]\n",
            "2087 [D loss: 0.598437, acc.: 62.50%] [G loss: 0.890035]\n",
            "2088 [D loss: 0.596431, acc.: 62.50%] [G loss: 0.889001]\n",
            "2089 [D loss: 0.598557, acc.: 62.50%] [G loss: 0.879011]\n",
            "2090 [D loss: 0.599427, acc.: 62.50%] [G loss: 0.887398]\n",
            "2091 [D loss: 0.601318, acc.: 62.50%] [G loss: 0.900324]\n",
            "2092 [D loss: 0.598745, acc.: 62.50%] [G loss: 0.899662]\n",
            "2093 [D loss: 0.598889, acc.: 62.50%] [G loss: 0.888244]\n",
            "2094 [D loss: 0.599346, acc.: 62.50%] [G loss: 0.889195]\n",
            "2095 [D loss: 0.604314, acc.: 62.50%] [G loss: 0.889502]\n",
            "2096 [D loss: 0.600501, acc.: 62.50%] [G loss: 0.889334]\n",
            "2097 [D loss: 0.597369, acc.: 62.50%] [G loss: 0.892041]\n",
            "2098 [D loss: 0.598253, acc.: 62.50%] [G loss: 0.893297]\n",
            "2099 [D loss: 0.599506, acc.: 62.50%] [G loss: 0.885662]\n",
            "2100 [D loss: 0.600246, acc.: 62.50%] [G loss: 0.881841]\n",
            "generated_data\n",
            "2101 [D loss: 0.596659, acc.: 62.50%] [G loss: 0.880867]\n",
            "2102 [D loss: 0.598327, acc.: 62.50%] [G loss: 0.881420]\n",
            "2103 [D loss: 0.599292, acc.: 62.50%] [G loss: 0.875873]\n",
            "2104 [D loss: 0.595871, acc.: 62.50%] [G loss: 0.880316]\n",
            "2105 [D loss: 0.600142, acc.: 62.50%] [G loss: 0.878186]\n",
            "2106 [D loss: 0.597592, acc.: 62.50%] [G loss: 0.877206]\n",
            "2107 [D loss: 0.597066, acc.: 62.50%] [G loss: 0.879990]\n",
            "2108 [D loss: 0.595003, acc.: 62.50%] [G loss: 0.882081]\n",
            "2109 [D loss: 0.603112, acc.: 62.50%] [G loss: 0.874531]\n",
            "2110 [D loss: 0.594735, acc.: 62.50%] [G loss: 0.876365]\n",
            "2111 [D loss: 0.598398, acc.: 62.50%] [G loss: 0.869705]\n",
            "2112 [D loss: 0.595769, acc.: 62.50%] [G loss: 0.879914]\n",
            "2113 [D loss: 0.603351, acc.: 62.50%] [G loss: 0.858820]\n",
            "2114 [D loss: 0.598219, acc.: 62.50%] [G loss: 0.876566]\n",
            "2115 [D loss: 0.600264, acc.: 60.94%] [G loss: 0.857923]\n",
            "2116 [D loss: 0.597587, acc.: 62.50%] [G loss: 0.854183]\n",
            "2117 [D loss: 0.595940, acc.: 60.94%] [G loss: 0.875025]\n",
            "2118 [D loss: 0.604453, acc.: 59.38%] [G loss: 0.860305]\n",
            "2119 [D loss: 0.599149, acc.: 62.50%] [G loss: 0.856304]\n",
            "2120 [D loss: 0.602364, acc.: 62.50%] [G loss: 0.852046]\n",
            "2121 [D loss: 0.598641, acc.: 62.50%] [G loss: 0.866093]\n",
            "2122 [D loss: 0.595358, acc.: 62.50%] [G loss: 0.880097]\n",
            "2123 [D loss: 0.602341, acc.: 62.50%] [G loss: 0.861151]\n",
            "2124 [D loss: 0.596693, acc.: 62.50%] [G loss: 0.869509]\n",
            "2125 [D loss: 0.599038, acc.: 62.50%] [G loss: 0.869131]\n",
            "2126 [D loss: 0.592552, acc.: 62.50%] [G loss: 0.881888]\n",
            "2127 [D loss: 0.592604, acc.: 62.50%] [G loss: 0.883481]\n",
            "2128 [D loss: 0.604597, acc.: 62.50%] [G loss: 0.881580]\n",
            "2129 [D loss: 0.602547, acc.: 62.50%] [G loss: 0.883808]\n",
            "2130 [D loss: 0.591531, acc.: 62.50%] [G loss: 0.872025]\n",
            "2131 [D loss: 0.598590, acc.: 62.50%] [G loss: 0.869099]\n",
            "2132 [D loss: 0.598132, acc.: 62.50%] [G loss: 0.871282]\n",
            "2133 [D loss: 0.604643, acc.: 62.50%] [G loss: 0.874520]\n",
            "2134 [D loss: 0.601891, acc.: 62.50%] [G loss: 0.872291]\n",
            "2135 [D loss: 0.600861, acc.: 62.50%] [G loss: 0.867818]\n",
            "2136 [D loss: 0.594092, acc.: 62.50%] [G loss: 0.869002]\n",
            "2137 [D loss: 0.598149, acc.: 62.50%] [G loss: 0.875181]\n",
            "2138 [D loss: 0.594273, acc.: 62.50%] [G loss: 0.877370]\n",
            "2139 [D loss: 0.596033, acc.: 62.50%] [G loss: 0.864987]\n",
            "2140 [D loss: 0.591822, acc.: 62.50%] [G loss: 0.884335]\n",
            "2141 [D loss: 0.606654, acc.: 62.50%] [G loss: 0.888599]\n",
            "2142 [D loss: 0.603394, acc.: 62.50%] [G loss: 0.932187]\n",
            "2143 [D loss: 0.614697, acc.: 62.50%] [G loss: 0.865477]\n",
            "2144 [D loss: 0.596423, acc.: 62.50%] [G loss: 0.878764]\n",
            "2145 [D loss: 0.600873, acc.: 62.50%] [G loss: 0.866689]\n",
            "2146 [D loss: 0.597147, acc.: 62.50%] [G loss: 0.876051]\n",
            "2147 [D loss: 0.597323, acc.: 62.50%] [G loss: 0.876087]\n",
            "2148 [D loss: 0.598446, acc.: 62.50%] [G loss: 0.878579]\n",
            "2149 [D loss: 0.591569, acc.: 62.50%] [G loss: 0.871566]\n",
            "2150 [D loss: 0.600813, acc.: 62.50%] [G loss: 0.871381]\n",
            "2151 [D loss: 0.598871, acc.: 62.50%] [G loss: 0.879533]\n",
            "2152 [D loss: 0.596061, acc.: 62.50%] [G loss: 0.882023]\n",
            "2153 [D loss: 0.592960, acc.: 62.50%] [G loss: 0.873850]\n",
            "2154 [D loss: 0.594095, acc.: 62.50%] [G loss: 0.884003]\n",
            "2155 [D loss: 0.597675, acc.: 62.50%] [G loss: 0.876677]\n",
            "2156 [D loss: 0.593558, acc.: 62.50%] [G loss: 0.866559]\n",
            "2157 [D loss: 0.597571, acc.: 62.50%] [G loss: 0.867797]\n",
            "2158 [D loss: 0.602642, acc.: 60.94%] [G loss: 0.863537]\n",
            "2159 [D loss: 0.596746, acc.: 60.94%] [G loss: 0.857885]\n",
            "2160 [D loss: 0.595768, acc.: 62.50%] [G loss: 0.869218]\n",
            "2161 [D loss: 0.595594, acc.: 64.06%] [G loss: 0.866018]\n",
            "2162 [D loss: 0.597410, acc.: 60.94%] [G loss: 0.861606]\n",
            "2163 [D loss: 0.604268, acc.: 60.94%] [G loss: 0.883225]\n",
            "2164 [D loss: 0.602832, acc.: 60.94%] [G loss: 0.846414]\n",
            "2165 [D loss: 0.599459, acc.: 62.50%] [G loss: 0.850433]\n",
            "2166 [D loss: 0.600951, acc.: 60.94%] [G loss: 0.857623]\n",
            "2167 [D loss: 0.601557, acc.: 59.38%] [G loss: 0.859580]\n",
            "2168 [D loss: 0.600992, acc.: 62.50%] [G loss: 0.851259]\n",
            "2169 [D loss: 0.592483, acc.: 62.50%] [G loss: 0.842637]\n",
            "2170 [D loss: 0.601727, acc.: 60.94%] [G loss: 0.851165]\n",
            "2171 [D loss: 0.596674, acc.: 62.50%] [G loss: 0.851786]\n",
            "2172 [D loss: 0.595876, acc.: 62.50%] [G loss: 0.828840]\n",
            "2173 [D loss: 0.596793, acc.: 60.94%] [G loss: 0.829529]\n",
            "2174 [D loss: 0.598348, acc.: 62.50%] [G loss: 0.826626]\n",
            "2175 [D loss: 0.608273, acc.: 59.38%] [G loss: 0.826779]\n",
            "2176 [D loss: 0.615388, acc.: 60.94%] [G loss: 0.852019]\n",
            "2177 [D loss: 0.596585, acc.: 62.50%] [G loss: 0.847220]\n",
            "2178 [D loss: 0.599292, acc.: 62.50%] [G loss: 0.860695]\n",
            "2179 [D loss: 0.602687, acc.: 62.50%] [G loss: 0.857367]\n",
            "2180 [D loss: 0.601509, acc.: 62.50%] [G loss: 0.855204]\n",
            "2181 [D loss: 0.598415, acc.: 62.50%] [G loss: 0.869658]\n",
            "2182 [D loss: 0.595860, acc.: 62.50%] [G loss: 0.865068]\n",
            "2183 [D loss: 0.598544, acc.: 62.50%] [G loss: 0.836178]\n",
            "2184 [D loss: 0.599344, acc.: 62.50%] [G loss: 0.862524]\n",
            "2185 [D loss: 0.601601, acc.: 62.50%] [G loss: 0.855478]\n",
            "2186 [D loss: 0.598269, acc.: 62.50%] [G loss: 0.869181]\n",
            "2187 [D loss: 0.590412, acc.: 62.50%] [G loss: 0.876184]\n",
            "2188 [D loss: 0.606184, acc.: 62.50%] [G loss: 0.881908]\n",
            "2189 [D loss: 0.601009, acc.: 60.94%] [G loss: 0.875486]\n",
            "2190 [D loss: 0.591413, acc.: 62.50%] [G loss: 0.868431]\n",
            "2191 [D loss: 0.599665, acc.: 60.94%] [G loss: 0.871557]\n",
            "2192 [D loss: 0.603020, acc.: 60.94%] [G loss: 0.859213]\n",
            "2193 [D loss: 0.602755, acc.: 62.50%] [G loss: 0.865277]\n",
            "2194 [D loss: 0.593387, acc.: 62.50%] [G loss: 0.867281]\n",
            "2195 [D loss: 0.599655, acc.: 62.50%] [G loss: 0.871253]\n",
            "2196 [D loss: 0.592069, acc.: 62.50%] [G loss: 0.879193]\n",
            "2197 [D loss: 0.597083, acc.: 62.50%] [G loss: 0.865926]\n",
            "2198 [D loss: 0.602083, acc.: 60.94%] [G loss: 0.874718]\n",
            "2199 [D loss: 0.597422, acc.: 62.50%] [G loss: 0.863780]\n",
            "2200 [D loss: 0.596249, acc.: 62.50%] [G loss: 0.873610]\n",
            "generated_data\n",
            "2201 [D loss: 0.607044, acc.: 62.50%] [G loss: 0.846183]\n",
            "2202 [D loss: 0.598189, acc.: 62.50%] [G loss: 0.849645]\n",
            "2203 [D loss: 0.599897, acc.: 62.50%] [G loss: 0.855486]\n",
            "2204 [D loss: 0.599734, acc.: 62.50%] [G loss: 0.855800]\n",
            "2205 [D loss: 0.598536, acc.: 62.50%] [G loss: 0.860963]\n",
            "2206 [D loss: 0.596044, acc.: 62.50%] [G loss: 0.864277]\n",
            "2207 [D loss: 0.602077, acc.: 62.50%] [G loss: 0.855586]\n",
            "2208 [D loss: 0.592725, acc.: 62.50%] [G loss: 0.861109]\n",
            "2209 [D loss: 0.602765, acc.: 62.50%] [G loss: 0.850645]\n",
            "2210 [D loss: 0.601856, acc.: 62.50%] [G loss: 0.850840]\n",
            "2211 [D loss: 0.599332, acc.: 62.50%] [G loss: 0.853307]\n",
            "2212 [D loss: 0.598958, acc.: 62.50%] [G loss: 0.879036]\n",
            "2213 [D loss: 0.592045, acc.: 62.50%] [G loss: 0.909500]\n",
            "2214 [D loss: 0.614700, acc.: 62.50%] [G loss: 0.880599]\n",
            "2215 [D loss: 0.596262, acc.: 62.50%] [G loss: 0.881022]\n",
            "2216 [D loss: 0.596172, acc.: 62.50%] [G loss: 0.867019]\n",
            "2217 [D loss: 0.589457, acc.: 62.50%] [G loss: 0.852457]\n",
            "2218 [D loss: 0.605944, acc.: 60.94%] [G loss: 0.866453]\n",
            "2219 [D loss: 0.607670, acc.: 62.50%] [G loss: 0.865725]\n",
            "2220 [D loss: 0.596485, acc.: 62.50%] [G loss: 0.868933]\n",
            "2221 [D loss: 0.596655, acc.: 62.50%] [G loss: 0.866579]\n",
            "2222 [D loss: 0.595509, acc.: 62.50%] [G loss: 0.887053]\n",
            "2223 [D loss: 0.594984, acc.: 62.50%] [G loss: 0.902942]\n",
            "2224 [D loss: 0.609530, acc.: 60.94%] [G loss: 0.871220]\n",
            "2225 [D loss: 0.597372, acc.: 62.50%] [G loss: 0.872392]\n",
            "2226 [D loss: 0.598960, acc.: 62.50%] [G loss: 0.864625]\n",
            "2227 [D loss: 0.594819, acc.: 62.50%] [G loss: 0.862955]\n",
            "2228 [D loss: 0.597896, acc.: 62.50%] [G loss: 0.861053]\n",
            "2229 [D loss: 0.597962, acc.: 62.50%] [G loss: 0.873938]\n",
            "2230 [D loss: 0.599545, acc.: 62.50%] [G loss: 0.870486]\n",
            "2231 [D loss: 0.600267, acc.: 60.94%] [G loss: 0.862647]\n",
            "2232 [D loss: 0.596861, acc.: 62.50%] [G loss: 0.857763]\n",
            "2233 [D loss: 0.603731, acc.: 62.50%] [G loss: 0.865293]\n",
            "2234 [D loss: 0.601355, acc.: 62.50%] [G loss: 0.868658]\n",
            "2235 [D loss: 0.595163, acc.: 62.50%] [G loss: 0.878677]\n",
            "2236 [D loss: 0.597794, acc.: 62.50%] [G loss: 0.879627]\n",
            "2237 [D loss: 0.596889, acc.: 62.50%] [G loss: 0.886351]\n",
            "2238 [D loss: 0.597752, acc.: 62.50%] [G loss: 0.874906]\n",
            "2239 [D loss: 0.604600, acc.: 62.50%] [G loss: 0.870437]\n",
            "2240 [D loss: 0.599711, acc.: 62.50%] [G loss: 0.874690]\n",
            "2241 [D loss: 0.600780, acc.: 62.50%] [G loss: 0.867657]\n",
            "2242 [D loss: 0.594916, acc.: 62.50%] [G loss: 0.858101]\n",
            "2243 [D loss: 0.597332, acc.: 62.50%] [G loss: 0.866887]\n",
            "2244 [D loss: 0.600498, acc.: 62.50%] [G loss: 0.882587]\n",
            "2245 [D loss: 0.605319, acc.: 62.50%] [G loss: 0.876844]\n",
            "2246 [D loss: 0.597257, acc.: 62.50%] [G loss: 0.851090]\n",
            "2247 [D loss: 0.594556, acc.: 62.50%] [G loss: 0.861107]\n",
            "2248 [D loss: 0.594290, acc.: 62.50%] [G loss: 0.862789]\n",
            "2249 [D loss: 0.596946, acc.: 62.50%] [G loss: 0.862671]\n",
            "2250 [D loss: 0.597716, acc.: 60.94%] [G loss: 0.861314]\n",
            "2251 [D loss: 0.599450, acc.: 62.50%] [G loss: 0.852559]\n",
            "2252 [D loss: 0.594802, acc.: 62.50%] [G loss: 0.855509]\n",
            "2253 [D loss: 0.600114, acc.: 62.50%] [G loss: 0.854338]\n",
            "2254 [D loss: 0.595735, acc.: 62.50%] [G loss: 0.855349]\n",
            "2255 [D loss: 0.603006, acc.: 64.06%] [G loss: 0.859910]\n",
            "2256 [D loss: 0.600172, acc.: 62.50%] [G loss: 0.857293]\n",
            "2257 [D loss: 0.593736, acc.: 62.50%] [G loss: 0.864905]\n",
            "2258 [D loss: 0.599549, acc.: 62.50%] [G loss: 0.859997]\n",
            "2259 [D loss: 0.598037, acc.: 62.50%] [G loss: 0.859598]\n",
            "2260 [D loss: 0.602092, acc.: 62.50%] [G loss: 0.859843]\n",
            "2261 [D loss: 0.600559, acc.: 62.50%] [G loss: 0.863207]\n",
            "2262 [D loss: 0.596687, acc.: 62.50%] [G loss: 0.857112]\n",
            "2263 [D loss: 0.600101, acc.: 62.50%] [G loss: 0.856953]\n",
            "2264 [D loss: 0.598053, acc.: 62.50%] [G loss: 0.858140]\n",
            "2265 [D loss: 0.597620, acc.: 64.06%] [G loss: 0.857268]\n",
            "2266 [D loss: 0.600134, acc.: 62.50%] [G loss: 0.868007]\n",
            "2267 [D loss: 0.595724, acc.: 62.50%] [G loss: 0.858571]\n",
            "2268 [D loss: 0.596487, acc.: 64.06%] [G loss: 0.863548]\n",
            "2269 [D loss: 0.600397, acc.: 62.50%] [G loss: 0.870925]\n",
            "2270 [D loss: 0.596134, acc.: 60.94%] [G loss: 0.864650]\n",
            "2271 [D loss: 0.594687, acc.: 62.50%] [G loss: 0.867691]\n",
            "2272 [D loss: 0.593445, acc.: 64.06%] [G loss: 0.867982]\n",
            "2273 [D loss: 0.596725, acc.: 62.50%] [G loss: 0.868759]\n",
            "2274 [D loss: 0.597660, acc.: 64.06%] [G loss: 0.871854]\n",
            "2275 [D loss: 0.599414, acc.: 62.50%] [G loss: 0.868691]\n",
            "2276 [D loss: 0.594597, acc.: 62.50%] [G loss: 0.867108]\n",
            "2277 [D loss: 0.593850, acc.: 62.50%] [G loss: 0.865941]\n",
            "2278 [D loss: 0.599457, acc.: 64.06%] [G loss: 0.860397]\n",
            "2279 [D loss: 0.593137, acc.: 64.06%] [G loss: 0.863998]\n",
            "2280 [D loss: 0.594297, acc.: 62.50%] [G loss: 0.866017]\n",
            "2281 [D loss: 0.597767, acc.: 62.50%] [G loss: 0.860145]\n",
            "2282 [D loss: 0.599499, acc.: 62.50%] [G loss: 0.863483]\n",
            "2283 [D loss: 0.599933, acc.: 62.50%] [G loss: 0.860240]\n",
            "2284 [D loss: 0.598714, acc.: 62.50%] [G loss: 0.860798]\n",
            "2285 [D loss: 0.591793, acc.: 64.06%] [G loss: 0.852475]\n",
            "2286 [D loss: 0.616852, acc.: 56.25%] [G loss: 0.857066]\n",
            "2287 [D loss: 0.593445, acc.: 64.06%] [G loss: 0.863545]\n",
            "2288 [D loss: 0.597507, acc.: 62.50%] [G loss: 0.876875]\n",
            "2289 [D loss: 0.602716, acc.: 62.50%] [G loss: 0.866974]\n",
            "2290 [D loss: 0.601165, acc.: 62.50%] [G loss: 0.858988]\n",
            "2291 [D loss: 0.600498, acc.: 62.50%] [G loss: 0.856285]\n",
            "2292 [D loss: 0.596934, acc.: 62.50%] [G loss: 0.856945]\n",
            "2293 [D loss: 0.597783, acc.: 62.50%] [G loss: 0.860907]\n",
            "2294 [D loss: 0.594815, acc.: 62.50%] [G loss: 0.854095]\n",
            "2295 [D loss: 0.595115, acc.: 62.50%] [G loss: 0.871122]\n",
            "2296 [D loss: 0.596959, acc.: 62.50%] [G loss: 0.871885]\n",
            "2297 [D loss: 0.601131, acc.: 62.50%] [G loss: 0.861964]\n",
            "2298 [D loss: 0.593095, acc.: 62.50%] [G loss: 0.858183]\n",
            "2299 [D loss: 0.598909, acc.: 62.50%] [G loss: 0.875713]\n",
            "2300 [D loss: 0.595122, acc.: 62.50%] [G loss: 0.864362]\n",
            "generated_data\n",
            "2301 [D loss: 0.600183, acc.: 62.50%] [G loss: 0.854903]\n",
            "2302 [D loss: 0.599375, acc.: 62.50%] [G loss: 0.863773]\n",
            "2303 [D loss: 0.603616, acc.: 62.50%] [G loss: 0.872184]\n",
            "2304 [D loss: 0.594578, acc.: 62.50%] [G loss: 0.850882]\n",
            "2305 [D loss: 0.599286, acc.: 62.50%] [G loss: 0.863256]\n",
            "2306 [D loss: 0.598033, acc.: 62.50%] [G loss: 0.857518]\n",
            "2307 [D loss: 0.594044, acc.: 62.50%] [G loss: 0.857223]\n",
            "2308 [D loss: 0.597765, acc.: 62.50%] [G loss: 0.853750]\n",
            "2309 [D loss: 0.600461, acc.: 62.50%] [G loss: 0.857351]\n",
            "2310 [D loss: 0.604379, acc.: 62.50%] [G loss: 0.846170]\n",
            "2311 [D loss: 0.592533, acc.: 64.06%] [G loss: 0.856769]\n",
            "2312 [D loss: 0.594145, acc.: 62.50%] [G loss: 0.862430]\n",
            "2313 [D loss: 0.601600, acc.: 60.94%] [G loss: 0.864750]\n",
            "2314 [D loss: 0.593895, acc.: 62.50%] [G loss: 0.869558]\n",
            "2315 [D loss: 0.601063, acc.: 62.50%] [G loss: 0.866821]\n",
            "2316 [D loss: 0.597936, acc.: 64.06%] [G loss: 0.852533]\n",
            "2317 [D loss: 0.596722, acc.: 62.50%] [G loss: 0.861434]\n",
            "2318 [D loss: 0.596513, acc.: 62.50%] [G loss: 0.863689]\n",
            "2319 [D loss: 0.593395, acc.: 64.06%] [G loss: 0.859922]\n",
            "2320 [D loss: 0.596233, acc.: 60.94%] [G loss: 0.862099]\n",
            "2321 [D loss: 0.596313, acc.: 62.50%] [G loss: 0.854581]\n",
            "2322 [D loss: 0.596507, acc.: 62.50%] [G loss: 0.857516]\n",
            "2323 [D loss: 0.606443, acc.: 62.50%] [G loss: 0.856217]\n",
            "2324 [D loss: 0.615767, acc.: 59.38%] [G loss: 0.863440]\n",
            "2325 [D loss: 0.601632, acc.: 62.50%] [G loss: 0.857226]\n",
            "2326 [D loss: 0.600186, acc.: 62.50%] [G loss: 0.857605]\n",
            "2327 [D loss: 0.599326, acc.: 62.50%] [G loss: 0.863485]\n",
            "2328 [D loss: 0.596529, acc.: 62.50%] [G loss: 0.859282]\n",
            "2329 [D loss: 0.598556, acc.: 62.50%] [G loss: 0.849774]\n",
            "2330 [D loss: 0.605685, acc.: 60.94%] [G loss: 0.854843]\n",
            "2331 [D loss: 0.598815, acc.: 62.50%] [G loss: 0.864629]\n",
            "2332 [D loss: 0.600017, acc.: 62.50%] [G loss: 0.872605]\n",
            "2333 [D loss: 0.600030, acc.: 62.50%] [G loss: 0.870545]\n",
            "2334 [D loss: 0.596120, acc.: 62.50%] [G loss: 0.854556]\n",
            "2335 [D loss: 0.594026, acc.: 62.50%] [G loss: 0.864939]\n",
            "2336 [D loss: 0.593864, acc.: 62.50%] [G loss: 0.850236]\n",
            "2337 [D loss: 0.598331, acc.: 64.06%] [G loss: 0.853096]\n",
            "2338 [D loss: 0.603411, acc.: 62.50%] [G loss: 0.854173]\n",
            "2339 [D loss: 0.597523, acc.: 59.38%] [G loss: 0.866661]\n",
            "2340 [D loss: 0.595477, acc.: 62.50%] [G loss: 0.864493]\n",
            "2341 [D loss: 0.593749, acc.: 62.50%] [G loss: 0.854788]\n",
            "2342 [D loss: 0.598900, acc.: 62.50%] [G loss: 0.853058]\n",
            "2343 [D loss: 0.600109, acc.: 60.94%] [G loss: 0.835237]\n",
            "2344 [D loss: 0.597244, acc.: 60.94%] [G loss: 0.853589]\n",
            "2345 [D loss: 0.596180, acc.: 62.50%] [G loss: 0.872436]\n",
            "2346 [D loss: 0.596344, acc.: 62.50%] [G loss: 0.854627]\n",
            "2347 [D loss: 0.603785, acc.: 62.50%] [G loss: 0.870346]\n",
            "2348 [D loss: 0.602091, acc.: 62.50%] [G loss: 0.879177]\n",
            "2349 [D loss: 0.596577, acc.: 62.50%] [G loss: 0.890984]\n",
            "2350 [D loss: 0.591268, acc.: 62.50%] [G loss: 0.897164]\n",
            "2351 [D loss: 0.591112, acc.: 62.50%] [G loss: 0.888676]\n",
            "2352 [D loss: 0.594213, acc.: 62.50%] [G loss: 0.890482]\n",
            "2353 [D loss: 0.604427, acc.: 62.50%] [G loss: 0.879694]\n",
            "2354 [D loss: 0.602131, acc.: 62.50%] [G loss: 0.871817]\n",
            "2355 [D loss: 0.601136, acc.: 60.94%] [G loss: 0.877581]\n",
            "2356 [D loss: 0.597491, acc.: 62.50%] [G loss: 0.876088]\n",
            "2357 [D loss: 0.598116, acc.: 62.50%] [G loss: 0.872210]\n",
            "2358 [D loss: 0.596531, acc.: 62.50%] [G loss: 0.873972]\n",
            "2359 [D loss: 0.600681, acc.: 62.50%] [G loss: 0.870239]\n",
            "2360 [D loss: 0.596749, acc.: 62.50%] [G loss: 0.875336]\n",
            "2361 [D loss: 0.600189, acc.: 60.94%] [G loss: 0.869240]\n",
            "2362 [D loss: 0.594606, acc.: 62.50%] [G loss: 0.873856]\n",
            "2363 [D loss: 0.598001, acc.: 62.50%] [G loss: 0.871407]\n",
            "2364 [D loss: 0.596544, acc.: 62.50%] [G loss: 0.867642]\n",
            "2365 [D loss: 0.593458, acc.: 62.50%] [G loss: 0.868028]\n",
            "2366 [D loss: 0.594356, acc.: 62.50%] [G loss: 0.864020]\n",
            "2367 [D loss: 0.598385, acc.: 64.06%] [G loss: 0.872010]\n",
            "2368 [D loss: 0.595270, acc.: 62.50%] [G loss: 0.873138]\n",
            "2369 [D loss: 0.597348, acc.: 60.94%] [G loss: 0.865034]\n",
            "2370 [D loss: 0.595310, acc.: 62.50%] [G loss: 0.864124]\n",
            "2371 [D loss: 0.592481, acc.: 62.50%] [G loss: 0.869355]\n",
            "2372 [D loss: 0.592033, acc.: 62.50%] [G loss: 0.881380]\n",
            "2373 [D loss: 0.600632, acc.: 62.50%] [G loss: 0.876921]\n",
            "2374 [D loss: 0.596156, acc.: 62.50%] [G loss: 0.870096]\n",
            "2375 [D loss: 0.595755, acc.: 62.50%] [G loss: 0.879368]\n",
            "2376 [D loss: 0.600264, acc.: 62.50%] [G loss: 0.872263]\n",
            "2377 [D loss: 0.588107, acc.: 62.50%] [G loss: 0.879281]\n",
            "2378 [D loss: 0.594036, acc.: 62.50%] [G loss: 0.872997]\n",
            "2379 [D loss: 0.593723, acc.: 62.50%] [G loss: 0.867981]\n",
            "2380 [D loss: 0.597603, acc.: 62.50%] [G loss: 0.872035]\n",
            "2381 [D loss: 0.599007, acc.: 62.50%] [G loss: 0.868410]\n",
            "2382 [D loss: 0.596871, acc.: 62.50%] [G loss: 0.875444]\n",
            "2383 [D loss: 0.594206, acc.: 62.50%] [G loss: 0.872434]\n",
            "2384 [D loss: 0.601642, acc.: 62.50%] [G loss: 0.873795]\n",
            "2385 [D loss: 0.600147, acc.: 62.50%] [G loss: 0.879331]\n",
            "2386 [D loss: 0.599815, acc.: 62.50%] [G loss: 0.868454]\n",
            "2387 [D loss: 0.595527, acc.: 62.50%] [G loss: 0.869861]\n",
            "2388 [D loss: 0.598506, acc.: 62.50%] [G loss: 0.871712]\n",
            "2389 [D loss: 0.594377, acc.: 62.50%] [G loss: 0.857269]\n",
            "2390 [D loss: 0.598063, acc.: 62.50%] [G loss: 0.867817]\n",
            "2391 [D loss: 0.598200, acc.: 62.50%] [G loss: 0.858850]\n",
            "2392 [D loss: 0.595982, acc.: 62.50%] [G loss: 0.868464]\n",
            "2393 [D loss: 0.593789, acc.: 64.06%] [G loss: 0.859821]\n",
            "2394 [D loss: 0.594720, acc.: 62.50%] [G loss: 0.861954]\n",
            "2395 [D loss: 0.592928, acc.: 64.06%] [G loss: 0.863502]\n",
            "2396 [D loss: 0.595224, acc.: 62.50%] [G loss: 0.858827]\n",
            "2397 [D loss: 0.608462, acc.: 60.94%] [G loss: 0.848338]\n",
            "2398 [D loss: 0.593869, acc.: 64.06%] [G loss: 0.856830]\n",
            "2399 [D loss: 0.598777, acc.: 62.50%] [G loss: 0.867839]\n",
            "2400 [D loss: 0.607973, acc.: 59.38%] [G loss: 0.864066]\n",
            "generated_data\n",
            "2401 [D loss: 0.593563, acc.: 64.06%] [G loss: 0.863322]\n",
            "2402 [D loss: 0.597783, acc.: 60.94%] [G loss: 0.862012]\n",
            "2403 [D loss: 0.595220, acc.: 62.50%] [G loss: 0.859313]\n",
            "2404 [D loss: 0.603649, acc.: 62.50%] [G loss: 0.860589]\n",
            "2405 [D loss: 0.599560, acc.: 60.94%] [G loss: 0.860788]\n",
            "2406 [D loss: 0.594349, acc.: 64.06%] [G loss: 0.865982]\n",
            "2407 [D loss: 0.600740, acc.: 60.94%] [G loss: 0.859227]\n",
            "2408 [D loss: 0.597866, acc.: 60.94%] [G loss: 0.875098]\n",
            "2409 [D loss: 0.593035, acc.: 64.06%] [G loss: 0.899561]\n",
            "2410 [D loss: 0.606609, acc.: 62.50%] [G loss: 0.887313]\n",
            "2411 [D loss: 0.595454, acc.: 62.50%] [G loss: 0.875844]\n",
            "2412 [D loss: 0.598589, acc.: 62.50%] [G loss: 0.885343]\n",
            "2413 [D loss: 0.595993, acc.: 62.50%] [G loss: 0.866278]\n",
            "2414 [D loss: 0.598208, acc.: 62.50%] [G loss: 0.873017]\n",
            "2415 [D loss: 0.595160, acc.: 62.50%] [G loss: 0.869147]\n",
            "2416 [D loss: 0.595792, acc.: 62.50%] [G loss: 0.871027]\n",
            "2417 [D loss: 0.601683, acc.: 62.50%] [G loss: 0.864566]\n",
            "2418 [D loss: 0.600265, acc.: 62.50%] [G loss: 0.868065]\n",
            "2419 [D loss: 0.599056, acc.: 62.50%] [G loss: 0.864230]\n",
            "2420 [D loss: 0.598661, acc.: 62.50%] [G loss: 0.864700]\n",
            "2421 [D loss: 0.598381, acc.: 60.94%] [G loss: 0.861681]\n",
            "2422 [D loss: 0.596315, acc.: 62.50%] [G loss: 0.864726]\n",
            "2423 [D loss: 0.597440, acc.: 62.50%] [G loss: 0.850865]\n",
            "2424 [D loss: 0.598835, acc.: 62.50%] [G loss: 0.859781]\n",
            "2425 [D loss: 0.597681, acc.: 60.94%] [G loss: 0.860547]\n",
            "2426 [D loss: 0.597140, acc.: 62.50%] [G loss: 0.857336]\n",
            "2427 [D loss: 0.598341, acc.: 62.50%] [G loss: 0.863426]\n",
            "2428 [D loss: 0.603148, acc.: 60.94%] [G loss: 0.866953]\n",
            "2429 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.866309]\n",
            "2430 [D loss: 0.595087, acc.: 62.50%] [G loss: 0.865055]\n",
            "2431 [D loss: 0.600430, acc.: 62.50%] [G loss: 0.867786]\n",
            "2432 [D loss: 0.599330, acc.: 62.50%] [G loss: 0.869873]\n",
            "2433 [D loss: 0.600053, acc.: 62.50%] [G loss: 0.867592]\n",
            "2434 [D loss: 0.597996, acc.: 62.50%] [G loss: 0.866258]\n",
            "2435 [D loss: 0.596470, acc.: 62.50%] [G loss: 0.865667]\n",
            "2436 [D loss: 0.595988, acc.: 62.50%] [G loss: 0.867398]\n",
            "2437 [D loss: 0.597274, acc.: 62.50%] [G loss: 0.867325]\n",
            "2438 [D loss: 0.596217, acc.: 62.50%] [G loss: 0.857906]\n",
            "2439 [D loss: 0.596315, acc.: 62.50%] [G loss: 0.863457]\n",
            "2440 [D loss: 0.596386, acc.: 62.50%] [G loss: 0.861379]\n",
            "2441 [D loss: 0.598994, acc.: 62.50%] [G loss: 0.860972]\n",
            "2442 [D loss: 0.595957, acc.: 62.50%] [G loss: 0.858384]\n",
            "2443 [D loss: 0.597234, acc.: 62.50%] [G loss: 0.862146]\n",
            "2444 [D loss: 0.594198, acc.: 62.50%] [G loss: 0.865454]\n",
            "2445 [D loss: 0.592998, acc.: 62.50%] [G loss: 0.863727]\n",
            "2446 [D loss: 0.596517, acc.: 62.50%] [G loss: 0.857597]\n",
            "2447 [D loss: 0.597491, acc.: 62.50%] [G loss: 0.861875]\n",
            "2448 [D loss: 0.599421, acc.: 62.50%] [G loss: 0.894580]\n",
            "2449 [D loss: 0.603501, acc.: 62.50%] [G loss: 0.862113]\n",
            "2450 [D loss: 0.597783, acc.: 62.50%] [G loss: 0.863720]\n",
            "2451 [D loss: 0.595128, acc.: 62.50%] [G loss: 0.867097]\n",
            "2452 [D loss: 0.596909, acc.: 62.50%] [G loss: 0.868627]\n",
            "2453 [D loss: 0.595116, acc.: 62.50%] [G loss: 0.864952]\n",
            "2454 [D loss: 0.597684, acc.: 62.50%] [G loss: 0.866630]\n",
            "2455 [D loss: 0.597276, acc.: 62.50%] [G loss: 0.864949]\n",
            "2456 [D loss: 0.593623, acc.: 62.50%] [G loss: 0.861043]\n",
            "2457 [D loss: 0.597872, acc.: 60.94%] [G loss: 0.864662]\n",
            "2458 [D loss: 0.596939, acc.: 62.50%] [G loss: 0.866008]\n",
            "2459 [D loss: 0.596819, acc.: 62.50%] [G loss: 0.864584]\n",
            "2460 [D loss: 0.595190, acc.: 62.50%] [G loss: 0.864456]\n",
            "2461 [D loss: 0.597897, acc.: 62.50%] [G loss: 0.867551]\n",
            "2462 [D loss: 0.598451, acc.: 62.50%] [G loss: 0.865040]\n",
            "2463 [D loss: 0.597822, acc.: 62.50%] [G loss: 0.865862]\n",
            "2464 [D loss: 0.598114, acc.: 62.50%] [G loss: 0.859138]\n",
            "2465 [D loss: 0.597412, acc.: 62.50%] [G loss: 0.863014]\n",
            "2466 [D loss: 0.598210, acc.: 62.50%] [G loss: 0.866482]\n",
            "2467 [D loss: 0.595484, acc.: 62.50%] [G loss: 0.857293]\n",
            "2468 [D loss: 0.600214, acc.: 62.50%] [G loss: 0.866107]\n",
            "2469 [D loss: 0.595928, acc.: 62.50%] [G loss: 0.862839]\n",
            "2470 [D loss: 0.596806, acc.: 62.50%] [G loss: 0.859084]\n",
            "2471 [D loss: 0.600316, acc.: 62.50%] [G loss: 0.860065]\n",
            "2472 [D loss: 0.595719, acc.: 62.50%] [G loss: 0.863074]\n",
            "2473 [D loss: 0.599513, acc.: 60.94%] [G loss: 0.864172]\n",
            "2474 [D loss: 0.597436, acc.: 62.50%] [G loss: 0.857425]\n",
            "2475 [D loss: 0.600152, acc.: 62.50%] [G loss: 0.862034]\n",
            "2476 [D loss: 0.595559, acc.: 62.50%] [G loss: 0.863707]\n",
            "2477 [D loss: 0.598837, acc.: 62.50%] [G loss: 0.862587]\n",
            "2478 [D loss: 0.595323, acc.: 62.50%] [G loss: 0.858855]\n",
            "2479 [D loss: 0.600264, acc.: 60.94%] [G loss: 0.869118]\n",
            "2480 [D loss: 0.596086, acc.: 62.50%] [G loss: 0.864615]\n",
            "2481 [D loss: 0.596849, acc.: 62.50%] [G loss: 0.870476]\n",
            "2482 [D loss: 0.598402, acc.: 62.50%] [G loss: 0.868506]\n",
            "2483 [D loss: 0.596308, acc.: 62.50%] [G loss: 0.874767]\n",
            "2484 [D loss: 0.597503, acc.: 62.50%] [G loss: 0.863939]\n",
            "2485 [D loss: 0.595814, acc.: 62.50%] [G loss: 0.870561]\n",
            "2486 [D loss: 0.596690, acc.: 62.50%] [G loss: 0.867217]\n",
            "2487 [D loss: 0.598494, acc.: 62.50%] [G loss: 0.863283]\n",
            "2488 [D loss: 0.599540, acc.: 62.50%] [G loss: 0.862192]\n",
            "2489 [D loss: 0.595823, acc.: 62.50%] [G loss: 0.858537]\n",
            "2490 [D loss: 0.598331, acc.: 62.50%] [G loss: 0.862827]\n",
            "2491 [D loss: 0.602601, acc.: 62.50%] [G loss: 0.856168]\n",
            "2492 [D loss: 0.607693, acc.: 62.50%] [G loss: 0.862844]\n",
            "2493 [D loss: 0.597583, acc.: 62.50%] [G loss: 0.859654]\n",
            "2494 [D loss: 0.598117, acc.: 62.50%] [G loss: 0.865449]\n",
            "2495 [D loss: 0.598439, acc.: 62.50%] [G loss: 0.857846]\n",
            "2496 [D loss: 0.597370, acc.: 62.50%] [G loss: 0.861481]\n",
            "2497 [D loss: 0.595626, acc.: 62.50%] [G loss: 0.854302]\n",
            "2498 [D loss: 0.600999, acc.: 62.50%] [G loss: 0.855676]\n",
            "2499 [D loss: 0.596480, acc.: 62.50%] [G loss: 0.855174]\n",
            "2500 [D loss: 0.597498, acc.: 62.50%] [G loss: 0.857705]\n",
            "generated_data\n",
            "2501 [D loss: 0.596490, acc.: 62.50%] [G loss: 0.858056]\n",
            "2502 [D loss: 0.595405, acc.: 62.50%] [G loss: 0.859319]\n",
            "2503 [D loss: 0.600144, acc.: 62.50%] [G loss: 0.852006]\n",
            "2504 [D loss: 0.599196, acc.: 62.50%] [G loss: 0.857033]\n",
            "2505 [D loss: 0.599074, acc.: 62.50%] [G loss: 0.856173]\n",
            "2506 [D loss: 0.595611, acc.: 62.50%] [G loss: 0.860663]\n",
            "2507 [D loss: 0.598917, acc.: 62.50%] [G loss: 0.863574]\n",
            "2508 [D loss: 0.597586, acc.: 62.50%] [G loss: 0.855527]\n",
            "2509 [D loss: 0.598022, acc.: 62.50%] [G loss: 0.854312]\n",
            "2510 [D loss: 0.599147, acc.: 62.50%] [G loss: 0.863070]\n",
            "2511 [D loss: 0.596127, acc.: 62.50%] [G loss: 0.860689]\n",
            "2512 [D loss: 0.595878, acc.: 62.50%] [G loss: 0.861592]\n",
            "2513 [D loss: 0.593905, acc.: 62.50%] [G loss: 0.860437]\n",
            "2514 [D loss: 0.596889, acc.: 62.50%] [G loss: 0.861913]\n",
            "2515 [D loss: 0.594956, acc.: 62.50%] [G loss: 0.859013]\n",
            "2516 [D loss: 0.595119, acc.: 62.50%] [G loss: 0.859633]\n",
            "2517 [D loss: 0.596751, acc.: 62.50%] [G loss: 0.859181]\n",
            "2518 [D loss: 0.596082, acc.: 62.50%] [G loss: 0.863645]\n",
            "2519 [D loss: 0.592713, acc.: 64.06%] [G loss: 0.855937]\n",
            "2520 [D loss: 0.594204, acc.: 64.06%] [G loss: 0.853998]\n",
            "2521 [D loss: 0.596472, acc.: 62.50%] [G loss: 0.864481]\n",
            "2522 [D loss: 0.594389, acc.: 64.06%] [G loss: 0.861192]\n",
            "2523 [D loss: 0.592023, acc.: 64.06%] [G loss: 0.828672]\n",
            "2524 [D loss: 0.592334, acc.: 64.06%] [G loss: 0.853213]\n",
            "2525 [D loss: 0.586286, acc.: 65.62%] [G loss: 0.783103]\n",
            "2526 [D loss: 0.614948, acc.: 57.81%] [G loss: 0.828139]\n",
            "2527 [D loss: 0.630723, acc.: 56.25%] [G loss: 0.837133]\n",
            "2528 [D loss: 0.594127, acc.: 64.06%] [G loss: 0.862979]\n",
            "2529 [D loss: 0.596932, acc.: 62.50%] [G loss: 0.853205]\n",
            "2530 [D loss: 0.597107, acc.: 62.50%] [G loss: 0.864926]\n",
            "2531 [D loss: 0.595996, acc.: 62.50%] [G loss: 0.864294]\n",
            "2532 [D loss: 0.599140, acc.: 62.50%] [G loss: 0.864054]\n",
            "2533 [D loss: 0.595186, acc.: 62.50%] [G loss: 0.852744]\n",
            "2534 [D loss: 0.597618, acc.: 62.50%] [G loss: 0.870613]\n",
            "2535 [D loss: 0.593473, acc.: 62.50%] [G loss: 0.858737]\n",
            "2536 [D loss: 0.600045, acc.: 62.50%] [G loss: 0.859772]\n",
            "2537 [D loss: 0.598992, acc.: 62.50%] [G loss: 0.858573]\n",
            "2538 [D loss: 0.595255, acc.: 62.50%] [G loss: 0.856724]\n",
            "2539 [D loss: 0.594710, acc.: 62.50%] [G loss: 0.860082]\n",
            "2540 [D loss: 0.595798, acc.: 62.50%] [G loss: 0.858058]\n",
            "2541 [D loss: 0.597618, acc.: 62.50%] [G loss: 0.852749]\n",
            "2542 [D loss: 0.600724, acc.: 62.50%] [G loss: 0.854838]\n",
            "2543 [D loss: 0.596068, acc.: 62.50%] [G loss: 0.855530]\n",
            "2544 [D loss: 0.597368, acc.: 62.50%] [G loss: 0.862569]\n",
            "2545 [D loss: 0.598874, acc.: 62.50%] [G loss: 0.857829]\n",
            "2546 [D loss: 0.600142, acc.: 62.50%] [G loss: 0.860713]\n",
            "2547 [D loss: 0.597392, acc.: 62.50%] [G loss: 0.866247]\n",
            "2548 [D loss: 0.599592, acc.: 62.50%] [G loss: 0.862917]\n",
            "2549 [D loss: 0.610655, acc.: 62.50%] [G loss: 0.853247]\n",
            "2550 [D loss: 0.599844, acc.: 62.50%] [G loss: 0.849736]\n",
            "2551 [D loss: 0.600975, acc.: 62.50%] [G loss: 0.850437]\n",
            "2552 [D loss: 0.603851, acc.: 62.50%] [G loss: 0.846503]\n",
            "2553 [D loss: 0.599685, acc.: 62.50%] [G loss: 0.853743]\n",
            "2554 [D loss: 0.600294, acc.: 62.50%] [G loss: 0.852723]\n",
            "2555 [D loss: 0.601781, acc.: 62.50%] [G loss: 0.860289]\n",
            "2556 [D loss: 0.598339, acc.: 62.50%] [G loss: 0.859786]\n",
            "2557 [D loss: 0.599273, acc.: 62.50%] [G loss: 0.859680]\n",
            "2558 [D loss: 0.601761, acc.: 62.50%] [G loss: 0.855976]\n",
            "2559 [D loss: 0.601676, acc.: 62.50%] [G loss: 0.852895]\n",
            "2560 [D loss: 0.601022, acc.: 62.50%] [G loss: 0.849309]\n",
            "2561 [D loss: 0.599794, acc.: 62.50%] [G loss: 0.853270]\n",
            "2562 [D loss: 0.600186, acc.: 62.50%] [G loss: 0.851200]\n",
            "2563 [D loss: 0.599369, acc.: 62.50%] [G loss: 0.848876]\n",
            "2564 [D loss: 0.599832, acc.: 62.50%] [G loss: 0.845759]\n",
            "2565 [D loss: 0.601544, acc.: 62.50%] [G loss: 0.850159]\n",
            "2566 [D loss: 0.601963, acc.: 62.50%] [G loss: 0.849246]\n",
            "2567 [D loss: 0.602293, acc.: 62.50%] [G loss: 0.846530]\n",
            "2568 [D loss: 0.600337, acc.: 62.50%] [G loss: 0.842644]\n",
            "2569 [D loss: 0.597383, acc.: 62.50%] [G loss: 0.863983]\n",
            "2570 [D loss: 0.597474, acc.: 62.50%] [G loss: 0.851853]\n",
            "2571 [D loss: 0.593924, acc.: 62.50%] [G loss: 0.856103]\n",
            "2572 [D loss: 0.598490, acc.: 62.50%] [G loss: 0.851096]\n",
            "2573 [D loss: 0.597530, acc.: 62.50%] [G loss: 0.846920]\n",
            "2574 [D loss: 0.598935, acc.: 62.50%] [G loss: 0.843551]\n",
            "2575 [D loss: 0.602652, acc.: 62.50%] [G loss: 0.848260]\n",
            "2576 [D loss: 0.607680, acc.: 62.50%] [G loss: 0.842457]\n",
            "2577 [D loss: 0.595663, acc.: 62.50%] [G loss: 0.851723]\n",
            "2578 [D loss: 0.597168, acc.: 62.50%] [G loss: 0.855730]\n",
            "2579 [D loss: 0.611656, acc.: 60.94%] [G loss: 0.859546]\n",
            "2580 [D loss: 0.595164, acc.: 62.50%] [G loss: 0.861498]\n",
            "2581 [D loss: 0.601908, acc.: 62.50%] [G loss: 0.859028]\n",
            "2582 [D loss: 0.601080, acc.: 62.50%] [G loss: 0.860024]\n",
            "2583 [D loss: 0.603132, acc.: 60.94%] [G loss: 0.855473]\n",
            "2584 [D loss: 0.598973, acc.: 62.50%] [G loss: 0.856165]\n",
            "2585 [D loss: 0.596437, acc.: 62.50%] [G loss: 0.851238]\n",
            "2586 [D loss: 0.594725, acc.: 62.50%] [G loss: 0.854684]\n",
            "2587 [D loss: 0.593770, acc.: 62.50%] [G loss: 0.854808]\n",
            "2588 [D loss: 0.597178, acc.: 62.50%] [G loss: 0.845327]\n",
            "2589 [D loss: 0.598211, acc.: 62.50%] [G loss: 0.859717]\n",
            "2590 [D loss: 0.598576, acc.: 62.50%] [G loss: 0.868091]\n",
            "2591 [D loss: 0.596757, acc.: 62.50%] [G loss: 0.853795]\n",
            "2592 [D loss: 0.596477, acc.: 62.50%] [G loss: 0.854389]\n",
            "2593 [D loss: 0.595974, acc.: 62.50%] [G loss: 0.846023]\n",
            "2594 [D loss: 0.603574, acc.: 62.50%] [G loss: 0.842661]\n",
            "2595 [D loss: 0.596320, acc.: 62.50%] [G loss: 0.849835]\n",
            "2596 [D loss: 0.598733, acc.: 62.50%] [G loss: 0.852921]\n",
            "2597 [D loss: 0.600258, acc.: 62.50%] [G loss: 0.843335]\n",
            "2598 [D loss: 0.593033, acc.: 62.50%] [G loss: 0.849616]\n",
            "2599 [D loss: 0.597552, acc.: 62.50%] [G loss: 0.848781]\n",
            "2600 [D loss: 0.600107, acc.: 62.50%] [G loss: 0.841435]\n",
            "generated_data\n",
            "2601 [D loss: 0.600628, acc.: 62.50%] [G loss: 0.831289]\n",
            "2602 [D loss: 0.598021, acc.: 62.50%] [G loss: 0.839720]\n",
            "2603 [D loss: 0.592563, acc.: 62.50%] [G loss: 0.842205]\n",
            "2604 [D loss: 0.596346, acc.: 62.50%] [G loss: 0.859678]\n",
            "2605 [D loss: 0.593267, acc.: 62.50%] [G loss: 0.843384]\n",
            "2606 [D loss: 0.596395, acc.: 62.50%] [G loss: 0.836499]\n",
            "2607 [D loss: 0.601559, acc.: 62.50%] [G loss: 0.851424]\n",
            "2608 [D loss: 0.596492, acc.: 62.50%] [G loss: 0.843840]\n",
            "2609 [D loss: 0.599245, acc.: 62.50%] [G loss: 0.830878]\n",
            "2610 [D loss: 0.594449, acc.: 62.50%] [G loss: 0.835651]\n",
            "2611 [D loss: 0.597983, acc.: 62.50%] [G loss: 0.836352]\n",
            "2612 [D loss: 0.605809, acc.: 62.50%] [G loss: 0.836808]\n",
            "2613 [D loss: 0.598645, acc.: 62.50%] [G loss: 0.833751]\n",
            "2614 [D loss: 0.595135, acc.: 62.50%] [G loss: 0.845304]\n",
            "2615 [D loss: 0.595371, acc.: 62.50%] [G loss: 0.843780]\n",
            "2616 [D loss: 0.600693, acc.: 62.50%] [G loss: 0.843633]\n",
            "2617 [D loss: 0.600275, acc.: 64.06%] [G loss: 0.835725]\n",
            "2618 [D loss: 0.595446, acc.: 62.50%] [G loss: 0.835684]\n",
            "2619 [D loss: 0.596157, acc.: 62.50%] [G loss: 0.846467]\n",
            "2620 [D loss: 0.597189, acc.: 62.50%] [G loss: 0.848401]\n",
            "2621 [D loss: 0.599106, acc.: 62.50%] [G loss: 0.838152]\n",
            "2622 [D loss: 0.602584, acc.: 62.50%] [G loss: 0.831386]\n",
            "2623 [D loss: 0.594402, acc.: 62.50%] [G loss: 0.846472]\n",
            "2624 [D loss: 0.598172, acc.: 62.50%] [G loss: 0.842376]\n",
            "2625 [D loss: 0.599362, acc.: 62.50%] [G loss: 0.835397]\n",
            "2626 [D loss: 0.598711, acc.: 62.50%] [G loss: 0.847210]\n",
            "2627 [D loss: 0.600060, acc.: 62.50%] [G loss: 0.845476]\n",
            "2628 [D loss: 0.602122, acc.: 62.50%] [G loss: 0.848592]\n",
            "2629 [D loss: 0.596279, acc.: 62.50%] [G loss: 0.849181]\n",
            "2630 [D loss: 0.594225, acc.: 62.50%] [G loss: 0.851134]\n",
            "2631 [D loss: 0.592623, acc.: 62.50%] [G loss: 0.836484]\n",
            "2632 [D loss: 0.597378, acc.: 62.50%] [G loss: 0.842474]\n",
            "2633 [D loss: 0.597829, acc.: 62.50%] [G loss: 0.845156]\n",
            "2634 [D loss: 0.597100, acc.: 62.50%] [G loss: 0.828513]\n",
            "2635 [D loss: 0.599489, acc.: 62.50%] [G loss: 0.829930]\n",
            "2636 [D loss: 0.594802, acc.: 62.50%] [G loss: 0.844715]\n",
            "2637 [D loss: 0.599783, acc.: 62.50%] [G loss: 0.845922]\n",
            "2638 [D loss: 0.599413, acc.: 62.50%] [G loss: 0.837927]\n",
            "2639 [D loss: 0.596519, acc.: 62.50%] [G loss: 0.839634]\n",
            "2640 [D loss: 0.596187, acc.: 62.50%] [G loss: 0.846349]\n",
            "2641 [D loss: 0.598342, acc.: 62.50%] [G loss: 0.845481]\n",
            "2642 [D loss: 0.598053, acc.: 62.50%] [G loss: 0.846544]\n",
            "2643 [D loss: 0.594010, acc.: 62.50%] [G loss: 0.852050]\n",
            "2644 [D loss: 0.601478, acc.: 62.50%] [G loss: 0.854009]\n",
            "2645 [D loss: 0.598722, acc.: 62.50%] [G loss: 0.851968]\n",
            "2646 [D loss: 0.591865, acc.: 62.50%] [G loss: 0.851419]\n",
            "2647 [D loss: 0.597676, acc.: 62.50%] [G loss: 0.845205]\n",
            "2648 [D loss: 0.600572, acc.: 60.94%] [G loss: 0.846258]\n",
            "2649 [D loss: 0.594210, acc.: 62.50%] [G loss: 0.852404]\n",
            "2650 [D loss: 0.599055, acc.: 62.50%] [G loss: 0.860574]\n",
            "2651 [D loss: 0.602146, acc.: 62.50%] [G loss: 0.847409]\n",
            "2652 [D loss: 0.597439, acc.: 62.50%] [G loss: 0.852142]\n",
            "2653 [D loss: 0.599497, acc.: 60.94%] [G loss: 0.856649]\n",
            "2654 [D loss: 0.597154, acc.: 62.50%] [G loss: 0.865663]\n",
            "2655 [D loss: 0.596407, acc.: 62.50%] [G loss: 0.870302]\n",
            "2656 [D loss: 0.604445, acc.: 62.50%] [G loss: 0.849456]\n",
            "2657 [D loss: 0.597157, acc.: 62.50%] [G loss: 0.852839]\n",
            "2658 [D loss: 0.596332, acc.: 62.50%] [G loss: 0.858919]\n",
            "2659 [D loss: 0.600921, acc.: 62.50%] [G loss: 0.859317]\n",
            "2660 [D loss: 0.596444, acc.: 62.50%] [G loss: 0.872799]\n",
            "2661 [D loss: 0.599583, acc.: 62.50%] [G loss: 0.886238]\n",
            "2662 [D loss: 0.598682, acc.: 62.50%] [G loss: 0.868891]\n",
            "2663 [D loss: 0.600143, acc.: 62.50%] [G loss: 0.866239]\n",
            "2664 [D loss: 0.595916, acc.: 62.50%] [G loss: 0.863097]\n",
            "2665 [D loss: 0.603628, acc.: 62.50%] [G loss: 0.866677]\n",
            "2666 [D loss: 0.601608, acc.: 62.50%] [G loss: 0.865430]\n",
            "2667 [D loss: 0.597622, acc.: 62.50%] [G loss: 0.866946]\n",
            "2668 [D loss: 0.599458, acc.: 62.50%] [G loss: 0.872150]\n",
            "2669 [D loss: 0.594865, acc.: 62.50%] [G loss: 0.871729]\n",
            "2670 [D loss: 0.596331, acc.: 62.50%] [G loss: 0.876329]\n",
            "2671 [D loss: 0.597657, acc.: 62.50%] [G loss: 0.867872]\n",
            "2672 [D loss: 0.595702, acc.: 62.50%] [G loss: 0.864656]\n",
            "2673 [D loss: 0.595292, acc.: 62.50%] [G loss: 0.865606]\n",
            "2674 [D loss: 0.597445, acc.: 62.50%] [G loss: 0.861418]\n",
            "2675 [D loss: 0.601016, acc.: 62.50%] [G loss: 0.860517]\n",
            "2676 [D loss: 0.598983, acc.: 62.50%] [G loss: 0.859992]\n",
            "2677 [D loss: 0.597544, acc.: 62.50%] [G loss: 0.861361]\n",
            "2678 [D loss: 0.598158, acc.: 64.06%] [G loss: 0.856713]\n",
            "2679 [D loss: 0.604555, acc.: 62.50%] [G loss: 0.855262]\n",
            "2680 [D loss: 0.595138, acc.: 62.50%] [G loss: 0.858340]\n",
            "2681 [D loss: 0.597646, acc.: 62.50%] [G loss: 0.856145]\n",
            "2682 [D loss: 0.602565, acc.: 62.50%] [G loss: 0.859738]\n",
            "2683 [D loss: 0.596941, acc.: 62.50%] [G loss: 0.851566]\n",
            "2684 [D loss: 0.597564, acc.: 62.50%] [G loss: 0.861789]\n",
            "2685 [D loss: 0.607790, acc.: 62.50%] [G loss: 0.885484]\n",
            "2686 [D loss: 0.598817, acc.: 62.50%] [G loss: 0.863098]\n",
            "2687 [D loss: 0.597526, acc.: 62.50%] [G loss: 0.859985]\n",
            "2688 [D loss: 0.596961, acc.: 62.50%] [G loss: 0.866233]\n",
            "2689 [D loss: 0.597932, acc.: 62.50%] [G loss: 0.860731]\n",
            "2690 [D loss: 0.600365, acc.: 62.50%] [G loss: 0.864933]\n",
            "2691 [D loss: 0.603667, acc.: 62.50%] [G loss: 0.859296]\n",
            "2692 [D loss: 0.598552, acc.: 62.50%] [G loss: 0.857952]\n",
            "2693 [D loss: 0.599389, acc.: 62.50%] [G loss: 0.856377]\n",
            "2694 [D loss: 0.597409, acc.: 62.50%] [G loss: 0.862495]\n",
            "2695 [D loss: 0.597435, acc.: 62.50%] [G loss: 0.863081]\n",
            "2696 [D loss: 0.600322, acc.: 62.50%] [G loss: 0.867625]\n",
            "2697 [D loss: 0.598701, acc.: 62.50%] [G loss: 0.861781]\n",
            "2698 [D loss: 0.595065, acc.: 62.50%] [G loss: 0.856314]\n",
            "2699 [D loss: 0.596929, acc.: 62.50%] [G loss: 0.858004]\n",
            "2700 [D loss: 0.595387, acc.: 62.50%] [G loss: 0.854221]\n",
            "generated_data\n",
            "2701 [D loss: 0.597676, acc.: 62.50%] [G loss: 0.852620]\n",
            "2702 [D loss: 0.595321, acc.: 62.50%] [G loss: 0.858499]\n",
            "2703 [D loss: 0.592791, acc.: 62.50%] [G loss: 0.866266]\n",
            "2704 [D loss: 0.606397, acc.: 62.50%] [G loss: 0.857812]\n",
            "2705 [D loss: 0.603706, acc.: 62.50%] [G loss: 0.849537]\n",
            "2706 [D loss: 0.596998, acc.: 62.50%] [G loss: 0.852908]\n",
            "2707 [D loss: 0.600910, acc.: 62.50%] [G loss: 0.852459]\n",
            "2708 [D loss: 0.595373, acc.: 62.50%] [G loss: 0.854958]\n",
            "2709 [D loss: 0.600309, acc.: 60.94%] [G loss: 0.858064]\n",
            "2710 [D loss: 0.599595, acc.: 62.50%] [G loss: 0.854872]\n",
            "2711 [D loss: 0.597939, acc.: 62.50%] [G loss: 0.849691]\n",
            "2712 [D loss: 0.595323, acc.: 62.50%] [G loss: 0.852401]\n",
            "2713 [D loss: 0.597864, acc.: 62.50%] [G loss: 0.856749]\n",
            "2714 [D loss: 0.599358, acc.: 62.50%] [G loss: 0.852837]\n",
            "2715 [D loss: 0.594467, acc.: 62.50%] [G loss: 0.852517]\n",
            "2716 [D loss: 0.598978, acc.: 62.50%] [G loss: 0.847228]\n",
            "2717 [D loss: 0.592506, acc.: 64.06%] [G loss: 0.844845]\n",
            "2718 [D loss: 0.596497, acc.: 62.50%] [G loss: 0.841026]\n",
            "2719 [D loss: 0.597198, acc.: 62.50%] [G loss: 0.845790]\n",
            "2720 [D loss: 0.596517, acc.: 62.50%] [G loss: 0.852826]\n",
            "2721 [D loss: 0.591773, acc.: 64.06%] [G loss: 0.849068]\n",
            "2722 [D loss: 0.595803, acc.: 64.06%] [G loss: 0.830845]\n",
            "2723 [D loss: 0.596655, acc.: 64.06%] [G loss: 0.849867]\n",
            "2724 [D loss: 0.598794, acc.: 65.62%] [G loss: 0.836675]\n",
            "2725 [D loss: 0.594733, acc.: 64.06%] [G loss: 0.841641]\n",
            "2726 [D loss: 0.598941, acc.: 60.94%] [G loss: 0.838438]\n",
            "2727 [D loss: 0.599537, acc.: 62.50%] [G loss: 0.837715]\n",
            "2728 [D loss: 0.603163, acc.: 64.06%] [G loss: 0.851991]\n",
            "2729 [D loss: 0.592932, acc.: 64.06%] [G loss: 0.860750]\n",
            "2730 [D loss: 0.600571, acc.: 64.06%] [G loss: 0.846492]\n",
            "2731 [D loss: 0.601505, acc.: 59.38%] [G loss: 0.846032]\n",
            "2732 [D loss: 0.597284, acc.: 60.94%] [G loss: 0.851712]\n",
            "2733 [D loss: 0.597720, acc.: 60.94%] [G loss: 0.840433]\n",
            "2734 [D loss: 0.597476, acc.: 64.06%] [G loss: 0.839015]\n",
            "2735 [D loss: 0.603714, acc.: 59.38%] [G loss: 0.844491]\n",
            "2736 [D loss: 0.606469, acc.: 59.38%] [G loss: 0.843306]\n",
            "2737 [D loss: 0.603452, acc.: 62.50%] [G loss: 0.852096]\n",
            "2738 [D loss: 0.594824, acc.: 62.50%] [G loss: 0.856306]\n",
            "2739 [D loss: 0.598811, acc.: 62.50%] [G loss: 0.848584]\n",
            "2740 [D loss: 0.598401, acc.: 62.50%] [G loss: 0.867054]\n",
            "2741 [D loss: 0.601357, acc.: 62.50%] [G loss: 0.861938]\n",
            "2742 [D loss: 0.596195, acc.: 62.50%] [G loss: 0.854298]\n",
            "2743 [D loss: 0.596358, acc.: 62.50%] [G loss: 0.848953]\n",
            "2744 [D loss: 0.597338, acc.: 62.50%] [G loss: 0.859820]\n",
            "2745 [D loss: 0.598368, acc.: 62.50%] [G loss: 0.854811]\n",
            "2746 [D loss: 0.600535, acc.: 62.50%] [G loss: 0.852476]\n",
            "2747 [D loss: 0.599837, acc.: 62.50%] [G loss: 0.859576]\n",
            "2748 [D loss: 0.594510, acc.: 62.50%] [G loss: 0.850784]\n",
            "2749 [D loss: 0.601442, acc.: 62.50%] [G loss: 0.858368]\n",
            "2750 [D loss: 0.597349, acc.: 62.50%] [G loss: 0.858056]\n",
            "2751 [D loss: 0.593960, acc.: 62.50%] [G loss: 0.856920]\n",
            "2752 [D loss: 0.597867, acc.: 62.50%] [G loss: 0.832503]\n",
            "2753 [D loss: 0.606559, acc.: 57.81%] [G loss: 0.853606]\n",
            "2754 [D loss: 0.597680, acc.: 60.94%] [G loss: 0.856043]\n",
            "2755 [D loss: 0.598521, acc.: 62.50%] [G loss: 0.863825]\n",
            "2756 [D loss: 0.595630, acc.: 62.50%] [G loss: 0.857364]\n",
            "2757 [D loss: 0.596926, acc.: 62.50%] [G loss: 0.856147]\n",
            "2758 [D loss: 0.594880, acc.: 62.50%] [G loss: 0.858462]\n",
            "2759 [D loss: 0.599024, acc.: 62.50%] [G loss: 0.853324]\n",
            "2760 [D loss: 0.595651, acc.: 62.50%] [G loss: 0.844593]\n",
            "2761 [D loss: 0.598967, acc.: 60.94%] [G loss: 0.859018]\n",
            "2762 [D loss: 0.595763, acc.: 62.50%] [G loss: 0.848170]\n",
            "2763 [D loss: 0.599709, acc.: 60.94%] [G loss: 0.860349]\n",
            "2764 [D loss: 0.597898, acc.: 62.50%] [G loss: 0.857644]\n",
            "2765 [D loss: 0.596467, acc.: 62.50%] [G loss: 0.865527]\n",
            "2766 [D loss: 0.594833, acc.: 62.50%] [G loss: 0.857472]\n",
            "2767 [D loss: 0.599263, acc.: 62.50%] [G loss: 0.856882]\n",
            "2768 [D loss: 0.599864, acc.: 62.50%] [G loss: 0.862685]\n",
            "2769 [D loss: 0.596682, acc.: 62.50%] [G loss: 0.865419]\n",
            "2770 [D loss: 0.597532, acc.: 62.50%] [G loss: 0.861884]\n",
            "2771 [D loss: 0.598107, acc.: 62.50%] [G loss: 0.847485]\n",
            "2772 [D loss: 0.600473, acc.: 62.50%] [G loss: 0.859909]\n",
            "2773 [D loss: 0.596388, acc.: 62.50%] [G loss: 0.860450]\n",
            "2774 [D loss: 0.598199, acc.: 62.50%] [G loss: 0.853645]\n",
            "2775 [D loss: 0.600564, acc.: 62.50%] [G loss: 0.857659]\n",
            "2776 [D loss: 0.600382, acc.: 62.50%] [G loss: 0.856974]\n",
            "2777 [D loss: 0.599458, acc.: 62.50%] [G loss: 0.860769]\n",
            "2778 [D loss: 0.600085, acc.: 62.50%] [G loss: 0.855003]\n",
            "2779 [D loss: 0.597700, acc.: 62.50%] [G loss: 0.856637]\n",
            "2780 [D loss: 0.597149, acc.: 62.50%] [G loss: 0.857698]\n",
            "2781 [D loss: 0.596258, acc.: 62.50%] [G loss: 0.855844]\n",
            "2782 [D loss: 0.597458, acc.: 62.50%] [G loss: 0.855361]\n",
            "2783 [D loss: 0.598730, acc.: 62.50%] [G loss: 0.854066]\n",
            "2784 [D loss: 0.595041, acc.: 62.50%] [G loss: 0.852861]\n",
            "2785 [D loss: 0.598311, acc.: 62.50%] [G loss: 0.856783]\n",
            "2786 [D loss: 0.598338, acc.: 62.50%] [G loss: 0.855506]\n",
            "2787 [D loss: 0.597480, acc.: 62.50%] [G loss: 0.849246]\n",
            "2788 [D loss: 0.596078, acc.: 62.50%] [G loss: 0.852374]\n",
            "2789 [D loss: 0.597725, acc.: 62.50%] [G loss: 0.862926]\n",
            "2790 [D loss: 0.597743, acc.: 62.50%] [G loss: 0.861419]\n",
            "2791 [D loss: 0.597996, acc.: 62.50%] [G loss: 0.866929]\n",
            "2792 [D loss: 0.597486, acc.: 62.50%] [G loss: 0.867994]\n",
            "2793 [D loss: 0.598232, acc.: 62.50%] [G loss: 0.873275]\n",
            "2794 [D loss: 0.602820, acc.: 62.50%] [G loss: 0.857518]\n",
            "2795 [D loss: 0.597315, acc.: 62.50%] [G loss: 0.861180]\n",
            "2796 [D loss: 0.598349, acc.: 62.50%] [G loss: 0.856370]\n",
            "2797 [D loss: 0.595841, acc.: 62.50%] [G loss: 0.859528]\n",
            "2798 [D loss: 0.597303, acc.: 62.50%] [G loss: 0.856096]\n",
            "2799 [D loss: 0.599553, acc.: 62.50%] [G loss: 0.857741]\n",
            "2800 [D loss: 0.597311, acc.: 62.50%] [G loss: 0.857099]\n",
            "generated_data\n",
            "2801 [D loss: 0.598538, acc.: 62.50%] [G loss: 0.856039]\n",
            "2802 [D loss: 0.597152, acc.: 62.50%] [G loss: 0.857959]\n",
            "2803 [D loss: 0.597751, acc.: 62.50%] [G loss: 0.858037]\n",
            "2804 [D loss: 0.598615, acc.: 62.50%] [G loss: 0.856575]\n",
            "2805 [D loss: 0.598047, acc.: 62.50%] [G loss: 0.857124]\n",
            "2806 [D loss: 0.597986, acc.: 62.50%] [G loss: 0.855480]\n",
            "2807 [D loss: 0.596217, acc.: 62.50%] [G loss: 0.859508]\n",
            "2808 [D loss: 0.599085, acc.: 62.50%] [G loss: 0.856938]\n",
            "2809 [D loss: 0.599638, acc.: 62.50%] [G loss: 0.855882]\n",
            "2810 [D loss: 0.596589, acc.: 62.50%] [G loss: 0.858263]\n",
            "2811 [D loss: 0.597603, acc.: 62.50%] [G loss: 0.853886]\n",
            "2812 [D loss: 0.598700, acc.: 62.50%] [G loss: 0.857504]\n",
            "2813 [D loss: 0.597381, acc.: 62.50%] [G loss: 0.852570]\n",
            "2814 [D loss: 0.595091, acc.: 62.50%] [G loss: 0.856781]\n",
            "2815 [D loss: 0.598892, acc.: 62.50%] [G loss: 0.858052]\n",
            "2816 [D loss: 0.598041, acc.: 62.50%] [G loss: 0.860854]\n",
            "2817 [D loss: 0.596965, acc.: 62.50%] [G loss: 0.863307]\n",
            "2818 [D loss: 0.600683, acc.: 62.50%] [G loss: 0.868826]\n",
            "2819 [D loss: 0.599758, acc.: 62.50%] [G loss: 0.858185]\n",
            "2820 [D loss: 0.600226, acc.: 62.50%] [G loss: 0.859211]\n",
            "2821 [D loss: 0.597971, acc.: 62.50%] [G loss: 0.857723]\n",
            "2822 [D loss: 0.597908, acc.: 62.50%] [G loss: 0.857570]\n",
            "2823 [D loss: 0.598319, acc.: 62.50%] [G loss: 0.859996]\n",
            "2824 [D loss: 0.594985, acc.: 62.50%] [G loss: 0.852380]\n",
            "2825 [D loss: 0.594307, acc.: 62.50%] [G loss: 0.855573]\n",
            "2826 [D loss: 0.595721, acc.: 62.50%] [G loss: 0.855877]\n",
            "2827 [D loss: 0.599020, acc.: 62.50%] [G loss: 0.853961]\n",
            "2828 [D loss: 0.598975, acc.: 62.50%] [G loss: 0.855844]\n",
            "2829 [D loss: 0.598063, acc.: 62.50%] [G loss: 0.852095]\n",
            "2830 [D loss: 0.598343, acc.: 62.50%] [G loss: 0.847579]\n",
            "2831 [D loss: 0.596052, acc.: 62.50%] [G loss: 0.851131]\n",
            "2832 [D loss: 0.598688, acc.: 62.50%] [G loss: 0.851464]\n",
            "2833 [D loss: 0.598692, acc.: 62.50%] [G loss: 0.853589]\n",
            "2834 [D loss: 0.598762, acc.: 62.50%] [G loss: 0.850799]\n",
            "2835 [D loss: 0.602163, acc.: 62.50%] [G loss: 0.857512]\n",
            "2836 [D loss: 0.595670, acc.: 62.50%] [G loss: 0.856756]\n",
            "2837 [D loss: 0.598318, acc.: 62.50%] [G loss: 0.852446]\n",
            "2838 [D loss: 0.597983, acc.: 62.50%] [G loss: 0.856454]\n",
            "2839 [D loss: 0.597329, acc.: 62.50%] [G loss: 0.859387]\n",
            "2840 [D loss: 0.596267, acc.: 62.50%] [G loss: 0.857032]\n",
            "2841 [D loss: 0.595249, acc.: 62.50%] [G loss: 0.868816]\n",
            "2842 [D loss: 0.595043, acc.: 62.50%] [G loss: 0.924158]\n",
            "2843 [D loss: 0.600201, acc.: 62.50%] [G loss: 0.865238]\n",
            "2844 [D loss: 0.598693, acc.: 62.50%] [G loss: 0.859335]\n",
            "2845 [D loss: 0.597038, acc.: 62.50%] [G loss: 0.857961]\n",
            "2846 [D loss: 0.597216, acc.: 62.50%] [G loss: 0.854687]\n",
            "2847 [D loss: 0.599183, acc.: 62.50%] [G loss: 0.858021]\n",
            "2848 [D loss: 0.595528, acc.: 62.50%] [G loss: 0.854800]\n",
            "2849 [D loss: 0.596589, acc.: 62.50%] [G loss: 0.857552]\n",
            "2850 [D loss: 0.595629, acc.: 62.50%] [G loss: 0.859855]\n",
            "2851 [D loss: 0.595177, acc.: 62.50%] [G loss: 0.858733]\n",
            "2852 [D loss: 0.597271, acc.: 62.50%] [G loss: 0.854705]\n",
            "2853 [D loss: 0.597776, acc.: 62.50%] [G loss: 0.853055]\n",
            "2854 [D loss: 0.599413, acc.: 62.50%] [G loss: 0.844045]\n",
            "2855 [D loss: 0.604521, acc.: 62.50%] [G loss: 0.843165]\n",
            "2856 [D loss: 0.601970, acc.: 62.50%] [G loss: 0.845940]\n",
            "2857 [D loss: 0.597425, acc.: 62.50%] [G loss: 0.853461]\n",
            "2858 [D loss: 0.597216, acc.: 62.50%] [G loss: 0.859541]\n",
            "2859 [D loss: 0.595813, acc.: 62.50%] [G loss: 0.894108]\n",
            "2860 [D loss: 0.604599, acc.: 62.50%] [G loss: 0.849449]\n",
            "2861 [D loss: 0.598830, acc.: 62.50%] [G loss: 0.855532]\n",
            "2862 [D loss: 0.598775, acc.: 62.50%] [G loss: 0.856120]\n",
            "2863 [D loss: 0.599894, acc.: 62.50%] [G loss: 0.857024]\n",
            "2864 [D loss: 0.597010, acc.: 62.50%] [G loss: 0.857590]\n",
            "2865 [D loss: 0.598377, acc.: 62.50%] [G loss: 0.845108]\n",
            "2866 [D loss: 0.597406, acc.: 62.50%] [G loss: 0.854504]\n",
            "2867 [D loss: 0.598524, acc.: 62.50%] [G loss: 0.850800]\n",
            "2868 [D loss: 0.603913, acc.: 62.50%] [G loss: 0.850547]\n",
            "2869 [D loss: 0.597693, acc.: 62.50%] [G loss: 0.853978]\n",
            "2870 [D loss: 0.598825, acc.: 62.50%] [G loss: 0.859397]\n",
            "2871 [D loss: 0.596218, acc.: 62.50%] [G loss: 0.855287]\n",
            "2872 [D loss: 0.598522, acc.: 62.50%] [G loss: 0.857628]\n",
            "2873 [D loss: 0.598686, acc.: 62.50%] [G loss: 0.854828]\n",
            "2874 [D loss: 0.597612, acc.: 62.50%] [G loss: 0.856553]\n",
            "2875 [D loss: 0.598011, acc.: 62.50%] [G loss: 0.849372]\n",
            "2876 [D loss: 0.597834, acc.: 62.50%] [G loss: 0.857333]\n",
            "2877 [D loss: 0.598176, acc.: 62.50%] [G loss: 0.857219]\n",
            "2878 [D loss: 0.598811, acc.: 62.50%] [G loss: 0.858710]\n",
            "2879 [D loss: 0.595829, acc.: 62.50%] [G loss: 0.856730]\n",
            "2880 [D loss: 0.600582, acc.: 62.50%] [G loss: 0.855886]\n",
            "2881 [D loss: 0.597480, acc.: 62.50%] [G loss: 0.854346]\n",
            "2882 [D loss: 0.596967, acc.: 62.50%] [G loss: 0.855244]\n",
            "2883 [D loss: 0.596201, acc.: 62.50%] [G loss: 0.855484]\n",
            "2884 [D loss: 0.599520, acc.: 62.50%] [G loss: 0.854243]\n",
            "2885 [D loss: 0.597521, acc.: 62.50%] [G loss: 0.855596]\n",
            "2886 [D loss: 0.597054, acc.: 62.50%] [G loss: 0.857164]\n",
            "2887 [D loss: 0.597159, acc.: 62.50%] [G loss: 0.855130]\n",
            "2888 [D loss: 0.598972, acc.: 62.50%] [G loss: 0.862689]\n",
            "2889 [D loss: 0.596065, acc.: 62.50%] [G loss: 0.855300]\n",
            "2890 [D loss: 0.599102, acc.: 62.50%] [G loss: 0.853866]\n",
            "2891 [D loss: 0.596616, acc.: 62.50%] [G loss: 0.853021]\n",
            "2892 [D loss: 0.596744, acc.: 62.50%] [G loss: 0.859498]\n",
            "2893 [D loss: 0.598861, acc.: 62.50%] [G loss: 0.853045]\n",
            "2894 [D loss: 0.596337, acc.: 62.50%] [G loss: 0.854866]\n",
            "2895 [D loss: 0.595653, acc.: 62.50%] [G loss: 0.860191]\n",
            "2896 [D loss: 0.595122, acc.: 62.50%] [G loss: 0.857850]\n",
            "2897 [D loss: 0.598295, acc.: 62.50%] [G loss: 0.866808]\n",
            "2898 [D loss: 0.593986, acc.: 62.50%] [G loss: 0.872446]\n",
            "2899 [D loss: 0.600355, acc.: 62.50%] [G loss: 0.859530]\n",
            "2900 [D loss: 0.597971, acc.: 62.50%] [G loss: 0.860222]\n",
            "generated_data\n",
            "2901 [D loss: 0.599959, acc.: 62.50%] [G loss: 0.857749]\n",
            "2902 [D loss: 0.595937, acc.: 62.50%] [G loss: 0.859340]\n",
            "2903 [D loss: 0.599007, acc.: 62.50%] [G loss: 0.857613]\n",
            "2904 [D loss: 0.598440, acc.: 62.50%] [G loss: 0.857754]\n",
            "2905 [D loss: 0.604989, acc.: 62.50%] [G loss: 0.847179]\n",
            "2906 [D loss: 0.600009, acc.: 62.50%] [G loss: 0.852799]\n",
            "2907 [D loss: 0.598848, acc.: 62.50%] [G loss: 0.855446]\n",
            "2908 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.859886]\n",
            "2909 [D loss: 0.597989, acc.: 62.50%] [G loss: 0.854170]\n",
            "2910 [D loss: 0.598954, acc.: 62.50%] [G loss: 0.852776]\n",
            "2911 [D loss: 0.596505, acc.: 62.50%] [G loss: 0.847703]\n",
            "2912 [D loss: 0.597393, acc.: 62.50%] [G loss: 0.854052]\n",
            "2913 [D loss: 0.597114, acc.: 62.50%] [G loss: 0.847519]\n",
            "2914 [D loss: 0.596067, acc.: 62.50%] [G loss: 0.848837]\n",
            "2915 [D loss: 0.598118, acc.: 62.50%] [G loss: 0.853227]\n",
            "2916 [D loss: 0.598383, acc.: 62.50%] [G loss: 0.860427]\n",
            "2917 [D loss: 0.598563, acc.: 62.50%] [G loss: 0.855590]\n",
            "2918 [D loss: 0.596756, acc.: 62.50%] [G loss: 0.860069]\n",
            "2919 [D loss: 0.595723, acc.: 62.50%] [G loss: 0.852818]\n",
            "2920 [D loss: 0.598285, acc.: 62.50%] [G loss: 0.851961]\n",
            "2921 [D loss: 0.597620, acc.: 62.50%] [G loss: 0.853429]\n",
            "2922 [D loss: 0.598622, acc.: 62.50%] [G loss: 0.853497]\n",
            "2923 [D loss: 0.597726, acc.: 62.50%] [G loss: 0.855953]\n",
            "2924 [D loss: 0.596059, acc.: 62.50%] [G loss: 0.853492]\n",
            "2925 [D loss: 0.595132, acc.: 62.50%] [G loss: 0.856403]\n",
            "2926 [D loss: 0.597009, acc.: 62.50%] [G loss: 0.871729]\n",
            "2927 [D loss: 0.591816, acc.: 62.50%] [G loss: 0.865521]\n",
            "2928 [D loss: 0.593493, acc.: 62.50%] [G loss: 0.877188]\n",
            "2929 [D loss: 0.593850, acc.: 62.50%] [G loss: 0.858606]\n",
            "2930 [D loss: 0.599246, acc.: 62.50%] [G loss: 0.891185]\n",
            "2931 [D loss: 0.603283, acc.: 62.50%] [G loss: 0.851055]\n",
            "2932 [D loss: 0.603587, acc.: 62.50%] [G loss: 0.854483]\n",
            "2933 [D loss: 0.597948, acc.: 62.50%] [G loss: 0.855111]\n",
            "2934 [D loss: 0.597602, acc.: 62.50%] [G loss: 0.851172]\n",
            "2935 [D loss: 0.595387, acc.: 62.50%] [G loss: 0.852279]\n",
            "2936 [D loss: 0.595255, acc.: 62.50%] [G loss: 0.852460]\n",
            "2937 [D loss: 0.595915, acc.: 62.50%] [G loss: 0.850273]\n",
            "2938 [D loss: 0.596251, acc.: 62.50%] [G loss: 0.855894]\n",
            "2939 [D loss: 0.594718, acc.: 64.06%] [G loss: 0.857543]\n",
            "2940 [D loss: 0.591447, acc.: 64.06%] [G loss: 0.850249]\n",
            "2941 [D loss: 0.598879, acc.: 62.50%] [G loss: 0.848271]\n",
            "2942 [D loss: 0.592572, acc.: 65.62%] [G loss: 0.850282]\n",
            "2943 [D loss: 0.591116, acc.: 64.06%] [G loss: 0.851643]\n",
            "2944 [D loss: 0.589901, acc.: 65.62%] [G loss: 0.850041]\n",
            "2945 [D loss: 0.592726, acc.: 64.06%] [G loss: 0.842833]\n",
            "2946 [D loss: 0.587048, acc.: 65.62%] [G loss: 0.808337]\n",
            "2947 [D loss: 0.612574, acc.: 62.50%] [G loss: 0.806227]\n",
            "2948 [D loss: 0.589196, acc.: 62.50%] [G loss: 0.794806]\n",
            "2949 [D loss: 0.615486, acc.: 60.94%] [G loss: 0.836554]\n",
            "2950 [D loss: 0.606614, acc.: 59.38%] [G loss: 0.845778]\n",
            "2951 [D loss: 0.598649, acc.: 62.50%] [G loss: 0.851757]\n",
            "2952 [D loss: 0.604584, acc.: 60.94%] [G loss: 0.841493]\n",
            "2953 [D loss: 0.604408, acc.: 62.50%] [G loss: 0.852472]\n",
            "2954 [D loss: 0.596430, acc.: 62.50%] [G loss: 0.854705]\n",
            "2955 [D loss: 0.598047, acc.: 62.50%] [G loss: 0.853725]\n",
            "2956 [D loss: 0.597131, acc.: 62.50%] [G loss: 0.856942]\n",
            "2957 [D loss: 0.592387, acc.: 62.50%] [G loss: 0.864248]\n",
            "2958 [D loss: 0.595894, acc.: 62.50%] [G loss: 0.856141]\n",
            "2959 [D loss: 0.594296, acc.: 62.50%] [G loss: 0.848661]\n",
            "2960 [D loss: 0.595274, acc.: 62.50%] [G loss: 0.850137]\n",
            "2961 [D loss: 0.594022, acc.: 62.50%] [G loss: 0.861602]\n",
            "2962 [D loss: 0.597166, acc.: 62.50%] [G loss: 0.863145]\n",
            "2963 [D loss: 0.596539, acc.: 62.50%] [G loss: 0.849439]\n",
            "2964 [D loss: 0.596869, acc.: 65.62%] [G loss: 0.847972]\n",
            "2965 [D loss: 0.603769, acc.: 59.38%] [G loss: 0.849053]\n",
            "2966 [D loss: 0.599059, acc.: 62.50%] [G loss: 0.842329]\n",
            "2967 [D loss: 0.600388, acc.: 60.94%] [G loss: 0.856815]\n",
            "2968 [D loss: 0.596381, acc.: 62.50%] [G loss: 0.852025]\n",
            "2969 [D loss: 0.598667, acc.: 62.50%] [G loss: 0.857212]\n",
            "2970 [D loss: 0.598811, acc.: 62.50%] [G loss: 0.848931]\n",
            "2971 [D loss: 0.597661, acc.: 62.50%] [G loss: 0.847910]\n",
            "2972 [D loss: 0.598021, acc.: 62.50%] [G loss: 0.853154]\n",
            "2973 [D loss: 0.596823, acc.: 62.50%] [G loss: 0.851607]\n",
            "2974 [D loss: 0.598059, acc.: 62.50%] [G loss: 0.853534]\n",
            "2975 [D loss: 0.598560, acc.: 62.50%] [G loss: 0.849092]\n",
            "2976 [D loss: 0.597033, acc.: 62.50%] [G loss: 0.851779]\n",
            "2977 [D loss: 0.597025, acc.: 62.50%] [G loss: 0.852332]\n",
            "2978 [D loss: 0.598927, acc.: 62.50%] [G loss: 0.852230]\n",
            "2979 [D loss: 0.599432, acc.: 62.50%] [G loss: 0.851578]\n",
            "2980 [D loss: 0.597752, acc.: 62.50%] [G loss: 0.847478]\n",
            "2981 [D loss: 0.599484, acc.: 62.50%] [G loss: 0.852343]\n",
            "2982 [D loss: 0.595952, acc.: 62.50%] [G loss: 0.852453]\n",
            "2983 [D loss: 0.597693, acc.: 62.50%] [G loss: 0.852341]\n",
            "2984 [D loss: 0.598865, acc.: 62.50%] [G loss: 0.855656]\n",
            "2985 [D loss: 0.598487, acc.: 62.50%] [G loss: 0.851995]\n",
            "2986 [D loss: 0.598706, acc.: 62.50%] [G loss: 0.854015]\n",
            "2987 [D loss: 0.598629, acc.: 62.50%] [G loss: 0.854508]\n",
            "2988 [D loss: 0.597653, acc.: 62.50%] [G loss: 0.854302]\n",
            "2989 [D loss: 0.596448, acc.: 62.50%] [G loss: 0.852575]\n",
            "2990 [D loss: 0.596941, acc.: 62.50%] [G loss: 0.851516]\n",
            "2991 [D loss: 0.597874, acc.: 62.50%] [G loss: 0.853042]\n",
            "2992 [D loss: 0.596188, acc.: 62.50%] [G loss: 0.850761]\n",
            "2993 [D loss: 0.598833, acc.: 62.50%] [G loss: 0.855133]\n",
            "2994 [D loss: 0.596561, acc.: 62.50%] [G loss: 0.855293]\n",
            "2995 [D loss: 0.596709, acc.: 62.50%] [G loss: 0.856075]\n",
            "2996 [D loss: 0.597610, acc.: 62.50%] [G loss: 0.856671]\n",
            "2997 [D loss: 0.597603, acc.: 62.50%] [G loss: 0.856564]\n",
            "2998 [D loss: 0.597039, acc.: 62.50%] [G loss: 0.853852]\n",
            "2999 [D loss: 0.597346, acc.: 62.50%] [G loss: 0.855025]\n",
            "3000 [D loss: 0.598457, acc.: 62.50%] [G loss: 0.853246]\n",
            "generated_data\n",
            "3001 [D loss: 0.598870, acc.: 62.50%] [G loss: 0.849523]\n",
            "3002 [D loss: 0.597720, acc.: 62.50%] [G loss: 0.850985]\n",
            "3003 [D loss: 0.596764, acc.: 62.50%] [G loss: 0.854633]\n",
            "3004 [D loss: 0.598182, acc.: 62.50%] [G loss: 0.852927]\n",
            "3005 [D loss: 0.595919, acc.: 62.50%] [G loss: 0.855054]\n",
            "3006 [D loss: 0.596730, acc.: 62.50%] [G loss: 0.854677]\n",
            "3007 [D loss: 0.597870, acc.: 62.50%] [G loss: 0.858471]\n",
            "3008 [D loss: 0.597093, acc.: 62.50%] [G loss: 0.860529]\n",
            "3009 [D loss: 0.599228, acc.: 62.50%] [G loss: 0.853284]\n",
            "3010 [D loss: 0.596908, acc.: 62.50%] [G loss: 0.858816]\n",
            "3011 [D loss: 0.597195, acc.: 62.50%] [G loss: 0.855804]\n",
            "3012 [D loss: 0.598005, acc.: 62.50%] [G loss: 0.853928]\n",
            "3013 [D loss: 0.597042, acc.: 62.50%] [G loss: 0.856384]\n",
            "3014 [D loss: 0.598650, acc.: 62.50%] [G loss: 0.854530]\n",
            "3015 [D loss: 0.598048, acc.: 62.50%] [G loss: 0.857846]\n",
            "3016 [D loss: 0.596590, acc.: 62.50%] [G loss: 0.861552]\n",
            "3017 [D loss: 0.594760, acc.: 62.50%] [G loss: 0.864758]\n",
            "3018 [D loss: 0.602932, acc.: 62.50%] [G loss: 0.852867]\n",
            "3019 [D loss: 0.596921, acc.: 62.50%] [G loss: 0.861855]\n",
            "3020 [D loss: 0.596401, acc.: 62.50%] [G loss: 0.857366]\n",
            "3021 [D loss: 0.598621, acc.: 62.50%] [G loss: 0.853669]\n",
            "3022 [D loss: 0.599170, acc.: 62.50%] [G loss: 0.855216]\n",
            "3023 [D loss: 0.598945, acc.: 62.50%] [G loss: 0.854662]\n",
            "3024 [D loss: 0.598962, acc.: 62.50%] [G loss: 0.849946]\n",
            "3025 [D loss: 0.598884, acc.: 62.50%] [G loss: 0.856804]\n",
            "3026 [D loss: 0.597103, acc.: 62.50%] [G loss: 0.855147]\n",
            "3027 [D loss: 0.596863, acc.: 62.50%] [G loss: 0.857068]\n",
            "3028 [D loss: 0.597412, acc.: 62.50%] [G loss: 0.854158]\n",
            "3029 [D loss: 0.598381, acc.: 62.50%] [G loss: 0.852448]\n",
            "3030 [D loss: 0.598388, acc.: 62.50%] [G loss: 0.851882]\n",
            "3031 [D loss: 0.596845, acc.: 62.50%] [G loss: 0.853490]\n",
            "3032 [D loss: 0.598903, acc.: 62.50%] [G loss: 0.851099]\n",
            "3033 [D loss: 0.597806, acc.: 62.50%] [G loss: 0.859152]\n",
            "3034 [D loss: 0.598143, acc.: 62.50%] [G loss: 0.852110]\n",
            "3035 [D loss: 0.595859, acc.: 62.50%] [G loss: 0.852548]\n",
            "3036 [D loss: 0.597914, acc.: 62.50%] [G loss: 0.850382]\n",
            "3037 [D loss: 0.600570, acc.: 62.50%] [G loss: 0.848219]\n",
            "3038 [D loss: 0.599931, acc.: 62.50%] [G loss: 0.844833]\n",
            "3039 [D loss: 0.596658, acc.: 62.50%] [G loss: 0.846523]\n",
            "3040 [D loss: 0.594951, acc.: 62.50%] [G loss: 0.846476]\n",
            "3041 [D loss: 0.596388, acc.: 62.50%] [G loss: 0.850399]\n",
            "3042 [D loss: 0.595132, acc.: 62.50%] [G loss: 0.852559]\n",
            "3043 [D loss: 0.597074, acc.: 62.50%] [G loss: 0.849073]\n",
            "3044 [D loss: 0.598124, acc.: 62.50%] [G loss: 0.847580]\n",
            "3045 [D loss: 0.597079, acc.: 62.50%] [G loss: 0.844718]\n",
            "3046 [D loss: 0.598520, acc.: 62.50%] [G loss: 0.844532]\n",
            "3047 [D loss: 0.598291, acc.: 62.50%] [G loss: 0.842798]\n",
            "3048 [D loss: 0.597126, acc.: 62.50%] [G loss: 0.837570]\n",
            "3049 [D loss: 0.596917, acc.: 62.50%] [G loss: 0.841233]\n",
            "3050 [D loss: 0.597691, acc.: 62.50%] [G loss: 0.832450]\n",
            "3051 [D loss: 0.599470, acc.: 62.50%] [G loss: 0.839397]\n",
            "3052 [D loss: 0.599234, acc.: 62.50%] [G loss: 0.845307]\n",
            "3053 [D loss: 0.597733, acc.: 62.50%] [G loss: 0.847348]\n",
            "3054 [D loss: 0.597862, acc.: 62.50%] [G loss: 0.849561]\n",
            "3055 [D loss: 0.597527, acc.: 62.50%] [G loss: 0.844592]\n",
            "3056 [D loss: 0.596250, acc.: 62.50%] [G loss: 0.850284]\n",
            "3057 [D loss: 0.598874, acc.: 62.50%] [G loss: 0.850999]\n",
            "3058 [D loss: 0.598656, acc.: 62.50%] [G loss: 0.846427]\n",
            "3059 [D loss: 0.598909, acc.: 62.50%] [G loss: 0.847970]\n",
            "3060 [D loss: 0.598651, acc.: 62.50%] [G loss: 0.850362]\n",
            "3061 [D loss: 0.598815, acc.: 62.50%] [G loss: 0.849029]\n",
            "3062 [D loss: 0.597666, acc.: 62.50%] [G loss: 0.849551]\n",
            "3063 [D loss: 0.597632, acc.: 62.50%] [G loss: 0.850314]\n",
            "3064 [D loss: 0.596824, acc.: 62.50%] [G loss: 0.847746]\n",
            "3065 [D loss: 0.597593, acc.: 62.50%] [G loss: 0.851495]\n",
            "3066 [D loss: 0.597233, acc.: 62.50%] [G loss: 0.848462]\n",
            "3067 [D loss: 0.597574, acc.: 62.50%] [G loss: 0.852338]\n",
            "3068 [D loss: 0.596266, acc.: 62.50%] [G loss: 0.851057]\n",
            "3069 [D loss: 0.598885, acc.: 62.50%] [G loss: 0.847720]\n",
            "3070 [D loss: 0.595277, acc.: 62.50%] [G loss: 0.852482]\n",
            "3071 [D loss: 0.594946, acc.: 62.50%] [G loss: 0.854733]\n",
            "3072 [D loss: 0.597745, acc.: 62.50%] [G loss: 0.850395]\n",
            "3073 [D loss: 0.598560, acc.: 62.50%] [G loss: 0.848234]\n",
            "3074 [D loss: 0.597743, acc.: 62.50%] [G loss: 0.848980]\n",
            "3075 [D loss: 0.596879, acc.: 62.50%] [G loss: 0.851986]\n",
            "3076 [D loss: 0.595080, acc.: 62.50%] [G loss: 0.930374]\n",
            "3077 [D loss: 0.622989, acc.: 62.50%] [G loss: 0.846100]\n",
            "3078 [D loss: 0.597781, acc.: 62.50%] [G loss: 0.844778]\n",
            "3079 [D loss: 0.599556, acc.: 62.50%] [G loss: 0.854540]\n",
            "3080 [D loss: 0.595558, acc.: 62.50%] [G loss: 0.855918]\n",
            "3081 [D loss: 0.596801, acc.: 62.50%] [G loss: 0.859110]\n",
            "3082 [D loss: 0.597148, acc.: 62.50%] [G loss: 0.881950]\n",
            "3083 [D loss: 0.601135, acc.: 62.50%] [G loss: 0.860937]\n",
            "3084 [D loss: 0.598784, acc.: 62.50%] [G loss: 0.864271]\n",
            "3085 [D loss: 0.600921, acc.: 62.50%] [G loss: 0.859774]\n",
            "3086 [D loss: 0.600482, acc.: 62.50%] [G loss: 0.850340]\n",
            "3087 [D loss: 0.597618, acc.: 62.50%] [G loss: 0.849925]\n",
            "3088 [D loss: 0.598248, acc.: 62.50%] [G loss: 0.851547]\n",
            "3089 [D loss: 0.598154, acc.: 62.50%] [G loss: 0.851925]\n",
            "3090 [D loss: 0.597351, acc.: 62.50%] [G loss: 0.849888]\n",
            "3091 [D loss: 0.596954, acc.: 62.50%] [G loss: 0.849365]\n",
            "3092 [D loss: 0.597575, acc.: 62.50%] [G loss: 0.848356]\n",
            "3093 [D loss: 0.596446, acc.: 62.50%] [G loss: 0.849791]\n",
            "3094 [D loss: 0.595963, acc.: 62.50%] [G loss: 0.848496]\n",
            "3095 [D loss: 0.595309, acc.: 62.50%] [G loss: 0.851188]\n",
            "3096 [D loss: 0.595088, acc.: 62.50%] [G loss: 0.849191]\n",
            "3097 [D loss: 0.596226, acc.: 62.50%] [G loss: 0.850609]\n",
            "3098 [D loss: 0.595171, acc.: 62.50%] [G loss: 0.849922]\n",
            "3099 [D loss: 0.596661, acc.: 62.50%] [G loss: 0.851053]\n",
            "3100 [D loss: 0.594279, acc.: 62.50%] [G loss: 0.848807]\n",
            "generated_data\n",
            "3101 [D loss: 0.594040, acc.: 62.50%] [G loss: 0.848769]\n",
            "3102 [D loss: 0.593514, acc.: 62.50%] [G loss: 0.849364]\n",
            "3103 [D loss: 0.593243, acc.: 62.50%] [G loss: 0.849175]\n",
            "3104 [D loss: 0.597775, acc.: 60.94%] [G loss: 0.847661]\n",
            "3105 [D loss: 0.592561, acc.: 62.50%] [G loss: 0.851168]\n",
            "3106 [D loss: 0.592527, acc.: 64.06%] [G loss: 0.849072]\n",
            "3107 [D loss: 0.592900, acc.: 62.50%] [G loss: 0.849292]\n",
            "3108 [D loss: 0.593424, acc.: 64.06%] [G loss: 0.848110]\n",
            "3109 [D loss: 0.597086, acc.: 64.06%] [G loss: 0.846431]\n",
            "3110 [D loss: 0.589642, acc.: 65.62%] [G loss: 0.837849]\n",
            "3111 [D loss: 0.591952, acc.: 65.62%] [G loss: 0.848843]\n",
            "3112 [D loss: 0.589525, acc.: 64.06%] [G loss: 0.847874]\n",
            "3113 [D loss: 0.587728, acc.: 65.62%] [G loss: 0.841978]\n",
            "3114 [D loss: 0.600066, acc.: 60.94%] [G loss: 0.844623]\n",
            "3115 [D loss: 0.589030, acc.: 65.62%] [G loss: 0.821043]\n",
            "3116 [D loss: 0.601610, acc.: 60.94%] [G loss: 0.850605]\n",
            "3117 [D loss: 0.601441, acc.: 60.94%] [G loss: 0.826186]\n",
            "3118 [D loss: 0.578554, acc.: 67.19%] [G loss: 0.824044]\n",
            "3119 [D loss: 0.596310, acc.: 64.06%] [G loss: 0.822520]\n",
            "3120 [D loss: 0.604566, acc.: 60.94%] [G loss: 0.832893]\n",
            "3121 [D loss: 0.615425, acc.: 56.25%] [G loss: 0.800071]\n",
            "3122 [D loss: 0.607840, acc.: 57.81%] [G loss: 0.814075]\n",
            "3123 [D loss: 0.611047, acc.: 57.81%] [G loss: 0.833343]\n",
            "3124 [D loss: 0.609283, acc.: 57.81%] [G loss: 0.833950]\n",
            "3125 [D loss: 0.605790, acc.: 59.38%] [G loss: 0.835184]\n",
            "3126 [D loss: 0.595633, acc.: 62.50%] [G loss: 0.850691]\n",
            "3127 [D loss: 0.594771, acc.: 62.50%] [G loss: 0.838727]\n",
            "3128 [D loss: 0.597397, acc.: 62.50%] [G loss: 0.850669]\n",
            "3129 [D loss: 0.598163, acc.: 62.50%] [G loss: 0.850856]\n",
            "3130 [D loss: 0.595345, acc.: 62.50%] [G loss: 0.888898]\n",
            "3131 [D loss: 0.591934, acc.: 64.06%] [G loss: 0.867193]\n",
            "3132 [D loss: 0.599156, acc.: 62.50%] [G loss: 0.879426]\n",
            "3133 [D loss: 0.596759, acc.: 64.06%] [G loss: 0.853652]\n",
            "3134 [D loss: 0.597065, acc.: 64.06%] [G loss: 0.852637]\n",
            "3135 [D loss: 0.599747, acc.: 62.50%] [G loss: 0.851815]\n",
            "3136 [D loss: 0.596675, acc.: 64.06%] [G loss: 0.852502]\n",
            "3137 [D loss: 0.596347, acc.: 62.50%] [G loss: 0.844702]\n",
            "3138 [D loss: 0.604254, acc.: 60.94%] [G loss: 0.849368]\n",
            "3139 [D loss: 0.598417, acc.: 62.50%] [G loss: 0.849948]\n",
            "3140 [D loss: 0.596809, acc.: 62.50%] [G loss: 0.845191]\n",
            "3141 [D loss: 0.599525, acc.: 62.50%] [G loss: 0.851296]\n",
            "3142 [D loss: 0.595977, acc.: 62.50%] [G loss: 0.858020]\n",
            "3143 [D loss: 0.594633, acc.: 62.50%] [G loss: 0.854479]\n",
            "3144 [D loss: 0.592487, acc.: 62.50%] [G loss: 0.917788]\n",
            "3145 [D loss: 0.599608, acc.: 62.50%] [G loss: 0.851762]\n",
            "3146 [D loss: 0.598520, acc.: 62.50%] [G loss: 0.851103]\n",
            "3147 [D loss: 0.595521, acc.: 62.50%] [G loss: 0.849279]\n",
            "3148 [D loss: 0.597025, acc.: 62.50%] [G loss: 0.842601]\n",
            "3149 [D loss: 0.597021, acc.: 62.50%] [G loss: 0.847087]\n",
            "3150 [D loss: 0.601873, acc.: 62.50%] [G loss: 0.850986]\n",
            "3151 [D loss: 0.594056, acc.: 62.50%] [G loss: 0.849765]\n",
            "3152 [D loss: 0.597514, acc.: 62.50%] [G loss: 0.850838]\n",
            "3153 [D loss: 0.596054, acc.: 62.50%] [G loss: 0.850766]\n",
            "3154 [D loss: 0.596659, acc.: 62.50%] [G loss: 0.851277]\n",
            "3155 [D loss: 0.596032, acc.: 62.50%] [G loss: 0.851666]\n",
            "3156 [D loss: 0.596078, acc.: 62.50%] [G loss: 0.847325]\n",
            "3157 [D loss: 0.597201, acc.: 62.50%] [G loss: 0.846419]\n",
            "3158 [D loss: 0.595206, acc.: 62.50%] [G loss: 0.850958]\n",
            "3159 [D loss: 0.599198, acc.: 62.50%] [G loss: 0.830939]\n",
            "3160 [D loss: 0.597792, acc.: 62.50%] [G loss: 0.838283]\n",
            "3161 [D loss: 0.599871, acc.: 60.94%] [G loss: 0.844757]\n",
            "3162 [D loss: 0.595628, acc.: 62.50%] [G loss: 0.840755]\n",
            "3163 [D loss: 0.603611, acc.: 62.50%] [G loss: 0.847179]\n",
            "3164 [D loss: 0.601504, acc.: 62.50%] [G loss: 0.851783]\n",
            "3165 [D loss: 0.599214, acc.: 62.50%] [G loss: 0.850311]\n",
            "3166 [D loss: 0.598083, acc.: 62.50%] [G loss: 0.852373]\n",
            "3167 [D loss: 0.597603, acc.: 62.50%] [G loss: 0.883312]\n",
            "3168 [D loss: 0.598229, acc.: 62.50%] [G loss: 0.859107]\n",
            "3169 [D loss: 0.599081, acc.: 62.50%] [G loss: 0.855561]\n",
            "3170 [D loss: 0.598329, acc.: 62.50%] [G loss: 0.851721]\n",
            "3171 [D loss: 0.599101, acc.: 62.50%] [G loss: 0.850488]\n",
            "3172 [D loss: 0.597548, acc.: 62.50%] [G loss: 0.850646]\n",
            "3173 [D loss: 0.599282, acc.: 62.50%] [G loss: 0.850149]\n",
            "3174 [D loss: 0.597365, acc.: 62.50%] [G loss: 0.850565]\n",
            "3175 [D loss: 0.598049, acc.: 62.50%] [G loss: 0.851044]\n",
            "3176 [D loss: 0.597504, acc.: 62.50%] [G loss: 0.851050]\n",
            "3177 [D loss: 0.598081, acc.: 62.50%] [G loss: 0.850271]\n",
            "3178 [D loss: 0.598680, acc.: 62.50%] [G loss: 0.850298]\n",
            "3179 [D loss: 0.598091, acc.: 62.50%] [G loss: 0.850034]\n",
            "3180 [D loss: 0.598072, acc.: 62.50%] [G loss: 0.851274]\n",
            "3181 [D loss: 0.598060, acc.: 62.50%] [G loss: 0.850343]\n",
            "3182 [D loss: 0.598713, acc.: 62.50%] [G loss: 0.853180]\n",
            "3183 [D loss: 0.597976, acc.: 62.50%] [G loss: 0.852069]\n",
            "3184 [D loss: 0.597998, acc.: 62.50%] [G loss: 0.850566]\n",
            "3185 [D loss: 0.597629, acc.: 62.50%] [G loss: 0.851034]\n",
            "3186 [D loss: 0.597459, acc.: 62.50%] [G loss: 0.850945]\n",
            "3187 [D loss: 0.597876, acc.: 62.50%] [G loss: 0.850932]\n",
            "3188 [D loss: 0.597463, acc.: 62.50%] [G loss: 0.851358]\n",
            "3189 [D loss: 0.597864, acc.: 62.50%] [G loss: 0.850931]\n",
            "3190 [D loss: 0.597561, acc.: 62.50%] [G loss: 0.850931]\n",
            "3191 [D loss: 0.597029, acc.: 62.50%] [G loss: 0.850961]\n",
            "3192 [D loss: 0.597798, acc.: 62.50%] [G loss: 0.850733]\n",
            "3193 [D loss: 0.598064, acc.: 62.50%] [G loss: 0.850587]\n",
            "3194 [D loss: 0.597547, acc.: 62.50%] [G loss: 0.850564]\n",
            "3195 [D loss: 0.597386, acc.: 62.50%] [G loss: 0.850924]\n",
            "3196 [D loss: 0.597359, acc.: 62.50%] [G loss: 0.850520]\n",
            "3197 [D loss: 0.598099, acc.: 62.50%] [G loss: 0.851008]\n",
            "3198 [D loss: 0.596607, acc.: 62.50%] [G loss: 0.851136]\n",
            "3199 [D loss: 0.597795, acc.: 62.50%] [G loss: 0.851062]\n",
            "3200 [D loss: 0.598223, acc.: 62.50%] [G loss: 0.848407]\n",
            "generated_data\n",
            "3201 [D loss: 0.597495, acc.: 62.50%] [G loss: 0.849232]\n",
            "3202 [D loss: 0.597240, acc.: 62.50%] [G loss: 0.849525]\n",
            "3203 [D loss: 0.597218, acc.: 62.50%] [G loss: 0.850824]\n",
            "3204 [D loss: 0.596253, acc.: 62.50%] [G loss: 0.848976]\n",
            "3205 [D loss: 0.597519, acc.: 62.50%] [G loss: 0.843267]\n",
            "3206 [D loss: 0.597050, acc.: 62.50%] [G loss: 0.846746]\n",
            "3207 [D loss: 0.600138, acc.: 62.50%] [G loss: 0.845769]\n",
            "3208 [D loss: 0.595298, acc.: 64.06%] [G loss: 0.848379]\n",
            "3209 [D loss: 0.595658, acc.: 62.50%] [G loss: 0.850269]\n",
            "3210 [D loss: 0.594579, acc.: 64.06%] [G loss: 0.849588]\n",
            "3211 [D loss: 0.594994, acc.: 64.06%] [G loss: 0.854575]\n",
            "3212 [D loss: 0.592784, acc.: 64.06%] [G loss: 0.853572]\n",
            "3213 [D loss: 0.592178, acc.: 64.06%] [G loss: 0.857292]\n",
            "3214 [D loss: 0.594253, acc.: 62.50%] [G loss: 0.844892]\n",
            "3215 [D loss: 0.606174, acc.: 62.50%] [G loss: 0.842337]\n",
            "3216 [D loss: 0.593350, acc.: 65.62%] [G loss: 0.853911]\n",
            "3217 [D loss: 0.589361, acc.: 65.62%] [G loss: 0.851109]\n",
            "3218 [D loss: 0.588861, acc.: 65.62%] [G loss: 0.838139]\n",
            "3219 [D loss: 0.589948, acc.: 65.62%] [G loss: 0.850623]\n",
            "3220 [D loss: 0.594574, acc.: 64.06%] [G loss: 0.836834]\n",
            "3221 [D loss: 0.605563, acc.: 59.38%] [G loss: 0.850717]\n",
            "3222 [D loss: 0.593219, acc.: 64.06%] [G loss: 0.848307]\n",
            "3223 [D loss: 0.595987, acc.: 62.50%] [G loss: 0.831979]\n",
            "3224 [D loss: 0.591911, acc.: 64.06%] [G loss: 0.815385]\n",
            "3225 [D loss: 0.607926, acc.: 59.38%] [G loss: 0.846346]\n",
            "3226 [D loss: 0.598238, acc.: 62.50%] [G loss: 0.839288]\n",
            "3227 [D loss: 0.602311, acc.: 60.94%] [G loss: 0.852675]\n",
            "3228 [D loss: 0.595629, acc.: 62.50%] [G loss: 0.891719]\n",
            "3229 [D loss: 0.578219, acc.: 62.50%] [G loss: 1.060253]\n",
            "3230 [D loss: 0.621106, acc.: 62.50%] [G loss: 0.849377]\n",
            "3231 [D loss: 0.604592, acc.: 59.38%] [G loss: 0.846618]\n",
            "3232 [D loss: 0.599277, acc.: 62.50%] [G loss: 0.850940]\n",
            "3233 [D loss: 0.596980, acc.: 62.50%] [G loss: 0.854397]\n",
            "3234 [D loss: 0.598740, acc.: 62.50%] [G loss: 0.851876]\n",
            "3235 [D loss: 0.598777, acc.: 62.50%] [G loss: 0.852690]\n",
            "3236 [D loss: 0.596930, acc.: 62.50%] [G loss: 0.860644]\n",
            "3237 [D loss: 0.592585, acc.: 62.50%] [G loss: 0.888790]\n",
            "3238 [D loss: 0.592767, acc.: 62.50%] [G loss: 0.945418]\n",
            "3239 [D loss: 0.605780, acc.: 62.50%] [G loss: 0.863522]\n",
            "3240 [D loss: 0.602397, acc.: 62.50%] [G loss: 0.855064]\n",
            "3241 [D loss: 0.599347, acc.: 62.50%] [G loss: 0.851483]\n",
            "3242 [D loss: 0.597936, acc.: 62.50%] [G loss: 0.852848]\n",
            "3243 [D loss: 0.597519, acc.: 62.50%] [G loss: 0.852607]\n",
            "3244 [D loss: 0.597293, acc.: 62.50%] [G loss: 0.856082]\n",
            "3245 [D loss: 0.596275, acc.: 62.50%] [G loss: 0.865299]\n",
            "3246 [D loss: 0.600357, acc.: 62.50%] [G loss: 0.851328]\n",
            "3247 [D loss: 0.597860, acc.: 62.50%] [G loss: 0.851306]\n",
            "3248 [D loss: 0.597859, acc.: 62.50%] [G loss: 0.851288]\n",
            "3249 [D loss: 0.598079, acc.: 62.50%] [G loss: 0.851417]\n",
            "3250 [D loss: 0.597858, acc.: 62.50%] [G loss: 0.851611]\n",
            "3251 [D loss: 0.597742, acc.: 62.50%] [G loss: 0.851552]\n",
            "3252 [D loss: 0.598058, acc.: 62.50%] [G loss: 0.851216]\n",
            "3253 [D loss: 0.597860, acc.: 62.50%] [G loss: 0.851673]\n",
            "3254 [D loss: 0.598252, acc.: 62.50%] [G loss: 0.851797]\n",
            "3255 [D loss: 0.598027, acc.: 62.50%] [G loss: 0.851163]\n",
            "3256 [D loss: 0.597868, acc.: 62.50%] [G loss: 0.851146]\n",
            "3257 [D loss: 0.597858, acc.: 62.50%] [G loss: 0.851129]\n",
            "3258 [D loss: 0.597858, acc.: 62.50%] [G loss: 0.851112]\n",
            "3259 [D loss: 0.597859, acc.: 62.50%] [G loss: 0.851095]\n",
            "3260 [D loss: 0.597859, acc.: 62.50%] [G loss: 0.851078]\n",
            "3261 [D loss: 0.598111, acc.: 62.50%] [G loss: 0.851064]\n",
            "3262 [D loss: 0.597877, acc.: 62.50%] [G loss: 0.851048]\n",
            "3263 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.851031]\n",
            "3264 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.851015]\n",
            "3265 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.850998]\n",
            "3266 [D loss: 0.597858, acc.: 62.50%] [G loss: 0.850982]\n",
            "3267 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.850966]\n",
            "3268 [D loss: 0.597887, acc.: 62.50%] [G loss: 0.850949]\n",
            "3269 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.850933]\n",
            "3270 [D loss: 0.597858, acc.: 62.50%] [G loss: 0.850917]\n",
            "3271 [D loss: 0.597956, acc.: 62.50%] [G loss: 0.850902]\n",
            "3272 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.850887]\n",
            "3273 [D loss: 0.598141, acc.: 62.50%] [G loss: 0.850866]\n",
            "3274 [D loss: 0.597860, acc.: 62.50%] [G loss: 0.850846]\n",
            "3275 [D loss: 0.597703, acc.: 62.50%] [G loss: 0.850827]\n",
            "3276 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.850809]\n",
            "3277 [D loss: 0.597954, acc.: 62.50%] [G loss: 0.851109]\n",
            "3278 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.850773]\n",
            "3279 [D loss: 0.597866, acc.: 62.50%] [G loss: 0.850758]\n",
            "3280 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.850742]\n",
            "3281 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.850727]\n",
            "3282 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.850712]\n",
            "3283 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.850697]\n",
            "3284 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.850682]\n",
            "3285 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.850667]\n",
            "3286 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.850652]\n",
            "3287 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.850638]\n",
            "3288 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.850623]\n",
            "3289 [D loss: 0.597820, acc.: 62.50%] [G loss: 0.850608]\n",
            "3290 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.850594]\n",
            "3291 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.850579]\n",
            "3292 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.850565]\n",
            "3293 [D loss: 0.597979, acc.: 62.50%] [G loss: 0.850552]\n",
            "3294 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.850538]\n",
            "3295 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.850524]\n",
            "3296 [D loss: 0.597784, acc.: 62.50%] [G loss: 0.850661]\n",
            "3297 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.850493]\n",
            "3298 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.850479]\n",
            "3299 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.850465]\n",
            "3300 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.850451]\n",
            "generated_data\n",
            "3301 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.850437]\n",
            "3302 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.850423]\n",
            "3303 [D loss: 0.598080, acc.: 62.50%] [G loss: 0.850415]\n",
            "3304 [D loss: 0.597652, acc.: 62.50%] [G loss: 0.850549]\n",
            "3305 [D loss: 0.597996, acc.: 62.50%] [G loss: 0.850386]\n",
            "3306 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.850367]\n",
            "3307 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.850352]\n",
            "3308 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.850338]\n",
            "3309 [D loss: 0.597954, acc.: 62.50%] [G loss: 0.850323]\n",
            "3310 [D loss: 0.597822, acc.: 62.50%] [G loss: 0.850309]\n",
            "3311 [D loss: 0.597576, acc.: 62.50%] [G loss: 0.850288]\n",
            "3312 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.850269]\n",
            "3313 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.850255]\n",
            "3314 [D loss: 0.597525, acc.: 62.50%] [G loss: 0.850253]\n",
            "3315 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.850243]\n",
            "3316 [D loss: 0.598134, acc.: 62.50%] [G loss: 0.850234]\n",
            "3317 [D loss: 0.597862, acc.: 62.50%] [G loss: 0.850222]\n",
            "3318 [D loss: 0.597807, acc.: 62.50%] [G loss: 0.850210]\n",
            "3319 [D loss: 0.597838, acc.: 62.50%] [G loss: 0.850197]\n",
            "3320 [D loss: 0.597572, acc.: 62.50%] [G loss: 0.849204]\n",
            "3321 [D loss: 0.598806, acc.: 62.50%] [G loss: 0.850173]\n",
            "3322 [D loss: 0.596959, acc.: 62.50%] [G loss: 0.850175]\n",
            "3323 [D loss: 0.598453, acc.: 62.50%] [G loss: 0.850164]\n",
            "3324 [D loss: 0.597245, acc.: 62.50%] [G loss: 0.849099]\n",
            "3325 [D loss: 0.595530, acc.: 62.50%] [G loss: 0.848754]\n",
            "3326 [D loss: 0.598093, acc.: 62.50%] [G loss: 0.848276]\n",
            "3327 [D loss: 0.596859, acc.: 62.50%] [G loss: 0.887070]\n",
            "3328 [D loss: 0.607820, acc.: 62.50%] [G loss: 0.849488]\n",
            "3329 [D loss: 0.595427, acc.: 62.50%] [G loss: 0.849518]\n",
            "3330 [D loss: 0.598217, acc.: 62.50%] [G loss: 0.847867]\n",
            "3331 [D loss: 0.598375, acc.: 62.50%] [G loss: 0.850282]\n",
            "3332 [D loss: 0.598947, acc.: 62.50%] [G loss: 0.840452]\n",
            "3333 [D loss: 0.598885, acc.: 62.50%] [G loss: 0.842285]\n",
            "3334 [D loss: 0.597823, acc.: 62.50%] [G loss: 0.848319]\n",
            "3335 [D loss: 0.597729, acc.: 62.50%] [G loss: 0.849881]\n",
            "3336 [D loss: 0.603085, acc.: 62.50%] [G loss: 0.849152]\n",
            "3337 [D loss: 0.597529, acc.: 62.50%] [G loss: 0.842966]\n",
            "3338 [D loss: 0.599518, acc.: 62.50%] [G loss: 0.843706]\n",
            "3339 [D loss: 0.596867, acc.: 62.50%] [G loss: 0.849358]\n",
            "3340 [D loss: 0.600723, acc.: 62.50%] [G loss: 0.849923]\n",
            "3341 [D loss: 0.597206, acc.: 62.50%] [G loss: 0.848361]\n",
            "3342 [D loss: 0.596565, acc.: 62.50%] [G loss: 0.848106]\n",
            "3343 [D loss: 0.597594, acc.: 62.50%] [G loss: 0.849467]\n",
            "3344 [D loss: 0.597912, acc.: 62.50%] [G loss: 0.850715]\n",
            "3345 [D loss: 0.596169, acc.: 62.50%] [G loss: 0.849944]\n",
            "3346 [D loss: 0.597525, acc.: 62.50%] [G loss: 0.850631]\n",
            "3347 [D loss: 0.597182, acc.: 62.50%] [G loss: 0.857011]\n",
            "3348 [D loss: 0.600111, acc.: 62.50%] [G loss: 0.848674]\n",
            "3349 [D loss: 0.598971, acc.: 62.50%] [G loss: 0.850023]\n",
            "3350 [D loss: 0.599166, acc.: 62.50%] [G loss: 0.851206]\n",
            "3351 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.850069]\n",
            "3352 [D loss: 0.596523, acc.: 62.50%] [G loss: 0.850136]\n",
            "3353 [D loss: 0.596759, acc.: 62.50%] [G loss: 0.850191]\n",
            "3354 [D loss: 0.597762, acc.: 62.50%] [G loss: 0.850220]\n",
            "3355 [D loss: 0.597455, acc.: 62.50%] [G loss: 0.850228]\n",
            "3356 [D loss: 0.597243, acc.: 62.50%] [G loss: 0.849439]\n",
            "3357 [D loss: 0.597376, acc.: 62.50%] [G loss: 0.848499]\n",
            "3358 [D loss: 0.596793, acc.: 62.50%] [G loss: 0.850320]\n",
            "3359 [D loss: 0.596843, acc.: 62.50%] [G loss: 0.848697]\n",
            "3360 [D loss: 0.597660, acc.: 62.50%] [G loss: 0.848386]\n",
            "3361 [D loss: 0.598069, acc.: 62.50%] [G loss: 0.850417]\n",
            "3362 [D loss: 0.597473, acc.: 62.50%] [G loss: 0.850442]\n",
            "3363 [D loss: 0.595922, acc.: 62.50%] [G loss: 0.850501]\n",
            "3364 [D loss: 0.597193, acc.: 62.50%] [G loss: 0.849621]\n",
            "3365 [D loss: 0.596787, acc.: 62.50%] [G loss: 0.850565]\n",
            "3366 [D loss: 0.596512, acc.: 62.50%] [G loss: 0.848833]\n",
            "3367 [D loss: 0.598500, acc.: 62.50%] [G loss: 0.850609]\n",
            "3368 [D loss: 0.597724, acc.: 62.50%] [G loss: 0.850533]\n",
            "3369 [D loss: 0.596791, acc.: 62.50%] [G loss: 0.845658]\n",
            "3370 [D loss: 0.607276, acc.: 62.50%] [G loss: 0.847798]\n",
            "3371 [D loss: 0.597627, acc.: 62.50%] [G loss: 0.845695]\n",
            "3372 [D loss: 0.595582, acc.: 62.50%] [G loss: 0.846791]\n",
            "3373 [D loss: 0.599249, acc.: 62.50%] [G loss: 0.842421]\n",
            "3374 [D loss: 0.596998, acc.: 62.50%] [G loss: 0.848953]\n",
            "3375 [D loss: 0.596563, acc.: 62.50%] [G loss: 0.848178]\n",
            "3376 [D loss: 0.599243, acc.: 62.50%] [G loss: 0.851176]\n",
            "3377 [D loss: 0.596131, acc.: 62.50%] [G loss: 0.837807]\n",
            "3378 [D loss: 0.595766, acc.: 62.50%] [G loss: 0.841319]\n",
            "3379 [D loss: 0.596465, acc.: 62.50%] [G loss: 0.849704]\n",
            "3380 [D loss: 0.601774, acc.: 62.50%] [G loss: 0.844537]\n",
            "3381 [D loss: 0.596702, acc.: 62.50%] [G loss: 0.849560]\n",
            "3382 [D loss: 0.596164, acc.: 62.50%] [G loss: 0.850669]\n",
            "3383 [D loss: 0.597278, acc.: 62.50%] [G loss: 0.848881]\n",
            "3384 [D loss: 0.597585, acc.: 62.50%] [G loss: 0.848432]\n",
            "3385 [D loss: 0.597287, acc.: 62.50%] [G loss: 0.849222]\n",
            "3386 [D loss: 0.598345, acc.: 62.50%] [G loss: 0.847627]\n",
            "3387 [D loss: 0.597368, acc.: 62.50%] [G loss: 0.849115]\n",
            "3388 [D loss: 0.598377, acc.: 62.50%] [G loss: 0.846963]\n",
            "3389 [D loss: 0.599357, acc.: 62.50%] [G loss: 0.848514]\n",
            "3390 [D loss: 0.597334, acc.: 62.50%] [G loss: 0.848087]\n",
            "3391 [D loss: 0.597534, acc.: 62.50%] [G loss: 0.851576]\n",
            "3392 [D loss: 0.596899, acc.: 62.50%] [G loss: 0.850559]\n",
            "3393 [D loss: 0.597863, acc.: 62.50%] [G loss: 0.854112]\n",
            "3394 [D loss: 0.599254, acc.: 62.50%] [G loss: 0.856951]\n",
            "3395 [D loss: 0.598680, acc.: 62.50%] [G loss: 0.849679]\n",
            "3396 [D loss: 0.597551, acc.: 62.50%] [G loss: 0.852206]\n",
            "3397 [D loss: 0.598741, acc.: 62.50%] [G loss: 0.848438]\n",
            "3398 [D loss: 0.598837, acc.: 62.50%] [G loss: 0.849191]\n",
            "3399 [D loss: 0.596765, acc.: 62.50%] [G loss: 0.848104]\n",
            "3400 [D loss: 0.597259, acc.: 62.50%] [G loss: 0.848536]\n",
            "generated_data\n",
            "3401 [D loss: 0.597130, acc.: 62.50%] [G loss: 0.844107]\n",
            "3402 [D loss: 0.597144, acc.: 62.50%] [G loss: 0.849944]\n",
            "3403 [D loss: 0.596234, acc.: 62.50%] [G loss: 0.848353]\n",
            "3404 [D loss: 0.607149, acc.: 62.50%] [G loss: 0.844942]\n",
            "3405 [D loss: 0.597766, acc.: 62.50%] [G loss: 0.867227]\n",
            "3406 [D loss: 0.592589, acc.: 62.50%] [G loss: 0.899080]\n",
            "3407 [D loss: 0.613056, acc.: 62.50%] [G loss: 0.854365]\n",
            "3408 [D loss: 0.606813, acc.: 62.50%] [G loss: 0.839229]\n",
            "3409 [D loss: 0.606676, acc.: 62.50%] [G loss: 0.847124]\n",
            "3410 [D loss: 0.597598, acc.: 62.50%] [G loss: 0.852971]\n",
            "3411 [D loss: 0.598407, acc.: 62.50%] [G loss: 0.851054]\n",
            "3412 [D loss: 0.597205, acc.: 62.50%] [G loss: 0.856631]\n",
            "3413 [D loss: 0.598185, acc.: 62.50%] [G loss: 0.852417]\n",
            "3414 [D loss: 0.600194, acc.: 62.50%] [G loss: 0.854289]\n",
            "3415 [D loss: 0.598540, acc.: 62.50%] [G loss: 0.850567]\n",
            "3416 [D loss: 0.598488, acc.: 62.50%] [G loss: 0.850231]\n",
            "3417 [D loss: 0.597495, acc.: 62.50%] [G loss: 0.850580]\n",
            "3418 [D loss: 0.598029, acc.: 62.50%] [G loss: 0.850712]\n",
            "3419 [D loss: 0.597929, acc.: 62.50%] [G loss: 0.849516]\n",
            "3420 [D loss: 0.598255, acc.: 62.50%] [G loss: 0.848897]\n",
            "3421 [D loss: 0.598535, acc.: 62.50%] [G loss: 0.850403]\n",
            "3422 [D loss: 0.597057, acc.: 62.50%] [G loss: 0.848559]\n",
            "3423 [D loss: 0.596777, acc.: 62.50%] [G loss: 0.849461]\n",
            "3424 [D loss: 0.597181, acc.: 62.50%] [G loss: 0.849961]\n",
            "3425 [D loss: 0.596766, acc.: 62.50%] [G loss: 0.848864]\n",
            "3426 [D loss: 0.595739, acc.: 62.50%] [G loss: 0.847508]\n",
            "3427 [D loss: 0.596423, acc.: 62.50%] [G loss: 0.847532]\n",
            "3428 [D loss: 0.596822, acc.: 62.50%] [G loss: 0.834738]\n",
            "3429 [D loss: 0.600039, acc.: 62.50%] [G loss: 0.837068]\n",
            "3430 [D loss: 0.599149, acc.: 62.50%] [G loss: 0.839664]\n",
            "3431 [D loss: 0.596977, acc.: 62.50%] [G loss: 0.830370]\n",
            "3432 [D loss: 0.595166, acc.: 60.94%] [G loss: 0.821979]\n",
            "3433 [D loss: 0.606631, acc.: 60.94%] [G loss: 0.837645]\n",
            "3434 [D loss: 0.599800, acc.: 60.94%] [G loss: 0.833109]\n",
            "3435 [D loss: 0.601257, acc.: 60.94%] [G loss: 0.844213]\n",
            "3436 [D loss: 0.597224, acc.: 62.50%] [G loss: 0.846087]\n",
            "3437 [D loss: 0.601197, acc.: 62.50%] [G loss: 0.834651]\n",
            "3438 [D loss: 0.602372, acc.: 62.50%] [G loss: 0.848421]\n",
            "3439 [D loss: 0.597594, acc.: 62.50%] [G loss: 0.846875]\n",
            "3440 [D loss: 0.596103, acc.: 62.50%] [G loss: 0.848915]\n",
            "3441 [D loss: 0.597488, acc.: 62.50%] [G loss: 0.850974]\n",
            "3442 [D loss: 0.599096, acc.: 62.50%] [G loss: 0.859988]\n",
            "3443 [D loss: 0.603524, acc.: 62.50%] [G loss: 0.850930]\n",
            "3444 [D loss: 0.596009, acc.: 62.50%] [G loss: 0.843459]\n",
            "3445 [D loss: 0.598312, acc.: 62.50%] [G loss: 0.843795]\n",
            "3446 [D loss: 0.597390, acc.: 62.50%] [G loss: 0.844661]\n",
            "3447 [D loss: 0.595967, acc.: 62.50%] [G loss: 0.843441]\n",
            "3448 [D loss: 0.597595, acc.: 62.50%] [G loss: 0.848028]\n",
            "3449 [D loss: 0.597261, acc.: 62.50%] [G loss: 0.847921]\n",
            "3450 [D loss: 0.600801, acc.: 62.50%] [G loss: 0.848102]\n",
            "3451 [D loss: 0.598298, acc.: 62.50%] [G loss: 0.841808]\n",
            "3452 [D loss: 0.595173, acc.: 62.50%] [G loss: 0.845183]\n",
            "3453 [D loss: 0.597148, acc.: 62.50%] [G loss: 0.846170]\n",
            "3454 [D loss: 0.597740, acc.: 62.50%] [G loss: 0.844235]\n",
            "3455 [D loss: 0.597607, acc.: 62.50%] [G loss: 0.847124]\n",
            "3456 [D loss: 0.595412, acc.: 62.50%] [G loss: 0.845229]\n",
            "3457 [D loss: 0.600342, acc.: 62.50%] [G loss: 0.849550]\n",
            "3458 [D loss: 0.597389, acc.: 62.50%] [G loss: 0.851148]\n",
            "3459 [D loss: 0.596556, acc.: 62.50%] [G loss: 0.853168]\n",
            "3460 [D loss: 0.597520, acc.: 62.50%] [G loss: 0.848961]\n",
            "3461 [D loss: 0.596045, acc.: 62.50%] [G loss: 0.848311]\n",
            "3462 [D loss: 0.597932, acc.: 62.50%] [G loss: 0.848833]\n",
            "3463 [D loss: 0.598035, acc.: 62.50%] [G loss: 0.852682]\n",
            "3464 [D loss: 0.598701, acc.: 62.50%] [G loss: 0.851806]\n",
            "3465 [D loss: 0.597590, acc.: 62.50%] [G loss: 0.848550]\n",
            "3466 [D loss: 0.599914, acc.: 62.50%] [G loss: 0.849104]\n",
            "3467 [D loss: 0.598085, acc.: 62.50%] [G loss: 0.851593]\n",
            "3468 [D loss: 0.598418, acc.: 62.50%] [G loss: 0.849611]\n",
            "3469 [D loss: 0.597142, acc.: 62.50%] [G loss: 0.846555]\n",
            "3470 [D loss: 0.600389, acc.: 62.50%] [G loss: 0.846205]\n",
            "3471 [D loss: 0.603845, acc.: 62.50%] [G loss: 0.848455]\n",
            "3472 [D loss: 0.596894, acc.: 62.50%] [G loss: 0.849806]\n",
            "3473 [D loss: 0.598524, acc.: 62.50%] [G loss: 0.850951]\n",
            "3474 [D loss: 0.597694, acc.: 62.50%] [G loss: 0.852266]\n",
            "3475 [D loss: 0.600804, acc.: 62.50%] [G loss: 0.856966]\n",
            "3476 [D loss: 0.598050, acc.: 62.50%] [G loss: 0.849340]\n",
            "3477 [D loss: 0.598484, acc.: 62.50%] [G loss: 0.851927]\n",
            "3478 [D loss: 0.596790, acc.: 62.50%] [G loss: 0.850439]\n",
            "3479 [D loss: 0.597735, acc.: 62.50%] [G loss: 0.852374]\n",
            "3480 [D loss: 0.597944, acc.: 62.50%] [G loss: 0.850954]\n",
            "3481 [D loss: 0.598506, acc.: 62.50%] [G loss: 0.852331]\n",
            "3482 [D loss: 0.597645, acc.: 62.50%] [G loss: 0.852300]\n",
            "3483 [D loss: 0.597865, acc.: 62.50%] [G loss: 0.852193]\n",
            "3484 [D loss: 0.597740, acc.: 62.50%] [G loss: 0.852254]\n",
            "3485 [D loss: 0.598016, acc.: 62.50%] [G loss: 0.851048]\n",
            "3486 [D loss: 0.597864, acc.: 62.50%] [G loss: 0.852208]\n",
            "3487 [D loss: 0.597136, acc.: 62.50%] [G loss: 0.852222]\n",
            "3488 [D loss: 0.597777, acc.: 62.50%] [G loss: 0.851853]\n",
            "3489 [D loss: 0.597458, acc.: 62.50%] [G loss: 0.853013]\n",
            "3490 [D loss: 0.597905, acc.: 62.50%] [G loss: 0.852201]\n",
            "3491 [D loss: 0.597863, acc.: 62.50%] [G loss: 0.852180]\n",
            "3492 [D loss: 0.597598, acc.: 62.50%] [G loss: 0.852164]\n",
            "3493 [D loss: 0.597863, acc.: 62.50%] [G loss: 0.852144]\n",
            "3494 [D loss: 0.597872, acc.: 62.50%] [G loss: 0.852123]\n",
            "3495 [D loss: 0.597863, acc.: 62.50%] [G loss: 0.852101]\n",
            "3496 [D loss: 0.597320, acc.: 62.50%] [G loss: 0.852102]\n",
            "3497 [D loss: 0.597862, acc.: 62.50%] [G loss: 0.852086]\n",
            "3498 [D loss: 0.597338, acc.: 62.50%] [G loss: 0.852090]\n",
            "3499 [D loss: 0.597956, acc.: 62.50%] [G loss: 0.852075]\n",
            "3500 [D loss: 0.597862, acc.: 62.50%] [G loss: 0.852055]\n",
            "generated_data\n",
            "3501 [D loss: 0.597894, acc.: 62.50%] [G loss: 0.852034]\n",
            "3502 [D loss: 0.597863, acc.: 62.50%] [G loss: 0.852013]\n",
            "3503 [D loss: 0.597848, acc.: 62.50%] [G loss: 0.851998]\n",
            "3504 [D loss: 0.597862, acc.: 62.50%] [G loss: 0.851978]\n",
            "3505 [D loss: 0.596924, acc.: 62.50%] [G loss: 0.852004]\n",
            "3506 [D loss: 0.598226, acc.: 62.50%] [G loss: 0.852027]\n",
            "3507 [D loss: 0.597354, acc.: 62.50%] [G loss: 0.849618]\n",
            "3508 [D loss: 0.596621, acc.: 62.50%] [G loss: 0.850413]\n",
            "3509 [D loss: 0.597707, acc.: 62.50%] [G loss: 0.849542]\n",
            "3510 [D loss: 0.597710, acc.: 62.50%] [G loss: 0.848843]\n",
            "3511 [D loss: 0.598188, acc.: 62.50%] [G loss: 0.846078]\n",
            "3512 [D loss: 0.597708, acc.: 62.50%] [G loss: 0.849091]\n",
            "3513 [D loss: 0.598124, acc.: 62.50%] [G loss: 0.847886]\n",
            "3514 [D loss: 0.599540, acc.: 62.50%] [G loss: 0.853892]\n",
            "3515 [D loss: 0.598463, acc.: 62.50%] [G loss: 0.850841]\n",
            "3516 [D loss: 0.598856, acc.: 62.50%] [G loss: 0.851041]\n",
            "3517 [D loss: 0.598318, acc.: 62.50%] [G loss: 0.849901]\n",
            "3518 [D loss: 0.598541, acc.: 62.50%] [G loss: 0.849930]\n",
            "3519 [D loss: 0.598259, acc.: 62.50%] [G loss: 0.851727]\n",
            "3520 [D loss: 0.598257, acc.: 62.50%] [G loss: 0.850578]\n",
            "3521 [D loss: 0.597693, acc.: 62.50%] [G loss: 0.850820]\n",
            "3522 [D loss: 0.597308, acc.: 62.50%] [G loss: 0.851661]\n",
            "3523 [D loss: 0.598211, acc.: 62.50%] [G loss: 0.851455]\n",
            "3524 [D loss: 0.597833, acc.: 62.50%] [G loss: 0.851896]\n",
            "3525 [D loss: 0.597864, acc.: 62.50%] [G loss: 0.851904]\n",
            "3526 [D loss: 0.598219, acc.: 62.50%] [G loss: 0.851363]\n",
            "3527 [D loss: 0.597003, acc.: 62.50%] [G loss: 0.852264]\n",
            "3528 [D loss: 0.597907, acc.: 62.50%] [G loss: 0.851729]\n",
            "3529 [D loss: 0.597288, acc.: 62.50%] [G loss: 0.851337]\n",
            "3530 [D loss: 0.598263, acc.: 62.50%] [G loss: 0.851456]\n",
            "3531 [D loss: 0.597505, acc.: 62.50%] [G loss: 0.851725]\n",
            "3532 [D loss: 0.597754, acc.: 62.50%] [G loss: 0.851789]\n",
            "3533 [D loss: 0.593404, acc.: 62.50%] [G loss: 1.065284]\n",
            "3534 [D loss: 0.668117, acc.: 62.50%] [G loss: 0.851056]\n",
            "3535 [D loss: 0.597531, acc.: 62.50%] [G loss: 0.850513]\n",
            "3536 [D loss: 0.597545, acc.: 62.50%] [G loss: 0.846277]\n",
            "3537 [D loss: 0.673288, acc.: 32.81%] [G loss: 0.851415]\n",
            "3538 [D loss: 0.600500, acc.: 62.50%] [G loss: 0.848941]\n",
            "3539 [D loss: 0.597946, acc.: 62.50%] [G loss: 0.850662]\n",
            "3540 [D loss: 0.597686, acc.: 62.50%] [G loss: 0.850342]\n",
            "3541 [D loss: 0.598311, acc.: 62.50%] [G loss: 0.851456]\n",
            "3542 [D loss: 0.597899, acc.: 62.50%] [G loss: 0.850628]\n",
            "3543 [D loss: 0.597974, acc.: 62.50%] [G loss: 0.852397]\n",
            "3544 [D loss: 0.597037, acc.: 62.50%] [G loss: 0.851283]\n",
            "3545 [D loss: 0.598280, acc.: 62.50%] [G loss: 0.850885]\n",
            "3546 [D loss: 0.597071, acc.: 62.50%] [G loss: 0.850564]\n",
            "3547 [D loss: 0.597731, acc.: 62.50%] [G loss: 0.850551]\n",
            "3548 [D loss: 0.598591, acc.: 62.50%] [G loss: 0.850577]\n",
            "3549 [D loss: 0.598573, acc.: 62.50%] [G loss: 0.851405]\n",
            "3550 [D loss: 0.597601, acc.: 62.50%] [G loss: 0.850513]\n",
            "3551 [D loss: 0.596640, acc.: 62.50%] [G loss: 0.850497]\n",
            "3552 [D loss: 0.596398, acc.: 62.50%] [G loss: 0.845110]\n",
            "3553 [D loss: 0.620889, acc.: 59.38%] [G loss: 0.852456]\n",
            "3554 [D loss: 0.597238, acc.: 62.50%] [G loss: 0.849375]\n",
            "3555 [D loss: 0.601835, acc.: 62.50%] [G loss: 0.852578]\n",
            "3556 [D loss: 0.597083, acc.: 62.50%] [G loss: 0.850657]\n",
            "3557 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.851667]\n",
            "3558 [D loss: 0.597359, acc.: 62.50%] [G loss: 0.850619]\n",
            "3559 [D loss: 0.599078, acc.: 62.50%] [G loss: 0.852788]\n",
            "3560 [D loss: 0.597876, acc.: 62.50%] [G loss: 0.852045]\n",
            "3561 [D loss: 0.598947, acc.: 62.50%] [G loss: 0.850561]\n",
            "3562 [D loss: 0.599291, acc.: 62.50%] [G loss: 0.850533]\n",
            "3563 [D loss: 0.598727, acc.: 62.50%] [G loss: 0.850515]\n",
            "3564 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.850519]\n",
            "3565 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.851215]\n",
            "3566 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.850471]\n",
            "3567 [D loss: 0.597940, acc.: 62.50%] [G loss: 0.850462]\n",
            "3568 [D loss: 0.598201, acc.: 62.50%] [G loss: 0.850458]\n",
            "3569 [D loss: 0.597966, acc.: 62.50%] [G loss: 0.850450]\n",
            "3570 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.850437]\n",
            "3571 [D loss: 0.598254, acc.: 62.50%] [G loss: 0.850442]\n",
            "3572 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.850390]\n",
            "3573 [D loss: 0.598028, acc.: 62.50%] [G loss: 0.850483]\n",
            "3574 [D loss: 0.597901, acc.: 62.50%] [G loss: 0.850409]\n",
            "3575 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.850395]\n",
            "3576 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.850615]\n",
            "3577 [D loss: 0.597842, acc.: 62.50%] [G loss: 0.850368]\n",
            "3578 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.850355]\n",
            "3579 [D loss: 0.597875, acc.: 62.50%] [G loss: 0.850338]\n",
            "3580 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.850342]\n",
            "3581 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.850310]\n",
            "3582 [D loss: 0.597947, acc.: 62.50%] [G loss: 0.850332]\n",
            "3583 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.850299]\n",
            "3584 [D loss: 0.597863, acc.: 62.50%] [G loss: 0.850285]\n",
            "3585 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.850272]\n",
            "3586 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.850258]\n",
            "3587 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.850245]\n",
            "3588 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.850232]\n",
            "3589 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.850219]\n",
            "3590 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.850205]\n",
            "3591 [D loss: 0.597497, acc.: 62.50%] [G loss: 0.850205]\n",
            "3592 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.850195]\n",
            "3593 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.850183]\n",
            "3594 [D loss: 0.597871, acc.: 62.50%] [G loss: 0.850169]\n",
            "3595 [D loss: 0.597734, acc.: 62.50%] [G loss: 0.850160]\n",
            "3596 [D loss: 0.599179, acc.: 62.50%] [G loss: 0.850148]\n",
            "3597 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.850126]\n",
            "3598 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.850111]\n",
            "3599 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.850098]\n",
            "3600 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.850085]\n",
            "generated_data\n",
            "3601 [D loss: 0.597865, acc.: 62.50%] [G loss: 0.850070]\n",
            "3602 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.850057]\n",
            "3603 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.850044]\n",
            "3604 [D loss: 0.597927, acc.: 62.50%] [G loss: 0.850031]\n",
            "3605 [D loss: 0.597863, acc.: 62.50%] [G loss: 0.850018]\n",
            "3606 [D loss: 0.598023, acc.: 62.50%] [G loss: 0.850000]\n",
            "3607 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.849984]\n",
            "3608 [D loss: 0.597896, acc.: 62.50%] [G loss: 0.849971]\n",
            "3609 [D loss: 0.597990, acc.: 62.50%] [G loss: 0.849958]\n",
            "3610 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.850011]\n",
            "3611 [D loss: 0.597879, acc.: 62.50%] [G loss: 0.849932]\n",
            "3612 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.849918]\n",
            "3613 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.849906]\n",
            "3614 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.849893]\n",
            "3615 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.849881]\n",
            "3616 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.849869]\n",
            "3617 [D loss: 0.597833, acc.: 62.50%] [G loss: 0.849855]\n",
            "3618 [D loss: 0.597653, acc.: 62.50%] [G loss: 0.849841]\n",
            "3619 [D loss: 0.598155, acc.: 62.50%] [G loss: 0.849832]\n",
            "3620 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.849822]\n",
            "3621 [D loss: 0.597860, acc.: 62.50%] [G loss: 0.849810]\n",
            "3622 [D loss: 0.597847, acc.: 62.50%] [G loss: 0.849798]\n",
            "3623 [D loss: 0.597862, acc.: 62.50%] [G loss: 0.849786]\n",
            "3624 [D loss: 0.597861, acc.: 62.50%] [G loss: 0.850175]\n",
            "3625 [D loss: 0.597844, acc.: 62.50%] [G loss: 0.849762]\n",
            "3626 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.849751]\n",
            "3627 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.849740]\n",
            "3628 [D loss: 0.598182, acc.: 62.50%] [G loss: 0.849731]\n",
            "3629 [D loss: 0.597888, acc.: 62.50%] [G loss: 0.849953]\n",
            "3630 [D loss: 0.597823, acc.: 62.50%] [G loss: 0.849711]\n",
            "3631 [D loss: 0.597967, acc.: 62.50%] [G loss: 0.849971]\n",
            "3632 [D loss: 0.597937, acc.: 62.50%] [G loss: 0.849701]\n",
            "3633 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.849691]\n",
            "3634 [D loss: 0.597900, acc.: 62.50%] [G loss: 0.849680]\n",
            "3635 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.849669]\n",
            "3636 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.849658]\n",
            "3637 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.849648]\n",
            "3638 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.849637]\n",
            "3639 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.849626]\n",
            "3640 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.849616]\n",
            "3641 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.849605]\n",
            "3642 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.849595]\n",
            "3643 [D loss: 0.597965, acc.: 62.50%] [G loss: 0.849587]\n",
            "3644 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.849577]\n",
            "3645 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.849567]\n",
            "3646 [D loss: 0.597817, acc.: 62.50%] [G loss: 0.849555]\n",
            "3647 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.849545]\n",
            "3648 [D loss: 0.597705, acc.: 62.50%] [G loss: 0.849536]\n",
            "3649 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.848707]\n",
            "3650 [D loss: 0.597939, acc.: 62.50%] [G loss: 0.849519]\n",
            "3651 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.849509]\n",
            "3652 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.849499]\n",
            "3653 [D loss: 0.597863, acc.: 62.50%] [G loss: 0.849489]\n",
            "3654 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.849479]\n",
            "3655 [D loss: 0.597334, acc.: 62.50%] [G loss: 0.849488]\n",
            "3656 [D loss: 0.597850, acc.: 62.50%] [G loss: 0.849404]\n",
            "3657 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.849474]\n",
            "3658 [D loss: 0.597637, acc.: 62.50%] [G loss: 0.847542]\n",
            "3659 [D loss: 0.598577, acc.: 62.50%] [G loss: 0.846858]\n",
            "3660 [D loss: 0.599046, acc.: 62.50%] [G loss: 0.848350]\n",
            "3661 [D loss: 0.595999, acc.: 62.50%] [G loss: 0.847305]\n",
            "3662 [D loss: 0.599151, acc.: 62.50%] [G loss: 0.850434]\n",
            "3663 [D loss: 0.595819, acc.: 62.50%] [G loss: 0.861492]\n",
            "3664 [D loss: 0.600464, acc.: 62.50%] [G loss: 0.844842]\n",
            "3665 [D loss: 0.597515, acc.: 62.50%] [G loss: 0.848317]\n",
            "3666 [D loss: 0.600978, acc.: 62.50%] [G loss: 0.854392]\n",
            "3667 [D loss: 0.602346, acc.: 62.50%] [G loss: 0.848787]\n",
            "3668 [D loss: 0.600987, acc.: 62.50%] [G loss: 0.845030]\n",
            "3669 [D loss: 0.599550, acc.: 62.50%] [G loss: 0.848836]\n",
            "3670 [D loss: 0.598759, acc.: 62.50%] [G loss: 0.848583]\n",
            "3671 [D loss: 0.597149, acc.: 62.50%] [G loss: 0.848507]\n",
            "3672 [D loss: 0.597774, acc.: 62.50%] [G loss: 0.848872]\n",
            "3673 [D loss: 0.597112, acc.: 62.50%] [G loss: 0.848903]\n",
            "3674 [D loss: 0.597308, acc.: 62.50%] [G loss: 0.848927]\n",
            "3675 [D loss: 0.597474, acc.: 62.50%] [G loss: 0.848939]\n",
            "3676 [D loss: 0.597625, acc.: 62.50%] [G loss: 0.848941]\n",
            "3677 [D loss: 0.597190, acc.: 62.50%] [G loss: 0.848970]\n",
            "3678 [D loss: 0.596740, acc.: 62.50%] [G loss: 0.848236]\n",
            "3679 [D loss: 0.598718, acc.: 62.50%] [G loss: 0.849021]\n",
            "3680 [D loss: 0.597187, acc.: 62.50%] [G loss: 0.849043]\n",
            "3681 [D loss: 0.596552, acc.: 62.50%] [G loss: 0.849079]\n",
            "3682 [D loss: 0.596452, acc.: 62.50%] [G loss: 0.849125]\n",
            "3683 [D loss: 0.597046, acc.: 62.50%] [G loss: 0.849152]\n",
            "3684 [D loss: 0.596307, acc.: 62.50%] [G loss: 0.849198]\n",
            "3685 [D loss: 0.597243, acc.: 62.50%] [G loss: 0.848950]\n",
            "3686 [D loss: 0.596881, acc.: 62.50%] [G loss: 0.847417]\n",
            "3687 [D loss: 0.598368, acc.: 62.50%] [G loss: 0.846097]\n",
            "3688 [D loss: 0.598842, acc.: 62.50%] [G loss: 0.844229]\n",
            "3689 [D loss: 0.600577, acc.: 62.50%] [G loss: 0.847389]\n",
            "3690 [D loss: 0.598822, acc.: 62.50%] [G loss: 0.845739]\n",
            "3691 [D loss: 0.597374, acc.: 62.50%] [G loss: 0.842553]\n",
            "3692 [D loss: 0.597247, acc.: 62.50%] [G loss: 0.859321]\n",
            "3693 [D loss: 0.606861, acc.: 62.50%] [G loss: 0.848320]\n",
            "3694 [D loss: 0.597633, acc.: 62.50%] [G loss: 0.849151]\n",
            "3695 [D loss: 0.597066, acc.: 62.50%] [G loss: 0.847488]\n",
            "3696 [D loss: 0.597864, acc.: 62.50%] [G loss: 0.845911]\n",
            "3697 [D loss: 0.598427, acc.: 62.50%] [G loss: 0.848596]\n",
            "3698 [D loss: 0.598311, acc.: 62.50%] [G loss: 0.849117]\n",
            "3699 [D loss: 0.597892, acc.: 62.50%] [G loss: 0.849101]\n",
            "3700 [D loss: 0.597863, acc.: 62.50%] [G loss: 0.849091]\n",
            "generated_data\n",
            "3701 [D loss: 0.598294, acc.: 62.50%] [G loss: 0.847234]\n",
            "3702 [D loss: 0.597790, acc.: 62.50%] [G loss: 0.848705]\n",
            "3703 [D loss: 0.597838, acc.: 62.50%] [G loss: 0.849046]\n",
            "3704 [D loss: 0.599267, acc.: 62.50%] [G loss: 0.847304]\n",
            "3705 [D loss: 0.598546, acc.: 62.50%] [G loss: 0.845280]\n",
            "3706 [D loss: 0.598573, acc.: 62.50%] [G loss: 0.846747]\n",
            "3707 [D loss: 0.597183, acc.: 62.50%] [G loss: 0.850790]\n",
            "3708 [D loss: 0.597180, acc.: 62.50%] [G loss: 0.859387]\n",
            "3709 [D loss: 0.596510, acc.: 62.50%] [G loss: 0.864102]\n",
            "3710 [D loss: 0.597817, acc.: 62.50%] [G loss: 0.856369]\n",
            "3711 [D loss: 0.595789, acc.: 62.50%] [G loss: 0.849326]\n",
            "3712 [D loss: 0.598963, acc.: 62.50%] [G loss: 0.849513]\n",
            "3713 [D loss: 0.603922, acc.: 62.50%] [G loss: 0.847054]\n",
            "3714 [D loss: 0.597757, acc.: 62.50%] [G loss: 0.846728]\n",
            "3715 [D loss: 0.607338, acc.: 62.50%] [G loss: 0.856491]\n",
            "3716 [D loss: 0.601333, acc.: 62.50%] [G loss: 0.847772]\n",
            "3717 [D loss: 0.599074, acc.: 62.50%] [G loss: 0.847022]\n",
            "3718 [D loss: 0.598166, acc.: 62.50%] [G loss: 0.848135]\n",
            "3719 [D loss: 0.597577, acc.: 62.50%] [G loss: 0.848325]\n",
            "3720 [D loss: 0.598306, acc.: 62.50%] [G loss: 0.848516]\n",
            "3721 [D loss: 0.598168, acc.: 62.50%] [G loss: 0.848846]\n",
            "3722 [D loss: 0.598493, acc.: 62.50%] [G loss: 0.848730]\n",
            "3723 [D loss: 0.597906, acc.: 62.50%] [G loss: 0.848216]\n",
            "3724 [D loss: 0.597490, acc.: 62.50%] [G loss: 0.848467]\n",
            "3725 [D loss: 0.597888, acc.: 62.50%] [G loss: 0.847905]\n",
            "3726 [D loss: 0.597703, acc.: 62.50%] [G loss: 0.846264]\n",
            "3727 [D loss: 0.599305, acc.: 62.50%] [G loss: 0.848079]\n",
            "3728 [D loss: 0.597338, acc.: 62.50%] [G loss: 0.848034]\n",
            "3729 [D loss: 0.596868, acc.: 62.50%] [G loss: 0.847377]\n",
            "3730 [D loss: 0.597552, acc.: 62.50%] [G loss: 0.846330]\n",
            "3731 [D loss: 0.597197, acc.: 62.50%] [G loss: 0.846288]\n",
            "3732 [D loss: 0.596289, acc.: 62.50%] [G loss: 0.844487]\n",
            "3733 [D loss: 0.598479, acc.: 62.50%] [G loss: 0.847372]\n",
            "3734 [D loss: 0.595565, acc.: 62.50%] [G loss: 0.845235]\n",
            "3735 [D loss: 0.601417, acc.: 62.50%] [G loss: 0.845757]\n",
            "3736 [D loss: 0.594754, acc.: 62.50%] [G loss: 0.850290]\n",
            "3737 [D loss: 0.600850, acc.: 60.94%] [G loss: 0.858300]\n",
            "3738 [D loss: 0.596071, acc.: 62.50%] [G loss: 0.846030]\n",
            "3739 [D loss: 0.599489, acc.: 62.50%] [G loss: 0.844117]\n",
            "3740 [D loss: 0.595160, acc.: 64.06%] [G loss: 0.837930]\n",
            "3741 [D loss: 0.597627, acc.: 62.50%] [G loss: 0.831832]\n",
            "3742 [D loss: 0.617825, acc.: 57.81%] [G loss: 0.847699]\n",
            "3743 [D loss: 0.596176, acc.: 62.50%] [G loss: 0.854221]\n",
            "3744 [D loss: 0.597718, acc.: 62.50%] [G loss: 0.855074]\n",
            "3745 [D loss: 0.599610, acc.: 62.50%] [G loss: 0.851318]\n",
            "3746 [D loss: 0.598127, acc.: 62.50%] [G loss: 0.830988]\n",
            "3747 [D loss: 0.601214, acc.: 60.94%] [G loss: 0.827331]\n",
            "3748 [D loss: 0.602196, acc.: 59.38%] [G loss: 0.825961]\n",
            "3749 [D loss: 0.611748, acc.: 59.38%] [G loss: 0.839689]\n",
            "3750 [D loss: 0.600591, acc.: 62.50%] [G loss: 0.845379]\n",
            "3751 [D loss: 0.599287, acc.: 62.50%] [G loss: 0.840921]\n",
            "3752 [D loss: 0.609350, acc.: 62.50%] [G loss: 0.841619]\n",
            "3753 [D loss: 0.595519, acc.: 62.50%] [G loss: 0.845944]\n",
            "3754 [D loss: 0.605449, acc.: 62.50%] [G loss: 0.839915]\n",
            "3755 [D loss: 0.601281, acc.: 62.50%] [G loss: 0.846524]\n",
            "3756 [D loss: 0.597612, acc.: 62.50%] [G loss: 0.844827]\n",
            "3757 [D loss: 0.597185, acc.: 62.50%] [G loss: 0.845879]\n",
            "3758 [D loss: 0.597304, acc.: 62.50%] [G loss: 0.848474]\n",
            "3759 [D loss: 0.597167, acc.: 62.50%] [G loss: 0.846142]\n",
            "3760 [D loss: 0.595646, acc.: 62.50%] [G loss: 0.848599]\n",
            "3761 [D loss: 0.595973, acc.: 62.50%] [G loss: 0.849600]\n",
            "3762 [D loss: 0.599759, acc.: 60.94%] [G loss: 0.849528]\n",
            "3763 [D loss: 0.595758, acc.: 62.50%] [G loss: 0.850161]\n",
            "3764 [D loss: 0.597832, acc.: 62.50%] [G loss: 0.849671]\n",
            "3765 [D loss: 0.597085, acc.: 62.50%] [G loss: 0.847811]\n",
            "3766 [D loss: 0.598549, acc.: 62.50%] [G loss: 0.848704]\n",
            "3767 [D loss: 0.597747, acc.: 62.50%] [G loss: 0.849889]\n",
            "3768 [D loss: 0.597135, acc.: 62.50%] [G loss: 0.849181]\n",
            "3769 [D loss: 0.597863, acc.: 62.50%] [G loss: 0.849143]\n",
            "3770 [D loss: 0.597858, acc.: 62.50%] [G loss: 0.849127]\n",
            "3771 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.849117]\n",
            "3772 [D loss: 0.597819, acc.: 62.50%] [G loss: 0.849101]\n",
            "3773 [D loss: 0.597645, acc.: 62.50%] [G loss: 0.849087]\n",
            "3774 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.849077]\n",
            "3775 [D loss: 0.597381, acc.: 62.50%] [G loss: 0.854871]\n",
            "3776 [D loss: 0.596586, acc.: 62.50%] [G loss: 0.932734]\n",
            "3777 [D loss: 0.634605, acc.: 62.50%] [G loss: 0.849536]\n",
            "3778 [D loss: 0.597922, acc.: 62.50%] [G loss: 0.849162]\n",
            "3779 [D loss: 0.597860, acc.: 62.50%] [G loss: 0.848569]\n",
            "3780 [D loss: 0.596922, acc.: 62.50%] [G loss: 0.893701]\n",
            "3781 [D loss: 0.610127, acc.: 62.50%] [G loss: 0.848596]\n",
            "3782 [D loss: 0.597395, acc.: 62.50%] [G loss: 0.846642]\n",
            "3783 [D loss: 0.599636, acc.: 60.94%] [G loss: 0.844013]\n",
            "3784 [D loss: 0.597918, acc.: 62.50%] [G loss: 0.847269]\n",
            "3785 [D loss: 0.598454, acc.: 62.50%] [G loss: 0.846641]\n",
            "3786 [D loss: 0.597948, acc.: 62.50%] [G loss: 0.840024]\n",
            "3787 [D loss: 0.599919, acc.: 62.50%] [G loss: 0.846374]\n",
            "3788 [D loss: 0.598291, acc.: 62.50%] [G loss: 0.846454]\n",
            "3789 [D loss: 0.597412, acc.: 62.50%] [G loss: 0.848132]\n",
            "3790 [D loss: 0.598348, acc.: 62.50%] [G loss: 0.848522]\n",
            "3791 [D loss: 0.597803, acc.: 62.50%] [G loss: 0.851298]\n",
            "3792 [D loss: 0.598296, acc.: 62.50%] [G loss: 0.849620]\n",
            "3793 [D loss: 0.598236, acc.: 62.50%] [G loss: 0.847973]\n",
            "3794 [D loss: 0.598707, acc.: 62.50%] [G loss: 0.848791]\n",
            "3795 [D loss: 0.596592, acc.: 62.50%] [G loss: 0.850171]\n",
            "3796 [D loss: 0.598080, acc.: 62.50%] [G loss: 0.852567]\n",
            "3797 [D loss: 0.598071, acc.: 62.50%] [G loss: 0.853310]\n",
            "3798 [D loss: 0.597692, acc.: 62.50%] [G loss: 0.855571]\n",
            "3799 [D loss: 0.597427, acc.: 62.50%] [G loss: 0.849904]\n",
            "3800 [D loss: 0.600031, acc.: 62.50%] [G loss: 0.850035]\n",
            "generated_data\n",
            "3801 [D loss: 0.597920, acc.: 62.50%] [G loss: 0.850013]\n",
            "3802 [D loss: 0.597244, acc.: 62.50%] [G loss: 0.854241]\n",
            "3803 [D loss: 0.597679, acc.: 62.50%] [G loss: 0.857226]\n",
            "3804 [D loss: 0.599904, acc.: 62.50%] [G loss: 0.851350]\n",
            "3805 [D loss: 0.603298, acc.: 62.50%] [G loss: 0.847150]\n",
            "3806 [D loss: 0.598079, acc.: 62.50%] [G loss: 0.848529]\n",
            "3807 [D loss: 0.597540, acc.: 62.50%] [G loss: 0.847334]\n",
            "3808 [D loss: 0.597702, acc.: 62.50%] [G loss: 0.848580]\n",
            "3809 [D loss: 0.598804, acc.: 62.50%] [G loss: 0.847901]\n",
            "3810 [D loss: 0.597910, acc.: 62.50%] [G loss: 0.849567]\n",
            "3811 [D loss: 0.597924, acc.: 62.50%] [G loss: 0.845485]\n",
            "3812 [D loss: 0.599219, acc.: 62.50%] [G loss: 0.846975]\n",
            "3813 [D loss: 0.598601, acc.: 62.50%] [G loss: 0.847748]\n",
            "3814 [D loss: 0.596384, acc.: 62.50%] [G loss: 0.847595]\n",
            "3815 [D loss: 0.597447, acc.: 62.50%] [G loss: 0.850860]\n",
            "3816 [D loss: 0.597619, acc.: 62.50%] [G loss: 0.850106]\n",
            "3817 [D loss: 0.598029, acc.: 62.50%] [G loss: 0.848717]\n",
            "3818 [D loss: 0.597778, acc.: 62.50%] [G loss: 0.848421]\n",
            "3819 [D loss: 0.597921, acc.: 62.50%] [G loss: 0.848981]\n",
            "3820 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848414]\n",
            "3821 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.848438]\n",
            "3822 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.848404]\n",
            "3823 [D loss: 0.597835, acc.: 62.50%] [G loss: 0.847758]\n",
            "3824 [D loss: 0.597502, acc.: 62.50%] [G loss: 0.848887]\n",
            "3825 [D loss: 0.598102, acc.: 62.50%] [G loss: 0.849255]\n",
            "3826 [D loss: 0.597847, acc.: 62.50%] [G loss: 0.848727]\n",
            "3827 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848364]\n",
            "3828 [D loss: 0.597711, acc.: 62.50%] [G loss: 0.848378]\n",
            "3829 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848435]\n",
            "3830 [D loss: 0.597986, acc.: 62.50%] [G loss: 0.849605]\n",
            "3831 [D loss: 0.598172, acc.: 62.50%] [G loss: 0.848411]\n",
            "3832 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.849590]\n",
            "3833 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848686]\n",
            "3834 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848389]\n",
            "3835 [D loss: 0.597483, acc.: 62.50%] [G loss: 0.849108]\n",
            "3836 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.850331]\n",
            "3837 [D loss: 0.597677, acc.: 62.50%] [G loss: 0.849961]\n",
            "3838 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.853133]\n",
            "3839 [D loss: 0.599686, acc.: 62.50%] [G loss: 0.848312]\n",
            "3840 [D loss: 0.597844, acc.: 62.50%] [G loss: 0.848305]\n",
            "3841 [D loss: 0.600103, acc.: 62.50%] [G loss: 0.848276]\n",
            "3842 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.848265]\n",
            "3843 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848259]\n",
            "3844 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.848254]\n",
            "3845 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848249]\n",
            "3846 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848244]\n",
            "3847 [D loss: 0.598157, acc.: 62.50%] [G loss: 0.848247]\n",
            "3848 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.850175]\n",
            "3849 [D loss: 0.597786, acc.: 62.50%] [G loss: 0.848240]\n",
            "3850 [D loss: 0.598700, acc.: 62.50%] [G loss: 0.848264]\n",
            "3851 [D loss: 0.598638, acc.: 62.50%] [G loss: 0.848266]\n",
            "3852 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848235]\n",
            "3853 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.848022]\n",
            "3854 [D loss: 0.597893, acc.: 62.50%] [G loss: 0.848225]\n",
            "3855 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848220]\n",
            "3856 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848216]\n",
            "3857 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848211]\n",
            "3858 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848207]\n",
            "3859 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848202]\n",
            "3860 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848198]\n",
            "3861 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848193]\n",
            "3862 [D loss: 0.597874, acc.: 62.50%] [G loss: 0.848188]\n",
            "3863 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848227]\n",
            "3864 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.848248]\n",
            "3865 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848175]\n",
            "3866 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848171]\n",
            "3867 [D loss: 0.597873, acc.: 62.50%] [G loss: 0.848164]\n",
            "3868 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848159]\n",
            "3869 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848155]\n",
            "3870 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848150]\n",
            "3871 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848146]\n",
            "3872 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.848142]\n",
            "3873 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848137]\n",
            "3874 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848133]\n",
            "3875 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848129]\n",
            "3876 [D loss: 0.597895, acc.: 62.50%] [G loss: 0.848126]\n",
            "3877 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848122]\n",
            "3878 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848118]\n",
            "3879 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848114]\n",
            "3880 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848110]\n",
            "3881 [D loss: 0.597789, acc.: 62.50%] [G loss: 0.848105]\n",
            "3882 [D loss: 0.597865, acc.: 62.50%] [G loss: 0.848100]\n",
            "3883 [D loss: 0.597947, acc.: 62.50%] [G loss: 0.848097]\n",
            "3884 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848093]\n",
            "3885 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848089]\n",
            "3886 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.848085]\n",
            "3887 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848081]\n",
            "3888 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848077]\n",
            "3889 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848073]\n",
            "3890 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848069]\n",
            "3891 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848065]\n",
            "3892 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848079]\n",
            "3893 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848058]\n",
            "3894 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848054]\n",
            "3895 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848050]\n",
            "3896 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848046]\n",
            "3897 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848042]\n",
            "3898 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848038]\n",
            "3899 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848035]\n",
            "3900 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848031]\n",
            "generated_data\n",
            "3901 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848027]\n",
            "3902 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848023]\n",
            "3903 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848020]\n",
            "3904 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848016]\n",
            "3905 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848012]\n",
            "3906 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848009]\n",
            "3907 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848005]\n",
            "3908 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848001]\n",
            "3909 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847998]\n",
            "3910 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847994]\n",
            "3911 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847991]\n",
            "3912 [D loss: 0.597947, acc.: 62.50%] [G loss: 0.847988]\n",
            "3913 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848163]\n",
            "3914 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847982]\n",
            "3915 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847978]\n",
            "3916 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847975]\n",
            "3917 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.847971]\n",
            "3918 [D loss: 0.597894, acc.: 62.50%] [G loss: 0.847967]\n",
            "3919 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847964]\n",
            "3920 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847960]\n",
            "3921 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847957]\n",
            "3922 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847954]\n",
            "3923 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847950]\n",
            "3924 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847947]\n",
            "3925 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847943]\n",
            "3926 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847940]\n",
            "3927 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847937]\n",
            "3928 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847933]\n",
            "3929 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847930]\n",
            "3930 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.847926]\n",
            "3931 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847923]\n",
            "3932 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847920]\n",
            "3933 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847917]\n",
            "3934 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847913]\n",
            "3935 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847927]\n",
            "3936 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847908]\n",
            "3937 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847904]\n",
            "3938 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847901]\n",
            "3939 [D loss: 0.597860, acc.: 62.50%] [G loss: 0.847898]\n",
            "3940 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847895]\n",
            "3941 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847891]\n",
            "3942 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847888]\n",
            "3943 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847871]\n",
            "3944 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847882]\n",
            "3945 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847879]\n",
            "3946 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847876]\n",
            "3947 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.847872]\n",
            "3948 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.847869]\n",
            "3949 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847866]\n",
            "3950 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847863]\n",
            "3951 [D loss: 0.597542, acc.: 62.50%] [G loss: 0.847878]\n",
            "3952 [D loss: 0.597850, acc.: 62.50%] [G loss: 0.847880]\n",
            "3953 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847878]\n",
            "3954 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847875]\n",
            "3955 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847872]\n",
            "3956 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847869]\n",
            "3957 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847866]\n",
            "3958 [D loss: 0.597724, acc.: 62.50%] [G loss: 0.847860]\n",
            "3959 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847855]\n",
            "3960 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847851]\n",
            "3961 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847848]\n",
            "3962 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847845]\n",
            "3963 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847842]\n",
            "3964 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847839]\n",
            "3965 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847836]\n",
            "3966 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847833]\n",
            "3967 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847830]\n",
            "3968 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847828]\n",
            "3969 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847825]\n",
            "3970 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847822]\n",
            "3971 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847819]\n",
            "3972 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847816]\n",
            "3973 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847813]\n",
            "3974 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847810]\n",
            "3975 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847807]\n",
            "3976 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847805]\n",
            "3977 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847802]\n",
            "3978 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847799]\n",
            "3979 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847796]\n",
            "3980 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847793]\n",
            "3981 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847791]\n",
            "3982 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847788]\n",
            "3983 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.847785]\n",
            "3984 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847782]\n",
            "3985 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847780]\n",
            "3986 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847777]\n",
            "3987 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847774]\n",
            "3988 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847772]\n",
            "3989 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847769]\n",
            "3990 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847766]\n",
            "3991 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847764]\n",
            "3992 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847761]\n",
            "3993 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847758]\n",
            "3994 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847756]\n",
            "3995 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847753]\n",
            "3996 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847750]\n",
            "3997 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847748]\n",
            "3998 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847745]\n",
            "3999 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847743]\n",
            "4000 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847740]\n",
            "generated_data\n",
            "4001 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847738]\n",
            "4002 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847735]\n",
            "4003 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847733]\n",
            "4004 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847730]\n",
            "4005 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847728]\n",
            "4006 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847725]\n",
            "4007 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847723]\n",
            "4008 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847720]\n",
            "4009 [D loss: 0.597868, acc.: 62.50%] [G loss: 0.847717]\n",
            "4010 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847715]\n",
            "4011 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847712]\n",
            "4012 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847710]\n",
            "4013 [D loss: 0.597904, acc.: 62.50%] [G loss: 0.847707]\n",
            "4014 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847705]\n",
            "4015 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847702]\n",
            "4016 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847700]\n",
            "4017 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847698]\n",
            "4018 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847695]\n",
            "4019 [D loss: 0.597924, acc.: 62.50%] [G loss: 0.847691]\n",
            "4020 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847688]\n",
            "4021 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847686]\n",
            "4022 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847684]\n",
            "4023 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847681]\n",
            "4024 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847679]\n",
            "4025 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847677]\n",
            "4026 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847674]\n",
            "4027 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847672]\n",
            "4028 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.847654]\n",
            "4029 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847668]\n",
            "4030 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847665]\n",
            "4031 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847663]\n",
            "4032 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847661]\n",
            "4033 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847659]\n",
            "4034 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847656]\n",
            "4035 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847654]\n",
            "4036 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847652]\n",
            "4037 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847650]\n",
            "4038 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847648]\n",
            "4039 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847645]\n",
            "4040 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847643]\n",
            "4041 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.847641]\n",
            "4042 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847639]\n",
            "4043 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847637]\n",
            "4044 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847635]\n",
            "4045 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847633]\n",
            "4046 [D loss: 0.597873, acc.: 62.50%] [G loss: 0.847630]\n",
            "4047 [D loss: 0.598177, acc.: 62.50%] [G loss: 0.847557]\n",
            "4048 [D loss: 0.623514, acc.: 62.50%] [G loss: 0.847702]\n",
            "4049 [D loss: 0.597845, acc.: 62.50%] [G loss: 0.847746]\n",
            "4050 [D loss: 0.597909, acc.: 62.50%] [G loss: 0.847755]\n",
            "4051 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847754]\n",
            "4052 [D loss: 0.597945, acc.: 62.50%] [G loss: 0.847757]\n",
            "4053 [D loss: 0.597546, acc.: 62.50%] [G loss: 0.848077]\n",
            "4054 [D loss: 0.601637, acc.: 62.50%] [G loss: 0.847723]\n",
            "4055 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.847703]\n",
            "4056 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847696]\n",
            "4057 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847693]\n",
            "4058 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847690]\n",
            "4059 [D loss: 0.598002, acc.: 62.50%] [G loss: 0.848271]\n",
            "4060 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847681]\n",
            "4061 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847678]\n",
            "4062 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847676]\n",
            "4063 [D loss: 0.597980, acc.: 62.50%] [G loss: 0.847678]\n",
            "4064 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847677]\n",
            "4065 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.848089]\n",
            "4066 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.847673]\n",
            "4067 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847670]\n",
            "4068 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847668]\n",
            "4069 [D loss: 0.597887, acc.: 62.50%] [G loss: 0.847665]\n",
            "4070 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847663]\n",
            "4071 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847660]\n",
            "4072 [D loss: 0.598006, acc.: 62.50%] [G loss: 0.847670]\n",
            "4073 [D loss: 0.597850, acc.: 62.50%] [G loss: 0.848270]\n",
            "4074 [D loss: 0.597645, acc.: 62.50%] [G loss: 0.848187]\n",
            "4075 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847444]\n",
            "4076 [D loss: 0.597279, acc.: 62.50%] [G loss: 0.847715]\n",
            "4077 [D loss: 0.597465, acc.: 62.50%] [G loss: 0.848196]\n",
            "4078 [D loss: 0.597402, acc.: 62.50%] [G loss: 0.848710]\n",
            "4079 [D loss: 0.597055, acc.: 62.50%] [G loss: 0.848297]\n",
            "4080 [D loss: 0.598042, acc.: 62.50%] [G loss: 0.847681]\n",
            "4081 [D loss: 0.598112, acc.: 62.50%] [G loss: 0.844716]\n",
            "4082 [D loss: 0.597500, acc.: 62.50%] [G loss: 0.846985]\n",
            "4083 [D loss: 0.598565, acc.: 62.50%] [G loss: 0.846892]\n",
            "4084 [D loss: 0.597996, acc.: 62.50%] [G loss: 0.845933]\n",
            "4085 [D loss: 0.597934, acc.: 62.50%] [G loss: 0.845340]\n",
            "4086 [D loss: 0.598210, acc.: 62.50%] [G loss: 0.847361]\n",
            "4087 [D loss: 0.597653, acc.: 62.50%] [G loss: 0.847427]\n",
            "4088 [D loss: 0.598710, acc.: 62.50%] [G loss: 0.848136]\n",
            "4089 [D loss: 0.598672, acc.: 62.50%] [G loss: 0.847644]\n",
            "4090 [D loss: 0.615023, acc.: 62.50%] [G loss: 0.865996]\n",
            "4091 [D loss: 0.601383, acc.: 62.50%] [G loss: 0.849298]\n",
            "4092 [D loss: 0.598109, acc.: 62.50%] [G loss: 0.846506]\n",
            "4093 [D loss: 0.598717, acc.: 62.50%] [G loss: 0.847457]\n",
            "4094 [D loss: 0.598312, acc.: 62.50%] [G loss: 0.847415]\n",
            "4095 [D loss: 0.597951, acc.: 62.50%] [G loss: 0.847114]\n",
            "4096 [D loss: 0.598711, acc.: 62.50%] [G loss: 0.846458]\n",
            "4097 [D loss: 0.597831, acc.: 62.50%] [G loss: 0.848112]\n",
            "4098 [D loss: 0.599196, acc.: 62.50%] [G loss: 0.848749]\n",
            "4099 [D loss: 0.597999, acc.: 62.50%] [G loss: 0.848768]\n",
            "4100 [D loss: 0.598337, acc.: 62.50%] [G loss: 0.848403]\n",
            "generated_data\n",
            "4101 [D loss: 0.597249, acc.: 62.50%] [G loss: 0.848072]\n",
            "4102 [D loss: 0.597831, acc.: 62.50%] [G loss: 0.848059]\n",
            "4103 [D loss: 0.597787, acc.: 62.50%] [G loss: 0.849702]\n",
            "4104 [D loss: 0.597720, acc.: 62.50%] [G loss: 0.849409]\n",
            "4105 [D loss: 0.597669, acc.: 62.50%] [G loss: 0.847356]\n",
            "4106 [D loss: 0.597631, acc.: 62.50%] [G loss: 0.848060]\n",
            "4107 [D loss: 0.597255, acc.: 62.50%] [G loss: 0.848043]\n",
            "4108 [D loss: 0.597500, acc.: 62.50%] [G loss: 0.847699]\n",
            "4109 [D loss: 0.598973, acc.: 62.50%] [G loss: 0.847783]\n",
            "4110 [D loss: 0.597321, acc.: 62.50%] [G loss: 0.847067]\n",
            "4111 [D loss: 0.598209, acc.: 62.50%] [G loss: 0.848074]\n",
            "4112 [D loss: 0.597913, acc.: 62.50%] [G loss: 0.847612]\n",
            "4113 [D loss: 0.597653, acc.: 62.50%] [G loss: 0.848257]\n",
            "4114 [D loss: 0.597380, acc.: 62.50%] [G loss: 0.848816]\n",
            "4115 [D loss: 0.597590, acc.: 62.50%] [G loss: 0.847275]\n",
            "4116 [D loss: 0.597373, acc.: 62.50%] [G loss: 0.847274]\n",
            "4117 [D loss: 0.598012, acc.: 62.50%] [G loss: 0.846368]\n",
            "4118 [D loss: 0.596604, acc.: 62.50%] [G loss: 0.849102]\n",
            "4119 [D loss: 0.597869, acc.: 62.50%] [G loss: 0.848462]\n",
            "4120 [D loss: 0.597414, acc.: 62.50%] [G loss: 0.846556]\n",
            "4121 [D loss: 0.596640, acc.: 62.50%] [G loss: 0.845702]\n",
            "4122 [D loss: 0.597431, acc.: 62.50%] [G loss: 0.848302]\n",
            "4123 [D loss: 0.597603, acc.: 62.50%] [G loss: 0.847165]\n",
            "4124 [D loss: 0.597233, acc.: 62.50%] [G loss: 0.847158]\n",
            "4125 [D loss: 0.597931, acc.: 62.50%] [G loss: 0.847157]\n",
            "4126 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847156]\n",
            "4127 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847156]\n",
            "4128 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847156]\n",
            "4129 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847156]\n",
            "4130 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847156]\n",
            "4131 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847156]\n",
            "4132 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847156]\n",
            "4133 [D loss: 0.597733, acc.: 62.50%] [G loss: 0.847156]\n",
            "4134 [D loss: 0.597833, acc.: 62.50%] [G loss: 0.847647]\n",
            "4135 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847160]\n",
            "4136 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847152]\n",
            "4137 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847152]\n",
            "4138 [D loss: 0.598042, acc.: 62.50%] [G loss: 0.847407]\n",
            "4139 [D loss: 0.597820, acc.: 62.50%] [G loss: 0.847153]\n",
            "4140 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847154]\n",
            "4141 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847154]\n",
            "4142 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847154]\n",
            "4143 [D loss: 0.598008, acc.: 62.50%] [G loss: 0.847165]\n",
            "4144 [D loss: 0.597850, acc.: 62.50%] [G loss: 0.847168]\n",
            "4145 [D loss: 0.598469, acc.: 62.50%] [G loss: 0.847172]\n",
            "4146 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847173]\n",
            "4147 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847173]\n",
            "4148 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847173]\n",
            "4149 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847173]\n",
            "4150 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847173]\n",
            "4151 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847058]\n",
            "4152 [D loss: 0.597836, acc.: 62.50%] [G loss: 0.847198]\n",
            "4153 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847192]\n",
            "4154 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847173]\n",
            "4155 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.847173]\n",
            "4156 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847173]\n",
            "4157 [D loss: 0.598217, acc.: 62.50%] [G loss: 0.847259]\n",
            "4158 [D loss: 0.597770, acc.: 62.50%] [G loss: 0.847175]\n",
            "4159 [D loss: 0.597811, acc.: 62.50%] [G loss: 0.847287]\n",
            "4160 [D loss: 0.597808, acc.: 62.50%] [G loss: 0.847432]\n",
            "4161 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847178]\n",
            "4162 [D loss: 0.597630, acc.: 62.50%] [G loss: 0.847179]\n",
            "4163 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.847179]\n",
            "4164 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847246]\n",
            "4165 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847179]\n",
            "4166 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847397]\n",
            "4167 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847179]\n",
            "4168 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847178]\n",
            "4169 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847178]\n",
            "4170 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847545]\n",
            "4171 [D loss: 0.597839, acc.: 62.50%] [G loss: 0.847178]\n",
            "4172 [D loss: 0.597848, acc.: 62.50%] [G loss: 0.847438]\n",
            "4173 [D loss: 0.597902, acc.: 62.50%] [G loss: 0.847497]\n",
            "4174 [D loss: 0.597849, acc.: 62.50%] [G loss: 0.847175]\n",
            "4175 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847478]\n",
            "4176 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.847175]\n",
            "4177 [D loss: 0.597871, acc.: 62.50%] [G loss: 0.847173]\n",
            "4178 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847173]\n",
            "4179 [D loss: 0.597884, acc.: 62.50%] [G loss: 0.847173]\n",
            "4180 [D loss: 0.597831, acc.: 62.50%] [G loss: 0.847173]\n",
            "4181 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847173]\n",
            "4182 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847173]\n",
            "4183 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847172]\n",
            "4184 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847359]\n",
            "4185 [D loss: 0.597820, acc.: 62.50%] [G loss: 0.847518]\n",
            "4186 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847173]\n",
            "4187 [D loss: 0.597892, acc.: 62.50%] [G loss: 0.847171]\n",
            "4188 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847171]\n",
            "4189 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847171]\n",
            "4190 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847170]\n",
            "4191 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847170]\n",
            "4192 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847170]\n",
            "4193 [D loss: 0.597893, acc.: 62.50%] [G loss: 0.847328]\n",
            "4194 [D loss: 0.597796, acc.: 62.50%] [G loss: 0.847170]\n",
            "4195 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847170]\n",
            "4196 [D loss: 0.597601, acc.: 62.50%] [G loss: 0.847169]\n",
            "4197 [D loss: 0.597826, acc.: 62.50%] [G loss: 0.847168]\n",
            "4198 [D loss: 0.598266, acc.: 62.50%] [G loss: 0.847862]\n",
            "4199 [D loss: 0.597813, acc.: 62.50%] [G loss: 0.847163]\n",
            "4200 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847163]\n",
            "generated_data\n",
            "4201 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847163]\n",
            "4202 [D loss: 0.597896, acc.: 62.50%] [G loss: 0.847161]\n",
            "4203 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847161]\n",
            "4204 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847161]\n",
            "4205 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847189]\n",
            "4206 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.847160]\n",
            "4207 [D loss: 0.597858, acc.: 62.50%] [G loss: 0.847445]\n",
            "4208 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847159]\n",
            "4209 [D loss: 0.597848, acc.: 62.50%] [G loss: 0.847159]\n",
            "4210 [D loss: 0.597849, acc.: 62.50%] [G loss: 0.847184]\n",
            "4211 [D loss: 0.597804, acc.: 62.50%] [G loss: 0.847542]\n",
            "4212 [D loss: 0.597917, acc.: 62.50%] [G loss: 0.847158]\n",
            "4213 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847157]\n",
            "4214 [D loss: 0.597681, acc.: 62.50%] [G loss: 0.847156]\n",
            "4215 [D loss: 0.597795, acc.: 62.50%] [G loss: 0.847156]\n",
            "4216 [D loss: 0.597539, acc.: 62.50%] [G loss: 0.847977]\n",
            "4217 [D loss: 0.598128, acc.: 62.50%] [G loss: 0.847158]\n",
            "4218 [D loss: 0.597950, acc.: 62.50%] [G loss: 0.847591]\n",
            "4219 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.847156]\n",
            "4220 [D loss: 0.597792, acc.: 62.50%] [G loss: 0.847157]\n",
            "4221 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847350]\n",
            "4222 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847158]\n",
            "4223 [D loss: 0.597724, acc.: 62.50%] [G loss: 0.848667]\n",
            "4224 [D loss: 0.597736, acc.: 62.50%] [G loss: 0.848534]\n",
            "4225 [D loss: 0.598194, acc.: 62.50%] [G loss: 0.847343]\n",
            "4226 [D loss: 0.598331, acc.: 62.50%] [G loss: 0.847164]\n",
            "4227 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847164]\n",
            "4228 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847163]\n",
            "4229 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847163]\n",
            "4230 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847163]\n",
            "4231 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847163]\n",
            "4232 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847163]\n",
            "4233 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847162]\n",
            "4234 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847162]\n",
            "4235 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847162]\n",
            "4236 [D loss: 0.597805, acc.: 62.50%] [G loss: 0.847162]\n",
            "4237 [D loss: 0.597477, acc.: 62.50%] [G loss: 0.855741]\n",
            "4238 [D loss: 0.600971, acc.: 62.50%] [G loss: 0.847165]\n",
            "4239 [D loss: 0.597850, acc.: 62.50%] [G loss: 0.847168]\n",
            "4240 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847169]\n",
            "4241 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847169]\n",
            "4242 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847168]\n",
            "4243 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847168]\n",
            "4244 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847168]\n",
            "4245 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847168]\n",
            "4246 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847225]\n",
            "4247 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847167]\n",
            "4248 [D loss: 0.597914, acc.: 62.50%] [G loss: 0.847167]\n",
            "4249 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847166]\n",
            "4250 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847166]\n",
            "4251 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847166]\n",
            "4252 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847166]\n",
            "4253 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847165]\n",
            "4254 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847165]\n",
            "4255 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847165]\n",
            "4256 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847165]\n",
            "4257 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847165]\n",
            "4258 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847165]\n",
            "4259 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847164]\n",
            "4260 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847164]\n",
            "4261 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847164]\n",
            "4262 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847164]\n",
            "4263 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847164]\n",
            "4264 [D loss: 0.597909, acc.: 62.50%] [G loss: 0.847162]\n",
            "4265 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847162]\n",
            "4266 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847162]\n",
            "4267 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847161]\n",
            "4268 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847161]\n",
            "4269 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847161]\n",
            "4270 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847161]\n",
            "4271 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847161]\n",
            "4272 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847160]\n",
            "4273 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847160]\n",
            "4274 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847160]\n",
            "4275 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847160]\n",
            "4276 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847160]\n",
            "4277 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847160]\n",
            "4278 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847159]\n",
            "4279 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847159]\n",
            "4280 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847159]\n",
            "4281 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847159]\n",
            "4282 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847159]\n",
            "4283 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847158]\n",
            "4284 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847158]\n",
            "4285 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847158]\n",
            "4286 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847158]\n",
            "4287 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847158]\n",
            "4288 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847158]\n",
            "4289 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847157]\n",
            "4290 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847157]\n",
            "4291 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847157]\n",
            "4292 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847157]\n",
            "4293 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847157]\n",
            "4294 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847157]\n",
            "4295 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847156]\n",
            "4296 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847156]\n",
            "4297 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847156]\n",
            "4298 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847156]\n",
            "4299 [D loss: 0.598156, acc.: 62.50%] [G loss: 0.847156]\n",
            "4300 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847156]\n",
            "generated_data\n",
            "4301 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847156]\n",
            "4302 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847155]\n",
            "4303 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847155]\n",
            "4304 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847155]\n",
            "4305 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847155]\n",
            "4306 [D loss: 0.597849, acc.: 62.50%] [G loss: 0.847155]\n",
            "4307 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847154]\n",
            "4308 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847154]\n",
            "4309 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847154]\n",
            "4310 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847154]\n",
            "4311 [D loss: 0.598083, acc.: 62.50%] [G loss: 0.847150]\n",
            "4312 [D loss: 0.597885, acc.: 62.50%] [G loss: 0.847154]\n",
            "4313 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847155]\n",
            "4314 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847721]\n",
            "4315 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847155]\n",
            "4316 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847155]\n",
            "4317 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847155]\n",
            "4318 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847155]\n",
            "4319 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847154]\n",
            "4320 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847154]\n",
            "4321 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847154]\n",
            "4322 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847154]\n",
            "4323 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847154]\n",
            "4324 [D loss: 0.597889, acc.: 62.50%] [G loss: 0.847153]\n",
            "4325 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847153]\n",
            "4326 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847153]\n",
            "4327 [D loss: 0.597863, acc.: 62.50%] [G loss: 0.847152]\n",
            "4328 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847152]\n",
            "4329 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847152]\n",
            "4330 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847152]\n",
            "4331 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847152]\n",
            "4332 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847151]\n",
            "4333 [D loss: 0.597858, acc.: 62.50%] [G loss: 0.847151]\n",
            "4334 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847151]\n",
            "4335 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847151]\n",
            "4336 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847151]\n",
            "4337 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847151]\n",
            "4338 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847150]\n",
            "4339 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847150]\n",
            "4340 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847150]\n",
            "4341 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847150]\n",
            "4342 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847150]\n",
            "4343 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847150]\n",
            "4344 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847149]\n",
            "4345 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847149]\n",
            "4346 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847149]\n",
            "4347 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847149]\n",
            "4348 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847149]\n",
            "4349 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847149]\n",
            "4350 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847148]\n",
            "4351 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847148]\n",
            "4352 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847148]\n",
            "4353 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847148]\n",
            "4354 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847148]\n",
            "4355 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847148]\n",
            "4356 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847148]\n",
            "4357 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847147]\n",
            "4358 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847147]\n",
            "4359 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847147]\n",
            "4360 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847147]\n",
            "4361 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847147]\n",
            "4362 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847147]\n",
            "4363 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847146]\n",
            "4364 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4365 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847146]\n",
            "4366 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847146]\n",
            "4367 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847146]\n",
            "4368 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847146]\n",
            "4369 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847145]\n",
            "4370 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847145]\n",
            "4371 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847145]\n",
            "4372 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847145]\n",
            "4373 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847145]\n",
            "4374 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847145]\n",
            "4375 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847145]\n",
            "4376 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847144]\n",
            "4377 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847144]\n",
            "4378 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847144]\n",
            "4379 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847144]\n",
            "4380 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847144]\n",
            "4381 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847144]\n",
            "4382 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847144]\n",
            "4383 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847143]\n",
            "4384 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847143]\n",
            "4385 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847143]\n",
            "4386 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847143]\n",
            "4387 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847143]\n",
            "4388 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847143]\n",
            "4389 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847142]\n",
            "4390 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847142]\n",
            "4391 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847142]\n",
            "4392 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847142]\n",
            "4393 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847142]\n",
            "4394 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847142]\n",
            "4395 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847142]\n",
            "4396 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847142]\n",
            "4397 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847141]\n",
            "4398 [D loss: 0.597883, acc.: 62.50%] [G loss: 0.847139]\n",
            "4399 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847139]\n",
            "4400 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847139]\n",
            "generated_data\n",
            "4401 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847138]\n",
            "4402 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847138]\n",
            "4403 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847138]\n",
            "4404 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847138]\n",
            "4405 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847138]\n",
            "4406 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847138]\n",
            "4407 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847138]\n",
            "4408 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847137]\n",
            "4409 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847137]\n",
            "4410 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847137]\n",
            "4411 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847137]\n",
            "4412 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847137]\n",
            "4413 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847137]\n",
            "4414 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847136]\n",
            "4415 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847136]\n",
            "4416 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847136]\n",
            "4417 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847136]\n",
            "4418 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847136]\n",
            "4419 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847506]\n",
            "4420 [D loss: 0.597898, acc.: 62.50%] [G loss: 0.847135]\n",
            "4421 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847135]\n",
            "4422 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847134]\n",
            "4423 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847134]\n",
            "4424 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847134]\n",
            "4425 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847134]\n",
            "4426 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847134]\n",
            "4427 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847134]\n",
            "4428 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847134]\n",
            "4429 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847134]\n",
            "4430 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847133]\n",
            "4431 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.847133]\n",
            "4432 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847133]\n",
            "4433 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847133]\n",
            "4434 [D loss: 0.598047, acc.: 62.50%] [G loss: 0.847130]\n",
            "4435 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847129]\n",
            "4436 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847129]\n",
            "4437 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847129]\n",
            "4438 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847129]\n",
            "4439 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847128]\n",
            "4440 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847128]\n",
            "4441 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847128]\n",
            "4442 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847128]\n",
            "4443 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847128]\n",
            "4444 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847128]\n",
            "4445 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847128]\n",
            "4446 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847128]\n",
            "4447 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847128]\n",
            "4448 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4449 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4450 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4451 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4452 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4453 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4454 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4455 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4456 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4457 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4458 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4459 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4460 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4461 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4462 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4463 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4464 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4465 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4466 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4467 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847126]\n",
            "4468 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4469 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4470 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4471 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4472 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4473 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4474 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4475 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4476 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4477 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4478 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4479 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4480 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4481 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4482 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4483 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4484 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4485 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4486 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4487 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4488 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4489 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4490 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4491 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4492 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4493 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4494 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4495 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4496 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4497 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4498 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4499 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4500 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847122]\n",
            "generated_data\n",
            "4501 [D loss: 0.598077, acc.: 62.50%] [G loss: 0.847130]\n",
            "4502 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847132]\n",
            "4503 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847132]\n",
            "4504 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847132]\n",
            "4505 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847132]\n",
            "4506 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847132]\n",
            "4507 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847132]\n",
            "4508 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847131]\n",
            "4509 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847131]\n",
            "4510 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847266]\n",
            "4511 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847131]\n",
            "4512 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847131]\n",
            "4513 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847131]\n",
            "4514 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847131]\n",
            "4515 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847131]\n",
            "4516 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847130]\n",
            "4517 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847130]\n",
            "4518 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847130]\n",
            "4519 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847130]\n",
            "4520 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847130]\n",
            "4521 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847130]\n",
            "4522 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847129]\n",
            "4523 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847129]\n",
            "4524 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847129]\n",
            "4525 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847129]\n",
            "4526 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847129]\n",
            "4527 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847129]\n",
            "4528 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847129]\n",
            "4529 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847129]\n",
            "4530 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847128]\n",
            "4531 [D loss: 0.597881, acc.: 62.50%] [G loss: 0.847126]\n",
            "4532 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4533 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4534 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4535 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4536 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4537 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4538 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4539 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4540 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4541 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4542 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4543 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4544 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4545 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4546 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4547 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4548 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4549 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4550 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4551 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4552 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4553 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4554 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4555 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4556 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4557 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4558 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4559 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.847122]\n",
            "4560 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4561 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4562 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4563 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847122]\n",
            "4564 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4565 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4566 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4567 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4568 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4569 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4570 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4571 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4572 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4573 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4574 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4575 [D loss: 0.597946, acc.: 62.50%] [G loss: 0.847125]\n",
            "4576 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4577 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4578 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4579 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4580 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4581 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4582 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4583 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4584 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4585 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4586 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4587 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4588 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4589 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4590 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4591 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4592 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4593 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4594 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4595 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4596 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4597 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4598 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4599 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4600 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "generated_data\n",
            "4601 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4602 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4603 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4604 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4605 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4606 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4607 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4608 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4609 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847237]\n",
            "4610 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4611 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4612 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4613 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4614 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4615 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4616 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4617 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4618 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4619 [D loss: 0.598081, acc.: 62.50%] [G loss: 0.847126]\n",
            "4620 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4621 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4622 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4623 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4624 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4625 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4626 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4627 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847127]\n",
            "4628 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4629 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4630 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4631 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4632 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4633 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4634 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847126]\n",
            "4635 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4636 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4637 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4638 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4639 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4640 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847125]\n",
            "4641 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4642 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4643 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4644 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847124]\n",
            "4645 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847108]\n",
            "4646 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4647 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847124]\n",
            "4648 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847123]\n",
            "4649 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4650 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4651 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4652 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847123]\n",
            "4653 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4654 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847123]\n",
            "4655 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4656 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.847122]\n",
            "4657 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4658 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4659 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847122]\n",
            "4660 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4661 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4662 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4663 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4664 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847121]\n",
            "4665 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4666 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4667 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847121]\n",
            "4668 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847120]\n",
            "4669 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847120]\n",
            "4670 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847120]\n",
            "4671 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847120]\n",
            "4672 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847120]\n",
            "4673 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847120]\n",
            "4674 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847120]\n",
            "4675 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847119]\n",
            "4676 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847119]\n",
            "4677 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847119]\n",
            "4678 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847119]\n",
            "4679 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847429]\n",
            "4680 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847119]\n",
            "4681 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847119]\n",
            "4682 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847118]\n",
            "4683 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847118]\n",
            "4684 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847118]\n",
            "4685 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847118]\n",
            "4686 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847118]\n",
            "4687 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847118]\n",
            "4688 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847118]\n",
            "4689 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847117]\n",
            "4690 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847117]\n",
            "4691 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847117]\n",
            "4692 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847117]\n",
            "4693 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847117]\n",
            "4694 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847117]\n",
            "4695 [D loss: 0.598137, acc.: 62.50%] [G loss: 0.847118]\n",
            "4696 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847118]\n",
            "4697 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847118]\n",
            "4698 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847118]\n",
            "4699 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847118]\n",
            "4700 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847118]\n",
            "generated_data\n",
            "4701 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847118]\n",
            "4702 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.847118]\n",
            "4703 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847118]\n",
            "4704 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847117]\n",
            "4705 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847117]\n",
            "4706 [D loss: 0.597886, acc.: 62.50%] [G loss: 0.847116]\n",
            "4707 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847116]\n",
            "4708 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847116]\n",
            "4709 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847116]\n",
            "4710 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847115]\n",
            "4711 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847115]\n",
            "4712 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847115]\n",
            "4713 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847115]\n",
            "4714 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847115]\n",
            "4715 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847115]\n",
            "4716 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847115]\n",
            "4717 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847114]\n",
            "4718 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847114]\n",
            "4719 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847114]\n",
            "4720 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847114]\n",
            "4721 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847114]\n",
            "4722 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847114]\n",
            "4723 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847114]\n",
            "4724 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847114]\n",
            "4725 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847113]\n",
            "4726 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847113]\n",
            "4727 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847113]\n",
            "4728 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847113]\n",
            "4729 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847113]\n",
            "4730 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847113]\n",
            "4731 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847113]\n",
            "4732 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847113]\n",
            "4733 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847112]\n",
            "4734 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847112]\n",
            "4735 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847112]\n",
            "4736 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847112]\n",
            "4737 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847112]\n",
            "4738 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847112]\n",
            "4739 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847112]\n",
            "4740 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847112]\n",
            "4741 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847111]\n",
            "4742 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847111]\n",
            "4743 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847111]\n",
            "4744 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847111]\n",
            "4745 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847111]\n",
            "4746 [D loss: 0.597851, acc.: 62.50%] [G loss: 0.847111]\n",
            "4747 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847111]\n",
            "4748 [D loss: 0.597623, acc.: 62.50%] [G loss: 0.852763]\n",
            "4749 [D loss: 0.600920, acc.: 62.50%] [G loss: 0.847060]\n",
            "4750 [D loss: 0.597862, acc.: 62.50%] [G loss: 0.847023]\n",
            "4751 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.847014]\n",
            "4752 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847012]\n",
            "4753 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847012]\n",
            "4754 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847012]\n",
            "4755 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847012]\n",
            "4756 [D loss: 0.597852, acc.: 62.50%] [G loss: 0.847013]\n",
            "4757 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847013]\n",
            "4758 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847013]\n",
            "4759 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847014]\n",
            "4760 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.847014]\n",
            "4761 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847014]\n",
            "4762 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847014]\n",
            "4763 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847015]\n",
            "4764 [D loss: 0.597881, acc.: 62.50%] [G loss: 0.847015]\n",
            "4765 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847015]\n",
            "4766 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847016]\n",
            "4767 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847016]\n",
            "4768 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847016]\n",
            "4769 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847016]\n",
            "4770 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847017]\n",
            "4771 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847017]\n",
            "4772 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847017]\n",
            "4773 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.847018]\n",
            "4774 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847018]\n",
            "4775 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847018]\n",
            "4776 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847018]\n",
            "4777 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847019]\n",
            "4778 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847019]\n",
            "4779 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847019]\n",
            "4780 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847019]\n",
            "4781 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847020]\n",
            "4782 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847020]\n",
            "4783 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847020]\n",
            "4784 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847020]\n",
            "4785 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847021]\n",
            "4786 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847021]\n",
            "4787 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847021]\n",
            "4788 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847022]\n",
            "4789 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847022]\n",
            "4790 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847022]\n",
            "4791 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847022]\n",
            "4792 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.847022]\n",
            "4793 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847023]\n",
            "4794 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847023]\n",
            "4795 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847023]\n",
            "4796 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847023]\n",
            "4797 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847024]\n",
            "4798 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847024]\n",
            "4799 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847024]\n",
            "4800 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847024]\n",
            "generated_data\n",
            "4801 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847025]\n",
            "4802 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847025]\n",
            "4803 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847025]\n",
            "4804 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847025]\n",
            "4805 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847025]\n",
            "4806 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847452]\n",
            "4807 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847026]\n",
            "4808 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847026]\n",
            "4809 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847026]\n",
            "4810 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847027]\n",
            "4811 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847027]\n",
            "4812 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847027]\n",
            "4813 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847027]\n",
            "4814 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847027]\n",
            "4815 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847028]\n",
            "4816 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847028]\n",
            "4817 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847345]\n",
            "4818 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847028]\n",
            "4819 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847029]\n",
            "4820 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847029]\n",
            "4821 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847029]\n",
            "4822 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847029]\n",
            "4823 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847029]\n",
            "4824 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847030]\n",
            "4825 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847030]\n",
            "4826 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847030]\n",
            "4827 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847085]\n",
            "4828 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847030]\n",
            "4829 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847031]\n",
            "4830 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847031]\n",
            "4831 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847031]\n",
            "4832 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847031]\n",
            "4833 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847031]\n",
            "4834 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847032]\n",
            "4835 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847032]\n",
            "4836 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847032]\n",
            "4837 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847032]\n",
            "4838 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847032]\n",
            "4839 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847033]\n",
            "4840 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847033]\n",
            "4841 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847033]\n",
            "4842 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847033]\n",
            "4843 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847033]\n",
            "4844 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847034]\n",
            "4845 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847034]\n",
            "4846 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847034]\n",
            "4847 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847034]\n",
            "4848 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847034]\n",
            "4849 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847034]\n",
            "4850 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847035]\n",
            "4851 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847035]\n",
            "4852 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847035]\n",
            "4853 [D loss: 0.597856, acc.: 62.50%] [G loss: 0.847035]\n",
            "4854 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847035]\n",
            "4855 [D loss: 0.597861, acc.: 62.50%] [G loss: 0.847035]\n",
            "4856 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847035]\n",
            "4857 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847036]\n",
            "4858 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847036]\n",
            "4859 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847036]\n",
            "4860 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847036]\n",
            "4861 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847036]\n",
            "4862 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847036]\n",
            "4863 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847037]\n",
            "4864 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847037]\n",
            "4865 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847037]\n",
            "4866 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847037]\n",
            "4867 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847037]\n",
            "4868 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847037]\n",
            "4869 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.848632]\n",
            "4870 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847038]\n",
            "4871 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847038]\n",
            "4872 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847038]\n",
            "4873 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847038]\n",
            "4874 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847039]\n",
            "4875 [D loss: 0.597857, acc.: 62.50%] [G loss: 0.847039]\n",
            "4876 [D loss: 0.597855, acc.: 62.50%] [G loss: 0.847039]\n",
            "4877 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847039]\n",
            "4878 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847039]\n",
            "4879 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847039]\n",
            "4880 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847039]\n",
            "4881 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847039]\n",
            "4882 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847040]\n",
            "4883 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847040]\n",
            "4884 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847040]\n",
            "4885 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847040]\n",
            "4886 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847040]\n",
            "4887 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847040]\n",
            "4888 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847041]\n",
            "4889 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847041]\n",
            "4890 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847041]\n",
            "4891 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847041]\n",
            "4892 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.847041]\n",
            "4893 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847041]\n",
            "4894 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847041]\n",
            "4895 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847041]\n",
            "4896 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847042]\n",
            "4897 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847042]\n",
            "4898 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.847042]\n",
            "4899 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847042]\n",
            "4900 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847042]\n",
            "generated_data\n",
            "4901 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847042]\n",
            "4902 [D loss: 0.597859, acc.: 62.50%] [G loss: 0.847042]\n",
            "4903 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847042]\n",
            "4904 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847042]\n",
            "4905 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847043]\n",
            "4906 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847043]\n",
            "4907 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847043]\n",
            "4908 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847043]\n",
            "4909 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847043]\n",
            "4910 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847043]\n",
            "4911 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847043]\n",
            "4912 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847096]\n",
            "4913 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847044]\n",
            "4914 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847044]\n",
            "4915 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847044]\n",
            "4916 [D loss: 0.597930, acc.: 62.50%] [G loss: 0.847042]\n",
            "4917 [D loss: 0.597982, acc.: 62.50%] [G loss: 0.847045]\n",
            "4918 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847046]\n",
            "4919 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847046]\n",
            "4920 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847046]\n",
            "4921 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847046]\n",
            "4922 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847046]\n",
            "4923 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847047]\n",
            "4924 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847047]\n",
            "4925 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847047]\n",
            "4926 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847047]\n",
            "4927 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847047]\n",
            "4928 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847047]\n",
            "4929 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847047]\n",
            "4930 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847047]\n",
            "4931 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847047]\n",
            "4932 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847048]\n",
            "4933 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847048]\n",
            "4934 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847048]\n",
            "4935 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847048]\n",
            "4936 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847048]\n",
            "4937 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847048]\n",
            "4938 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.847048]\n",
            "4939 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847048]\n",
            "4940 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847048]\n",
            "4941 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847049]\n",
            "4942 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847049]\n",
            "4943 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847049]\n",
            "4944 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847049]\n",
            "4945 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847049]\n",
            "4946 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847049]\n",
            "4947 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847049]\n",
            "4948 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847049]\n",
            "4949 [D loss: 0.597878, acc.: 62.50%] [G loss: 0.847050]\n",
            "4950 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847174]\n",
            "4951 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847050]\n",
            "4952 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847050]\n",
            "4953 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847050]\n",
            "4954 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847051]\n",
            "4955 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847051]\n",
            "4956 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847051]\n",
            "4957 [D loss: 0.598039, acc.: 62.50%] [G loss: 0.847054]\n",
            "4958 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847054]\n",
            "4959 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847055]\n",
            "4960 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847055]\n",
            "4961 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847055]\n",
            "4962 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847055]\n",
            "4963 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847055]\n",
            "4964 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847055]\n",
            "4965 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847055]\n",
            "4966 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847055]\n",
            "4967 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847055]\n",
            "4968 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847055]\n",
            "4969 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847056]\n",
            "4970 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847056]\n",
            "4971 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847056]\n",
            "4972 [D loss: 0.597802, acc.: 62.50%] [G loss: 0.847055]\n",
            "4973 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847341]\n",
            "4974 [D loss: 0.598258, acc.: 62.50%] [G loss: 0.847061]\n",
            "4975 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847062]\n",
            "4976 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4977 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4978 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4979 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4980 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4981 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4982 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.847063]\n",
            "4983 [D loss: 0.597854, acc.: 62.50%] [G loss: 0.847063]\n",
            "4984 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4985 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4986 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4987 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4988 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4989 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4990 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4991 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4992 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4993 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4994 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4995 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4996 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4997 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4998 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "4999 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847063]\n",
            "5000 [D loss: 0.597853, acc.: 62.50%] [G loss: 0.847064]\n",
            "generated_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir model/gan\n",
        "!mkdir model/gan/saved"
      ],
      "metadata": {
        "id": "-pnvO3IIAzDK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthesizer.generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaXiltIPA8Jq",
        "outputId": "55ef532d-c04d-4d9f-a4dc-0768e96229eb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(32, 32)]                0         \n",
            "                                                                 \n",
            " dense (Dense)               (32, 128)                 4224      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (32, 256)                 33024     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (32, 512)                 131584    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (32, 10)                  5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 173,962\n",
            "Trainable params: 173,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synthesizer.discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VBsbNU3A_Gp",
        "outputId": "2be3d798-ef80-492f-c977-0269938ae202"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(32, 10)]                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (32, 512)                 5632      \n",
            "                                                                 \n",
            " dropout (Dropout)           (32, 512)                 0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (32, 256)                 131328    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (32, 256)                 0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (32, 128)                 32896     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (32, 1)                   129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 169,985\n",
            "Trainable params: 0\n",
            "Non-trainable params: 169,985\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = {'GAN': ['GAN', False, synthesizer.generator]}"
      ],
      "metadata": {
        "id": "LCZ1VLvoJqut"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Setup parameters visualization parameters\n",
        "seed = 17\n",
        "test_size = 151\n",
        "noise_dim = 32\n",
        "\n",
        "np.random.seed(seed)\n",
        "z = np.random.normal(size=(test_size, noise_dim))\n",
        "real = synthesizer.get_data_batch(train=df, batch_size=test_size, seed=seed)\n",
        "real_samples = pd.DataFrame(real, columns=data_cols)"
      ],
      "metadata": {
        "id": "GkFcicXIO8cF"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = ['GAN']\n",
        "colors = ['deepskyblue','blue']\n",
        "markers = ['o','^']"
      ],
      "metadata": {
        "id": "_WMOIa5HPx3L"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_cols"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI0qOWh2Q8ES",
        "outputId": "c96971dc-aacb-4f5a-c594-8b78aa65d117"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['conc (ppm)',\n",
              " 'ad dose(g/L)',\n",
              " 'ph value',\n",
              " 'Temperature(⁰C)',\n",
              " 'time',\n",
              " 'absorbance',\n",
              " 'conc',\n",
              " 'real conc',\n",
              " 'removal',\n",
              " '%removal  ']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col1,col2,col3,col4,col5,col6,col7,col8,col9,col10='conc (ppm)','ad dose(g/L)','ph value','Temperature(⁰C)','time','absorbance','conc','real conc','removal','%removal  '"
      ],
      "metadata": {
        "id": "kyw9blFPRJdX"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = 'model/'"
      ],
      "metadata": {
        "id": "GzwJZhlMR-eB"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_steps= [ 0, 100, 200, 300, 400, 500, 1000, 2000, 3000, 4000, 5000]\n",
        "rows = len(model_steps)\n",
        "columns = 10\n"
      ],
      "metadata": {
        "id": "oSjcQ01ZTKy2"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for model_step_ix, model_step in enumerate(model_steps):\n",
        "  [model_name, with_class, generator_model] = models['GAN']\n",
        "\n",
        "  generator_model.load_weights( base_dir + '_generator_model_weights_step_'+str(model_step)+'.h5')\n",
        "\n",
        "  #ax = plt.subplot(rows, columns, model_step_ix*columns + 1 + (i+1) )\n",
        "\n",
        "  g_z = generator_model.predict(z)\n",
        "  gen_samples = pd.DataFrame(g_z, columns=data_cols)\n",
        "  gen_samples.to_csv('Generated_sample.csv')"
      ],
      "metadata": {
        "id": "oDidOv-0T3-G"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yy=gen_samples.iloc[:,-1]\n",
        "xx=gen_samples.iloc[:,0:5]"
      ],
      "metadata": {
        "id": "GGpjYY3bcGWJ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " gen_samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tMDhnCR-VSR7",
        "outputId": "73ea9564-f479-4928-f417-a080ae929a19"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b4aee239-efdf-463f-8a3a-c5d55514a58f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conc (ppm)</th>\n",
              "      <th>ad dose(g/L)</th>\n",
              "      <th>ph value</th>\n",
              "      <th>Temperature(⁰C)</th>\n",
              "      <th>time</th>\n",
              "      <th>absorbance</th>\n",
              "      <th>conc</th>\n",
              "      <th>real conc</th>\n",
              "      <th>removal</th>\n",
              "      <th>%removal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27.660261</td>\n",
              "      <td>1.618244</td>\n",
              "      <td>3.735134</td>\n",
              "      <td>27.909702</td>\n",
              "      <td>13.476619</td>\n",
              "      <td>1.805746</td>\n",
              "      <td>2.650773</td>\n",
              "      <td>2.352627</td>\n",
              "      <td>26.605284</td>\n",
              "      <td>89.788040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26.326616</td>\n",
              "      <td>3.667342</td>\n",
              "      <td>5.331314</td>\n",
              "      <td>27.241755</td>\n",
              "      <td>48.583408</td>\n",
              "      <td>-0.548532</td>\n",
              "      <td>4.777030</td>\n",
              "      <td>0.629774</td>\n",
              "      <td>25.725002</td>\n",
              "      <td>89.138596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22.852629</td>\n",
              "      <td>1.004803</td>\n",
              "      <td>3.059339</td>\n",
              "      <td>20.674023</td>\n",
              "      <td>14.333040</td>\n",
              "      <td>1.631472</td>\n",
              "      <td>2.444756</td>\n",
              "      <td>1.683973</td>\n",
              "      <td>20.907017</td>\n",
              "      <td>67.832657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26.600159</td>\n",
              "      <td>2.383255</td>\n",
              "      <td>4.866921</td>\n",
              "      <td>25.024033</td>\n",
              "      <td>34.677898</td>\n",
              "      <td>0.359784</td>\n",
              "      <td>3.459568</td>\n",
              "      <td>0.788936</td>\n",
              "      <td>25.646530</td>\n",
              "      <td>85.929886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22.013552</td>\n",
              "      <td>3.259620</td>\n",
              "      <td>4.223422</td>\n",
              "      <td>23.429605</td>\n",
              "      <td>45.440678</td>\n",
              "      <td>-0.943759</td>\n",
              "      <td>4.218081</td>\n",
              "      <td>0.578856</td>\n",
              "      <td>21.645710</td>\n",
              "      <td>76.650772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>18.962521</td>\n",
              "      <td>2.272252</td>\n",
              "      <td>3.651122</td>\n",
              "      <td>20.312044</td>\n",
              "      <td>37.573811</td>\n",
              "      <td>-0.082875</td>\n",
              "      <td>3.364410</td>\n",
              "      <td>0.082747</td>\n",
              "      <td>18.730110</td>\n",
              "      <td>65.727425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>15.966755</td>\n",
              "      <td>3.987911</td>\n",
              "      <td>4.847888</td>\n",
              "      <td>28.787365</td>\n",
              "      <td>56.483368</td>\n",
              "      <td>2.084304</td>\n",
              "      <td>3.031299</td>\n",
              "      <td>-0.948794</td>\n",
              "      <td>29.215036</td>\n",
              "      <td>102.097305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>24.133488</td>\n",
              "      <td>2.870627</td>\n",
              "      <td>4.637295</td>\n",
              "      <td>28.265459</td>\n",
              "      <td>21.723787</td>\n",
              "      <td>2.071230</td>\n",
              "      <td>3.212455</td>\n",
              "      <td>1.167626</td>\n",
              "      <td>28.457733</td>\n",
              "      <td>100.045425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>30.119204</td>\n",
              "      <td>0.792066</td>\n",
              "      <td>3.581024</td>\n",
              "      <td>28.310966</td>\n",
              "      <td>11.824623</td>\n",
              "      <td>2.167235</td>\n",
              "      <td>2.864714</td>\n",
              "      <td>3.531495</td>\n",
              "      <td>27.194139</td>\n",
              "      <td>87.186119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>30.336504</td>\n",
              "      <td>1.638295</td>\n",
              "      <td>4.321148</td>\n",
              "      <td>26.817745</td>\n",
              "      <td>19.273611</td>\n",
              "      <td>1.600845</td>\n",
              "      <td>3.006646</td>\n",
              "      <td>2.257397</td>\n",
              "      <td>28.325228</td>\n",
              "      <td>90.159698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4aee239-efdf-463f-8a3a-c5d55514a58f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4aee239-efdf-463f-8a3a-c5d55514a58f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4aee239-efdf-463f-8a3a-c5d55514a58f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     conc (ppm)  ad dose(g/L)  ph value  Temperature(⁰C)       time  \\\n",
              "0     27.660261      1.618244  3.735134        27.909702  13.476619   \n",
              "1     26.326616      3.667342  5.331314        27.241755  48.583408   \n",
              "2     22.852629      1.004803  3.059339        20.674023  14.333040   \n",
              "3     26.600159      2.383255  4.866921        25.024033  34.677898   \n",
              "4     22.013552      3.259620  4.223422        23.429605  45.440678   \n",
              "..          ...           ...       ...              ...        ...   \n",
              "146   18.962521      2.272252  3.651122        20.312044  37.573811   \n",
              "147   15.966755      3.987911  4.847888        28.787365  56.483368   \n",
              "148   24.133488      2.870627  4.637295        28.265459  21.723787   \n",
              "149   30.119204      0.792066  3.581024        28.310966  11.824623   \n",
              "150   30.336504      1.638295  4.321148        26.817745  19.273611   \n",
              "\n",
              "     absorbance      conc  real conc    removal  %removal    \n",
              "0      1.805746  2.650773   2.352627  26.605284   89.788040  \n",
              "1     -0.548532  4.777030   0.629774  25.725002   89.138596  \n",
              "2      1.631472  2.444756   1.683973  20.907017   67.832657  \n",
              "3      0.359784  3.459568   0.788936  25.646530   85.929886  \n",
              "4     -0.943759  4.218081   0.578856  21.645710   76.650772  \n",
              "..          ...       ...        ...        ...         ...  \n",
              "146   -0.082875  3.364410   0.082747  18.730110   65.727425  \n",
              "147    2.084304  3.031299  -0.948794  29.215036  102.097305  \n",
              "148    2.071230  3.212455   1.167626  28.457733  100.045425  \n",
              "149    2.167235  2.864714   3.531495  27.194139   87.186119  \n",
              "150    1.600845  3.006646   2.257397  28.325228   90.159698  \n",
              "\n",
              "[151 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN2pUu4iaZDr",
        "outputId": "54ae1e3e-d817-4598-ce30-37d91a3ddd6b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.0-py3-none-any.whl (98 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 17.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 40 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 51 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 71 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 81 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 92 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 98 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.5)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.44.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.0 kt-legacy-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kerastuner\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from kerastuner.tuners import RandomSearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-XjLCIBaets",
        "outputId": "8502a3d4-9fc7-4988-c447-74aec4d470bb"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model(hp):\n",
        "  build_model=Sequential()\n",
        "  build_model.add(Dense(units=hp.Int('n',min_value=16,max_value=512,step=16),activation='relu',input_dim=Xtrain.shape[1]))\n",
        "  for i in range(hp.Int('nlayers',min_value=2,max_value=10)):\n",
        "    build_model.add(Dense(units=hp.Int('units',min_value=16,max_value=256,step=16),activation='relu'))\n",
        "  build_model.add(Dense(units=1,activation='linear'))\n",
        "  build_model.compile(optimizer=Adam(hp.Choice('lr',[1e-2,1e-3,1e-4])),loss='mean_absolute_error',metrics=['mean_absolute_error'])\n",
        "  return build_model"
      ],
      "metadata": {
        "id": "H4paFoHKavOH"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner=RandomSearch(model,objective='val_mean_absolute_error',max_trials=5,executions_per_trial=3,directory='output',project_name='chemann')"
      ],
      "metadata": {
        "id": "OG_AKi7da3_z"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(Xtrain,ytrain,epochs=20,validation_data=(Xtest,ytest),batch_size=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-gNJYa2a7BJ",
        "outputId": "021995a8-50d0-4fd6-ce9d-f9a1499ac233"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 6 Complete [00h 00m 15s]\n",
            "val_mean_absolute_error: 11.22193972269694\n",
            "\n",
            "Best val_mean_absolute_error So Far: 9.41278330485026\n",
            "Total elapsed time: 00h 01m 44s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model=tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "rzS8rCPVb0lB"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBYXRprMcWKR",
        "outputId": "67b6e69e-5c9c-45a8-c119-ac10a3df0eb6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 112)               672       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 80)                9040      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 80)                6480      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 80)                6480      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 80)                6480      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 80)                6480      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 80)                6480      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 81        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,193\n",
            "Trainable params: 42,193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypred=best_model.predict(xx)"
      ],
      "metadata": {
        "id": "MBieCePfcaTX"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLo9ApTJdLOn",
        "outputId": "6d39d2b0-9e27-46f7-b4e5-b4edac2f5fe0"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       89.788040\n",
              "1       89.138596\n",
              "2       67.832657\n",
              "3       85.929886\n",
              "4       76.650772\n",
              "          ...    \n",
              "146     65.727425\n",
              "147    102.097305\n",
              "148    100.045425\n",
              "149     87.186119\n",
              "150     90.159698\n",
              "Name: %removal  , Length: 151, dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KdNq7XYdZ4P",
        "outputId": "a25f75d1-75cb-44a4-89f4-032f0da19676"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 84.86184 ],\n",
              "       [ 93.05983 ],\n",
              "       [ 65.6334  ],\n",
              "       [ 83.50088 ],\n",
              "       [ 80.93003 ],\n",
              "       [ 64.63751 ],\n",
              "       [ 60.263176],\n",
              "       [111.1159  ],\n",
              "       [103.04861 ],\n",
              "       [ 62.250374],\n",
              "       [ 76.94509 ],\n",
              "       [ 60.11001 ],\n",
              "       [ 63.940857],\n",
              "       [ 51.90059 ],\n",
              "       [ 64.127144],\n",
              "       [112.61979 ],\n",
              "       [ 71.270546],\n",
              "       [ 74.048485],\n",
              "       [ 93.56954 ],\n",
              "       [ 81.65387 ],\n",
              "       [ 64.00303 ],\n",
              "       [107.53633 ],\n",
              "       [ 65.40314 ],\n",
              "       [ 70.52867 ],\n",
              "       [145.94589 ],\n",
              "       [ 65.83022 ],\n",
              "       [ 56.967422],\n",
              "       [ 94.36686 ],\n",
              "       [ 71.44091 ],\n",
              "       [ 80.33999 ],\n",
              "       [ 53.30298 ],\n",
              "       [ 35.18811 ],\n",
              "       [ 83.58815 ],\n",
              "       [ 53.949833],\n",
              "       [132.50511 ],\n",
              "       [ 54.250637],\n",
              "       [ 72.49631 ],\n",
              "       [ 75.63415 ],\n",
              "       [128.55566 ],\n",
              "       [111.81977 ],\n",
              "       [ 62.929775],\n",
              "       [ 75.136116],\n",
              "       [ 64.22817 ],\n",
              "       [115.15734 ],\n",
              "       [100.777435],\n",
              "       [ 81.36262 ],\n",
              "       [ 58.47236 ],\n",
              "       [ 52.730972],\n",
              "       [ 37.65621 ],\n",
              "       [ 88.73095 ],\n",
              "       [ 56.292812],\n",
              "       [ 61.41565 ],\n",
              "       [ 50.88242 ],\n",
              "       [ 84.36431 ],\n",
              "       [ 78.79946 ],\n",
              "       [ 58.655167],\n",
              "       [ 76.40098 ],\n",
              "       [ 62.631348],\n",
              "       [100.67164 ],\n",
              "       [ 65.651985],\n",
              "       [ 57.46693 ],\n",
              "       [ 57.696922],\n",
              "       [ 82.45963 ],\n",
              "       [ 81.39584 ],\n",
              "       [130.00912 ],\n",
              "       [105.21009 ],\n",
              "       [ 64.66787 ],\n",
              "       [ 79.19421 ],\n",
              "       [ 66.084915],\n",
              "       [107.63309 ],\n",
              "       [ 56.47609 ],\n",
              "       [ 76.93774 ],\n",
              "       [ 61.568832],\n",
              "       [110.692375],\n",
              "       [126.91496 ],\n",
              "       [ 65.643654],\n",
              "       [ 51.987747],\n",
              "       [ 84.36165 ],\n",
              "       [ 83.39182 ],\n",
              "       [142.84724 ],\n",
              "       [ 73.169815],\n",
              "       [ 54.34648 ],\n",
              "       [ 58.122974],\n",
              "       [ 48.525963],\n",
              "       [ 54.88367 ],\n",
              "       [ 73.49003 ],\n",
              "       [118.58986 ],\n",
              "       [ 59.455536],\n",
              "       [ 90.57416 ],\n",
              "       [ 81.80954 ],\n",
              "       [ 46.970333],\n",
              "       [ 59.111103],\n",
              "       [ 54.770214],\n",
              "       [106.107895],\n",
              "       [ 99.58513 ],\n",
              "       [ 82.12415 ],\n",
              "       [ 89.93227 ],\n",
              "       [ 81.04354 ],\n",
              "       [ 61.689693],\n",
              "       [102.7078  ],\n",
              "       [ 62.803185],\n",
              "       [ 70.69593 ],\n",
              "       [103.702446],\n",
              "       [ 61.25102 ],\n",
              "       [111.667595],\n",
              "       [ 59.26647 ],\n",
              "       [ 41.20534 ],\n",
              "       [ 80.7669  ],\n",
              "       [ 88.22933 ],\n",
              "       [ 80.63124 ],\n",
              "       [ 80.147575],\n",
              "       [128.25171 ],\n",
              "       [ 89.43719 ],\n",
              "       [ 86.465065],\n",
              "       [ 67.46215 ],\n",
              "       [ 76.216484],\n",
              "       [ 65.07209 ],\n",
              "       [102.9114  ],\n",
              "       [ 47.205975],\n",
              "       [ 60.026886],\n",
              "       [ 66.62862 ],\n",
              "       [ 88.09779 ],\n",
              "       [ 47.46125 ],\n",
              "       [ 52.6997  ],\n",
              "       [ 64.526726],\n",
              "       [ 64.777596],\n",
              "       [ 42.960453],\n",
              "       [ 57.4483  ],\n",
              "       [ 97.355705],\n",
              "       [128.61322 ],\n",
              "       [ 81.5917  ],\n",
              "       [ 56.115707],\n",
              "       [109.7455  ],\n",
              "       [125.92336 ],\n",
              "       [ 76.88246 ],\n",
              "       [119.83661 ],\n",
              "       [ 54.971024],\n",
              "       [135.69656 ],\n",
              "       [ 55.63999 ],\n",
              "       [ 89.91336 ],\n",
              "       [ 54.70555 ],\n",
              "       [ 66.17176 ],\n",
              "       [ 64.07621 ],\n",
              "       [106.11528 ],\n",
              "       [ 45.028904],\n",
              "       [ 59.736126],\n",
              "       [ 69.49352 ],\n",
              "       [ 98.33603 ],\n",
              "       [ 91.042816],\n",
              "       [ 82.52806 ],\n",
              "       [ 84.424675]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "By4Bt_86dcvG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}